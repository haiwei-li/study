
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 基本配置](#1-基本配置)
- [2. docker 安装](#2-docker-安装)
- [3. 修改docker cgroup driver为systemd](#3-修改docker-cgroup-driver为systemd)
- [4. kube-proxy开启ipvs的前置条件(可选)](#4-kube-proxy开启ipvs的前置条件可选)

<!-- /code_chunk_output -->

Kubernetes 系统由一组可执行程序组成, 用户可以通过 GitHub 上的Kubernetes 项目页**下载编译好的二进制包**, 或者**下载源代码并编译后进行安装**.

安装 Kubernetes 对软件和硬件的系统要求如表 2.1 所示.

![2019-08-14-15-29-47.png](./images/2019-08-14-15-29-47.png)

Kubernetes 需要**容器运行时(Container Runtime Interface, CRI**)的支持, 目前官方支持的容器运行时包括: **Docker**、**Containerd**、**CRI\-O** 和 **frakti**. 容器运行时 CRI 的原理详见 3.9 节的说明. 本节以 Docker 作为容器运行环境.

宿主机操作系统以 CentOS Linux 7 为例, 使用 **Systemd 系统**完成对 Kubernetes 服务的配置. 其他 Linux 发行版的服务配置请参考相关的系统管理手册. 为了便于管理, 常见的做法是将 Kubernetes 服务程序配置为 Linux 系统开机自启动的服务.

需要注意的是, CentOS Linux 7 默认启动了防火墙服务(firewalld), 而 Kubernetes 的 **Master** 与 **工作 Node** 之间会有大量的**网络通信**, 安全的做法是在**防火墙上配置各组件需要相互通信的端口号**, 具体要配置的端口号详见 2.8 节各服务启动参数中监听的端口号.

# 1. 基本配置

修改主机名, 添加 `/etc/hosts`, 添加 `ssh-key`

```
# hostnamectl set-hostname 02master01
# ssh-keygen
# cat /root/.ssh/id_rsa.pub
# vim /root/.ssh/authorized_keys
# vim /etc/hosts
# reboot
```

如果各个主机启用了防火墙, 需要开放 Kubernetes 各个组件所需要的端口, 可以查看[Installing kubeadm](https://kubernetes.io/docs/setup/independent/install-kubeadm/)中的 "Check required ports" 一节.

这里简单起见可以关闭防火墙服务

```
# systemctl disable firewalld
# systemctl stop firewalld
```

禁用 SELinux, 让容器可以读取主机文件系统:

```
# setenforce 0
```

或修改系统文件 `/etc/sysconfig/selinux`, 将 `SELINUX=enforcing` 改成 `SELINUX=disabled`, 然后重启 Linux.

将桥接的 IPV4 流量传递到 iptables 的链, 创建 `/etc/sysctl.d/k8s.conf` 文件

```conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
```

使修改生效

```
modprobe br_netfilter
sysctl -p /etc/sysctl.d/k8s.conf
```

```
sysctl --system
```

# 2. docker 安装

Kubernetes 从 1.6 开始使用 CRI(Container Runtime Interface) 容器运行时接口. 默认的容器运行时仍然是 Docker, 使用的是 kubelet 中内置 **dockershim CRI** 实现.

具体可以查看文档 [Install Docker](https://docs.docker.com/install/). 也可以查看国内镜像源的安装方式, 比如 [清华镜像源](https://mirrors.tuna.tsinghua.edu.cn/help/docker-ce/)

先卸载旧版本

```
# sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```

安装依赖包. `yum-utils` 提供 `yum-config-manager` 组件, `device-mapper-persistent-data` 和 `lvm2` 是被 devicemapper 存储驱动依赖.

```
# sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
```

下载 repo 文件

```
# wget -O /etc/yum.repos.d/docker-ce.repo http://mirrors.tencent.com/docker-ce/linux/centos/docker-ce.repo
# sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
```

将仓库地址修改为国内源, 比如 tuna 或腾讯

```
# sudo sed -i 's+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo
# sudo sed -i 's+download.docker.com+mirrors.tencent.com/docker-ce+' /etc/yum.repos.d/docker-ce.repo
```

更新 yum 缓存

```
# sudo yum makecache
```

查看最新的 Docker 版本:

```
[root@master01 ~]# yum list docker-ce.x86_64 --showduplicates |sort -r
docker-ce.x86_64            3:19.03.1-3.el7                    docker-ce-stable
docker-ce.x86_64            3:19.03.0-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.8-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.7-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.7-3.el7                    @docker-ce-stable
docker-ce.x86_64            3:18.09.6-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.5-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.4-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.3-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.2-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.1-3.el7                    docker-ce-stable
docker-ce.x86_64            3:18.09.0-3.el7                    docker-ce-stable
docker-ce.x86_64            18.06.3.ce-3.el7                   docker-ce-stable
docker-ce.x86_64            18.06.2.ce-3.el7                   docker-ce-stable
docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable
docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable
docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.09.0.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.06.2.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.06.1.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.06.0.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.03.3.ce-1.el7                   docker-ce-stable
docker-ce.x86_64            17.03.2.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable
docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable
```

Kubernetes 1.15 当前支持的 docker 版本列表是 1.13.1, 17.03, 17.06, 17.09, 18.06, 18.09.

这里在各节点安装 docker 的 18.09.7 版本.

安装 docker engine

```
# yum install -y --setopt=obsoletes=0 docker-ce-18.09.7-3.el7
# systemctl start docker
# systemctl enable docker
```

Docker 需要用户具有 sudo 权限, 为了避免每次命令都输入 sudo, 可以把用户加入 Docker 用户组

```
# sudo usermod -aG docker $USER
```

修改iptables filter表中FOWARD链的默认策略(pllicy)为ACCEPT

```
# iptables -P FORWARD ACCEPT
# iptables -nvL
Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
    0     0 KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
    0     0 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    0     0 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
    0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
    0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
    0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0
    0     0 ACCEPT     all  --  *      virbr0  0.0.0.0/0            192.168.122.0/24     ctstate RELATED,ESTABLISHED
    0     0 ACCEPT     all  --  virbr0 *       192.168.122.0/24     0.0.0.0/0
    0     0 ACCEPT     all  --  virbr0 virbr0  0.0.0.0/0            0.0.0.0/0
    0     0 REJECT     all  --  *      virbr0  0.0.0.0/0            0.0.0.0/0            reject-with icmp-port-unreachable
    0     0 REJECT     all  --  virbr0 *       0.0.0.0/0            0.0.0.0/0            reject-with icmp-port-unreachable
```

# 3. 修改docker cgroup driver为systemd

根据文档 [CRI installation](https://kubernetes.io/docs/setup/cri/)中的内容, 对于使用 systemd 作为 init system 的Linux的发行版, 使用systemd作为docker的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定, 因此这里修改各个节点上docker的cgroup driver为systemd.

创建或修改/etc/docker/daemon.json:

```
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}
```

重启docker:

```
# systemctl restart docker

# docker info | grep Cgroup
Cgroup Driver: systemd
```

# 4. kube-proxy开启ipvs的前置条件(可选)

由于ipvs已经加入到了内核的主干, 所以为kube\-proxy开启ipvs的前提需要加载以下的内核模块

```
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack_ipv4
```

在所有的Kubernetes节点执行下面脚本

```
# cat > /etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF

# chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4
```

上面脚本创建了的/etc/sysconfig/modules/ipvs.modules文件, 保证在节点重启后能自动加载所需模块.  使用`lsmod | grep -e ip_vs -e nf_conntrack_ipv4`命令查看是否已经正确加载所需的内核模块.

接下来还需要确保各个节点上已经安装了ipset软件包yum install ipset.  为了便于查看ipvs的代理规则, 最好安装一下管理工具ipvsadm yum install ipvsadm.

如果以上前提条件如果不满足, 则即使kube-proxy的配置开启了ipvs模式, 也会退回到iptables模式.








```
# kubeadm init --apiserver-advertise-address=192.168.56.11 --image-repository registry.aliyuncs.com/google_containers --service-cidr=192.168.0.0/16 --pod-network-cidr=192.168.0.0/16

# kubeadm init --apiserver-advertise-address=192.168.56.11 --service-cidr=192.168.0.0/16 --pod-network-cidr=192.168.0.0/16
```


```
journalctl -xeu kubelet
```




```
https://www.jianshu.com/p/745c96476a32
```

