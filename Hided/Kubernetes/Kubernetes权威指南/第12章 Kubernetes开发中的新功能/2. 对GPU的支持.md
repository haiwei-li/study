
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [环境准备](#环境准备)
- [发展趋势](#发展趋势)

<!-- /code_chunk_output -->
随着人工智能和机器学习的迅速发展, 基于GPU的大数据运算越来越普及. 在Kubernetes的发展规划中, GPU资源有着非常重要的地位. 用户应该能够为其工作任务请求GPU资源, 就像请求CPU或内存一样, 而Kubernetes将负责调度容器到具有GPU资源的节点上. 

目前Kubernetes对NVIDIA和AMD两个厂商的GPU进行了实验性的支持. Kubernetes对**NVIDIA GPU**的支持是从**1.6版本**开始的, 对**AMD GPU**的支持是从**1.9版本**开始的, 并且都在快速发展. 

Kubernetes从**1.8版本**开始, 引入了**Device Plugin(设备插件)模型**, 为设备提供商提供了一种**基于插件的**、无须修改kubelet核心代码的**外部设备启用方式**, 设备提供商**只需**在**计算节点**上以**DaemonSet方式**启动一个**设备插件容器**供**kubelet调用**, 即可使用外部设备. 

目前支持的**设备类型**包括**GPU**、**高性能NIC卡**、**FPGA**、**InfiniBand**等, 关于设备插件的说明详见官方文档 https://kubernetes.io/docs/concepts/extend-kubernetes/computestorage-net/device-plugins . 

下面对如何在Kubernetes中使用GPU资源进行说明. 

# 环境准备

# 发展趋势

发展趋势如下. 

* **GPU**和**其他设备**将像CPU那样成为Kubernetes系统的**原生计算资源类型**, 以**Device Plugin**的方式供**kubelet调用**. 
* 目前的API限制较多, Kubernetes未来会有功能更丰富的API, 能支持以可扩展的形式进行GPU等硬件加速器资源的供给、调度和使用. 
* **Kubernetes**将能**自动确保**使用GPU的应用程序达到**最佳性能**. 
