<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 虚拟化场景中的组件](#1-虚拟化场景中的组件)
- [2. vhost-net](#2-vhost-net)
- [3. Open vSwitch](#3-open-vswitch)
- [4. DPDK](#4-dpdk)
- [5. SPDK](#5-spdk)
- [6. Ceph](#6-ceph)
- [7. libguestfs](#7-libguestfs)

<!-- /code_chunk_output -->

# 1. 虚拟化场景中的组件

在 KVM 虚拟化的软件栈中, 毋庸置疑的是**KVM 内核模块**与 **QEMU 用户态程序**是处于最核心的位置, 有了它们就可通过 qemu 命令行操作实现完整的虚拟机功能, 本书中多数的实践范例正是通过 qemu 命令行来演示的.

然而, 在**实际的云计算的虚拟化场景**中, 为了**更高的性能**或者**管理的方便性**, 还有很多的软件可以作为**KVM 虚拟化**实施中的**组件**, 这里简单介绍其中的几个.

# 2. vhost-net

**vhost\-net**是 Linux 内核中的一个模块, 它用于**替代**QEMU 中的 virtio\-net 用户态的**virtio 网络的后端实现**.

使用 vhost\-net 时, 还支持**网卡的多队列**, 整体来说会让网络性能得到较大提高. 在 6.1.6 节中对 vhost\-net 有更多的介绍.

# 3. Open vSwitch

Open vSwitch 是一个高质量的、**多层虚拟交换机**, 使用开源 Apache2.0 许可协议, 主要用可移植性强的 C 语言编写的.

它的目的是让**大规模网络自动化**可以通过编程扩展, 同时仍然**支持标准的管理接口和协议**(例如**NetFlow**、**sFlow**、**SPAN**、**RSPAN**、**CLI**、**LACP**、**802.1ag**).

同时也提供了对**OpenFlow 协议**的支持, 用户可以使用任何**支持 OpenFlow 协议**的**控制器**对 OVS 进行**远程管理控制！！！**.

Open vSwitch 被设计为支持**跨越多个物理服务器**的分布式环境, 类似于 VMware 的 vNetwork 分布式 vswitch 或 Cisco Nexus 1000 V.

Open vSwitch 支持**多种虚拟化技术**, 包括 Xen/XenServer、KVM 和 VirtualBox.

在 KVM 虚拟化中, 要实现**软件定义网络(SDN**), 那么 Open vSwitch 是一个非常好的开源选择.

# 4. DPDK

DPDK 全称是**Data Plane Development Kit**, 最初是由**Intel**公司维护的**数据平面开发工具集**.

它为 Intel x**86 处理器架构**下**用户空间**高效的**数据包处理**提供**库函数和驱动**的支持, 现在也是一个完全独立的开源项目, 它还支持**POWER**和**ARM 处理器架构**.

不同于 Linux 系统以通用性设计为目的, 它专注于**网络应用中数据包的高性能处理**. 具体体现在**DPDK**应用程序是运行在**用户空间**上, 利用**自身提供的数据平面库**来**收发数据包**, **绕过了 Linux 内核协议栈！！！**对数据包处理过程.

其优点是: 性能高、用户态开发、出故障后易恢复.

在 KVM 架构中, 为了达到**非常高的网络处理能力！！！**(特别是**小包处理能力**), 可以选择**DPDK**与**QEMU 中**的**vhost\-user**结合起来使用.

# 5. SPDK

SPDK 全称是**Storage Performance Development Kit**, 它可为编写**高性能**、**可扩展的**、**用户模式**的**存储程序**提供一系列**工具及开发库**.

它与 DPDK 非常类似, 其主要特点是: 将**驱动**放到**用户态**从而实现**零拷贝**、用**轮询模式**替代**传统的中断模式**、在**所有的 I/O 链路**上实现**无锁设计**, 这些设计会使其性能比较高.

在 KVM 中需要非常高的存储 I/O 性能时, 可以将**QEMU 与 SPDK 结合**使用.

# 6. Ceph

Ceph 是 Linux 上一个著名的分布式存储系统, 能够在维护 POSIX 兼容性的同时加入复制和容错功能.

Ceph 由**储存管理器**(Object storage cluster 对象存储集群, 即**OSD 守护进程**)、**集群监视器**(Ceph Monitor)和**元数据服务器**(Metadata server cluster, MDS)构成.

其中, **元数据服务器 MDS**仅仅在**客户端**通过**文件系统方式**使用 Ceph 时才需要. 当客户端通过块设备或对象存储使用 Ceph 时, **可以没有 MDS**.

Ceph 支持 3 种调用接口: **对象存储**, **块存储**, **文件系统挂载**.

在 libvirt 和 QEMU 中都有 Ceph 的接口, 所以 Ceph 与 KVM 虚拟化集成是非常容易的.

在 OpenStack 的云平台解决方案中, Ceph 是一个非常常用的存储后端.

# 7. libguestfs

libguestfs 是用于**访问和修改虚拟机的磁盘镜像**的一组工具集合.

libguestfs 提供了**访问**和**编辑客户机**中的**文件**、**脚本化修改客户机中的信息**、**监控磁盘使用和空闲的统计信息**、P2V、V2V、创建客户机、克隆客户机、备份磁盘内容、格式化磁盘、调整磁盘大小等非常丰富的功能.

libguestfs 还提供了共享库, 可以在 C/C++、Python 等编程语言中对其进行调用.

libguestfs**不需要启动 KVM 客户机**就可以**对磁盘镜像进行管理**, 功能强大且非常灵活, 是**管理 KVM 磁盘镜像**的首选工具.
