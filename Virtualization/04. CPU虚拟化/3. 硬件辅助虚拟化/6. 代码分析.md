
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. KVM 模块初始化流程](#1-kvm-模块初始化流程)
- [2. QEMU 与 KVM 交互](#2-qemu-与-kvm-交互)
- [3. /dev/kvm 的 ioctl 接口 kvm_dev_ioctl](#3-devkvm-的-ioctl-接口-kvm_dev_ioctl)
- [4. 虚拟机的创建](#4-虚拟机的创建)
  - [4.1. 基本原理](#41-基本原理)
  - [4.2. 整体流程](#42-整体流程)
  - [4.3. 代码分析](#43-代码分析)
    - [4.3.1. 虚拟机创建过程 kvm_dev_ioctl_create_vm](#431-虚拟机创建过程-kvm_dev_ioctl_create_vm)
      - [4.3.1.1. kvm_create_vm 流程](#4311-kvm_create_vm-流程)
      - [4.3.1.2. 返回 kvm_vm 的 fd 文件描述符](#4312-返回-kvm_vm-的-fd-文件描述符)
- [5. 虚拟机 fd 的 ioctl 接口 kvm_vm_ioctl](#5-虚拟机-fd-的-ioctl-接口-kvm_vm_ioctl)
- [6. vCPU 的创建](#6-vcpu-的创建)
  - [6.1. 基本原理](#61-基本原理)
  - [6.2. 整体流程](#62-整体流程)
  - [6.3. 代码分析](#63-代码分析)
    - [6.3.1. vCPU 的创建过程 kvm_vm_ioctl_create_vcpu](#631-vcpu-的创建过程-kvm_vm_ioctl_create_vcpu)
      - [6.3.1.1. kvm_arch_vcpu_create 创建 kvm_vcpu](#6311-kvm_arch_vcpu_create-创建-kvm_vcpu)
      - [6.3.1.2. kvm_arch_vcpu_setup 初始化 kvm_vcpu](#6312-kvm_arch_vcpu_setup-初始化-kvm_vcpu)
      - [6.3.1.3. vCPU 检测](#6313-vcpu-检测)
      - [6.3.1.4. 创建 vcpu_fd](#6314-创建-vcpu_fd)
      - [6.3.1.5. 释放内核锁和返回 vcpu_fd](#6315-释放内核锁和返回-vcpu_fd)
- [7. vCPU 的运行](#7-vcpu-的运行)
  - [7.1. 基本原理](#71-基本原理)
  - [7.2. 整体流程](#72-整体流程)
  - [7.3. 代码分析](#73-代码分析)
    - [7.3.1. SVM 的 VMRUN](#731-svm-的-vmrun)

<!-- /code_chunk_output -->

# 1. KVM 模块初始化流程

先有 KVM 相关模块的初始化. 从而生成 `/dev/kvm` 文件句柄给用户空间使用.

# 2. QEMU 与 KVM 交互

KVM 内核模块加载之后只提供了一个对外接口 /dev/kvm, qemu 通过 /dev/kvm 文件依次创建 vm 句柄和 vcpu 句柄来和 kvm 交互.

所以存在三种句柄: KVM 访问句柄、虚拟机访问句柄和 vCPU 访问句柄

![](./images/2019-06-04-15-01-11.png)

整体流程是:

```cpp
qemu_open("/dev/kvm", O_RDWR); //KVM 访问句柄
kvm_ioctl(s, KVM_GET_API_VERSION, 0);
kvm_ioctl(s,KVM_CREATE_VM, 0); //创建 vm 访问句柄
kvm_arch_init ==>
kvm_vm_ioctl(s,KVM_SET_IDENTITY_MAP_ADDR, &identity_base)

           kvm_vm_ioctl(s,KVM_SET_TSS_ADDR, identity_base + 0x1000)

           kvm_vm_ioctl(s,KVM_SET_NR_MMU_PAGES, shadow_mem)
==>kvm_irqchip_create(s) ==> kvm_vm_ioctl(s, KVM_CREATE_IRQCHIP)

kvm_init_vcpu(env);
==> kvm_vm_ioctl(s, KVM_CREATE_VCPU, env->cpu_index);创建 vcpu 句柄

	kvm_cpu_exec
	==>kvm_vcpu_ioctl(env, KVM_RUN, 0);

	//根据 Exit 的原因处理 VM-Exit

       switch (run->exit_reason) {

       case KVM_EXIT_IO: //VM Exit Cause by IO operation

           kvm_handle_io();

```

# 3. /dev/kvm 的 ioctl 接口 kvm_dev_ioctl

在上面初始化中调用了`misc_register(&kvm_dev);`注册了`/dev/kvm`

`/dev/kvm`的 ioctl 的接口`kvm_dev_ioctl`主要提供了创建 vm 和校验版本号的功能

```cpp
static long kvm_dev_ioctl(struct file *filp,
			  unsigned int ioctl, unsigned long arg)
{
	long r = -EINVAL;

	switch (ioctl) {
	case KVM_GET_API_VERSION:             //获取 api 版本
		if (arg)
			goto out;
		r = KVM_API_VERSION;
		break;
	case KVM_CREATE_VM:                    //创建 VM, 返回 vmfd
		r = kvm_dev_ioctl_create_vm(arg);
		break;
	case KVM_CHECK_EXTENSION:
		r = kvm_vm_ioctl_check_extension_generic(NULL, arg);
		break;
	case KVM_GET_VCPU_MMAP_SIZE:
		if (arg)
			goto out;
		r = PAGE_SIZE;     /* struct kvm_run */
#ifdef CONFIG_X86
		r += PAGE_SIZE;    /* pio data page */
#endif
#ifdef KVM_COALESCED_MMIO_PAGE_OFFSET
		r += PAGE_SIZE;    /* coalesced mmio ring page */
#endif
		break;

	default:
		return kvm_arch_dev_ioctl(filp, ioctl, arg); //默认创建设备
	}
out:
	return r;
}
```

# 4. 虚拟机的创建

## 4.1. 基本原理

基于 KVM 的虚拟机创建分为**虚拟机创建**和**虚拟 CPU 创建**两个步骤.

在下文的描述中, **虚拟机**对应的**文件描述符**为`vm_fd`, **虚拟 CPU**对应的**文件描述符**为`vcpu_fd`.

**打开/dev/kvm** 文件并且获得**文件描述符 fd** 后, 通过 `kvm_dev_ioctl` 指令写入`KVM_CREATE_VM`, 即可创建一个 VM 虚拟机.

对`虚拟机(VM)`来说, **kvm 结构体**是关键, **一个虚拟机**对应**一个 kvm 结构体**, 虚拟机的创建过程实质为**kvm 结构体的创建**和**初始化过程**.

## 4.2. 整体流程

整体流程如下:

```cpp
用户态 ioctl(fd,KVM_CREATE_VM,..)
kvm_dev_ioctl() // kvm ioctl 指令入口
 ├─ kvm_dev_ioctl_create_vm() // 创建虚拟机
 │   ├─ kvm_create_vm() // 实现虚拟机创建的主要函数
 │   │   ├─ kvm_arch_alloc_vm() // 分配 kvm 虚拟机结构体
 │   │   ├─ kvm_eventfd_init() // 初始化事件通道
 │   │   ├─ kvm_alloc_memslots() // 分配 memslots 结构,
 │   │   │   └─ kvzalloc() //
 │   │   ├─ kzalloc() // 分配 kvm_io_bus 结构,
 │   │   ├─ kvm_arch_init_vm() // 初始化 kvm 结构中的架构相关部分, 比如中断, 最后会调用 vmx_vm_init?
 │   │   ├─ hardware_enable_all() // 使能硬件, 架构相关操作
 │   │   │   └─ on_each_cpu(hardware_enable_nolock, NULL, 1) // 对所有 cpu 调用 hardware_enable_nolock 方法, 从 hardware_enable_all 调用过来的话只会执行一次
 │   │   │       └─ kvm_arch_hardware_enable() //
 │   │   │           ├─ kvm_user_reture_msr_cpu_online()     // kvm
 │   │   │           ├─ static_call(kvm_x86_hardware_enable)()  // 打开硬件功能, 会调用 vmxon 指令
 │   │   │           │   ├─ kvm_cpu_vmxon()  // vmxon 打开 VMX 模式
 │   │   │           │   └─ ept_sync_global()  //
 │   │   │           ├─ kvm_check_tsc_unstable()     // 接下来还有一些初始化 tsc 规则
 │   │   ├─ kvm_init_mmu_notifier() // 初始化 mmu 操作的通知链
 │   │   ├─ kvm_arch_post_init_vm() //
 │   │   │   └─ kvm_mmu_post_init_vm() //
 │   │   │       └─ kvm_vm_create_worker_thread() //
 │   │   └─ list_add(&kvm->vm_list, &vm_list) // 将新创建的虚拟机的 kvm 结构, 加入到全局链表 vm_list 中
```

## 4.3. 代码分析

kvm 结构体见上节

### 4.3.1. 虚拟机创建过程 kvm_dev_ioctl_create_vm

KVM 的**该部分代码**实现在`kvm_dev` 的 `file_operation` 结构体中, 对应的代码在 `kvm_main.c` 中调用 `kvm_dev_ioctl_create_vm` 函数实现, 其代码如下:

代码 5\-7 KVM\_CREATE\_VM 实现代码

```cpp
// virt/kvm/kvm_main.c
static long kvm_dev_ioctl(struct file *filp,
			  unsigned int ioctl, unsigned long arg)
{
(1880)        case KVM_CREATE_VM:
(1881)             r = -EINVAL;
(1882)             if (arg)
(1883)                  goto out;
(1884)             r = kvm_dev_ioctl_create_vm();
(1885)             break;
```

`kvm_dev_ioctl_create_vm`函数(`virt/kvm/kvm_main.c`)通过调用`kvm_create_vm`函数对**KVM 结构体**进行创建.

```cpp
// virt/kvm/kvm_main.c
static int kvm_dev_ioctl_create_vm(unsigned long type)
{
	int r;
	struct kvm *kvm;

	kvm = kvm_create_vm(type);			// 创建 VM
	if (IS_ERR(kvm))
		return PTR_ERR(kvm);
#ifdef KVM_COALESCED_MMIO_PAGE_OFFSET
	r = kvm_coalesced_mmio_init(kvm);
	if (r < 0) {
		kvm_put_kvm(kvm);
		return r;
	}
#endif
	r = anon_inode_getfd("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);	//挂载 vmfd 的 ioctl 接口
	if (r < 0)
		kvm_put_kvm(kvm);

	return r;
}
```

**KVM 结构体**如前文所述, 保存了**虚拟机运行的上下文**及**其他相关状态**, 在**使用之前**, 需要进行**一定的初始化**工作.

#### 4.3.1.1. kvm_create_vm 流程

虚拟机创建的主要函数

```cpp
// virt/kvm/kvm_main.c
static struct kvm *kvm_create_vm(unsigned long type)
{
	int r, i;
	/*
     * 分配 kvm 结构体, 一个虚拟机对应一个 kvm 结构, 其中包括了虚拟机中的
     * 关键系统, 比如内存、中断、VCPU、总线等信息, 该结构体也是 kvm 的关键结
     * 构体之一
     */
	struct kvm *kvm = kvm_arch_alloc_vm();
	//  // 初始化 kvm 结构中的架构相关部分, 比如中断
	r = kvm_arch_init_vm(kvm, type);
	// 硬件使能, 最终调用架构相关的 kvm_x86_ops->hardware_enable()接口
	r = hardware_enable_all();
	// 分配 memslots 结构, 并初始化为 0
	kvm->memslots = kzalloc(sizeof(struct kvm_memslots), GFP_KERNEL);
    // 初始化内存槽位(slot)的 id 信息, 便于后续索引
	kvm_init_memslots_id(kvm);
	if (init_srcu_struct(&kvm->srcu))
		goto out_err_nosrcu;
	// 初始化虚拟机的 bus 信息
	for (i = 0; i < KVM_NR_BUSES; i++) {
		kvm->buses[i] = kzalloc(sizeof(struct kvm_io_bus),
					GFP_KERNEL);
		if (!kvm->buses[i])
			goto out_err;
	}
	// 初始化 mmu_lock
	spin_lock_init(&kvm->mmu_lock);
	// 设置虚拟机的 mm(mm_struct)为当前进程的 mm
	kvm->mm = current->mm;
	atomic_inc(&kvm->mm->mm_count);
	// 初始化事件通道
	kvm_eventfd_init(kvm);
	// 初始化 mmu 操作的通知链
	r = kvm_init_mmu_notifier(kvm);

	raw_spin_lock(&kvm_lock);
	// 将新创建的虚拟机的 kvm 结构, 加入到全局链表 vm_list 中
	list_add(&kvm->vm_list, &vm_list);
	raw_spin_unlock(&kvm_lock);

	return kvm;
}
```

先**分配一个虚拟机 struct kvm 数据结构**;

在 x86 体系架构中, **KVM 结构体**的**初始化**任务在`kvm_arch_init_vm`函数(`arch/x86/kvm/x86.c`)中进行, 进行了**分配内存**、**初始化设备列表**、设置**中断管理**和**初始化 tsc 的 spin\_lock 的功能**.

在**完成之后**, 将执行**硬件初始化**工作, 该部分硬件初始化工作通过调用`on_each_cpu`宏, 将在**每个物理 CPU**上执行**同样的操作**. 该操作主要是尝试将**所有的 CPU**切换入**vitualize 模式**(使用`vmxon`指令), 并且设置好**时钟**等信息, 这个过程通过 `kvm_arch_hardware_enable` 函数完成.

```cpp
// virt/kvm/kvm_main.c
static int kvm_usage_count;

static int hardware_enable_all(void)
{
        int r = 0;

        raw_spin_lock(&kvm_count_lock);
        // 只有这里才会加一
        kvm_usage_count++;
        // 所以第一次才会调用
        if (kvm_usage_count == 1) {
                atomic_set(&hardware_enable_failed, 0);
                // 对于每个 cpu, 执行 hardware_enable_nolock 开启硬件虚拟化功能
                // 还有一个就是 vcpu 变成 starting 状态时会调用(CPU 热插时, 见模块初始化部分)
                on_each_cpu(hardware_enable_nolock, NULL, 1);

                if (atomic_read(&hardware_enable_failed)) {
                        hardware_disable_all_nolock();
                        r = -EBUSY;
                }
        }

        raw_spin_unlock(&kvm_count_lock);

        return r;
}
```

该函数代码(`arch/x86/kvm/x86.c`)如下, 主要执行了两个工作:

- 处理 kvm shared msr 信息
- **整理 CPU 的时钟信息**;
- 调用`kvm_x86_ops`的**硬件相关**的函数进行具体操作, 这其中调用了`vmxon`使每个 cpu 进入 Virtualization 模式.

代码 5\-8 `kvm_arch_hardware_enable`函数代码

```cpp
(5799)int kvm_arch_hardware_enable(void *garbage)
(5800){
(5801)     struct kvm *kvm;
(5802)     struct kvm_vcpu *vcpu;
(5803)     int i;
(5804)
(5805)     kvm_shared_msr_cpu_online();
(5806)     list_for_each_entry(kvm, &vm_list, vm_list)
(5807)          kvm_for_each_vcpu(i, vcpu, kvm)
(5808)               if (vcpu->cpu == smp_processor_id())
(5809)                    kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);
(5810)     return kvm_x86_ops->hardware_enable(garbage);
(5811)}
```

接下来, 将初始化 KVM 的 **memslot 结构体**、**Bus 总线结构体信息**、**scru 读/写锁信息**、**eventfd 事件通知信息**、**mmu 内存管理结构体**信息.

#### 4.3.1.2. 返回 kvm_vm 的 fd 文件描述符

然后, 调用 `anon_inode_getfd` 函数.

该函数设置了对**所有 KVM 的操作**都将给予**kvm\_vm 这个共享文件**进行, 该共享文件的操作封装在`kvm_vm_fops`结构体中, 对**VM 的操作**实际上就是对此文件的操作. 因此, 对其**ioctl 调用**的是`kvm_vm_fops`中的成员函数**.

代码 5\-9 调用`anon_inode_getfd`创建 kvm\-vm

```cpp
//
(1840)        fd = anon_inode_getfd("kvm-vm", &kvm_vm_fops, kvm, O_RDWR);
(1841)        if (fd < 0)
(1842)             kvm_put_kvm(kvm);
(1843)
(1844)        return fd;
```

通过 anon\_inode\_getfd 获得的**fd 文件描述符**, 就是供**用户态**使用的**vm\_fd**, 用户态将通过该 fd 进行进一步的虚拟机操作, 首先要做的事情是**初始化 vCPU**.

# 5. 虚拟机 fd 的 ioctl 接口 kvm_vm_ioctl

上面调用后会得到虚拟机的 fd, 对应的 ioctl 是`kvm_vm_ioctl()`

```cpp
// virt/kvm/kvm_main.c
static long kvm_vm_ioctl(struct file *filp,
			   unsigned int ioctl, unsigned long arg)
```

# 6. vCPU 的创建

## 6.1. 基本原理

创建 vCPU 实际上就是**创建 vCPU 的描述符**, 在 KVM 中, **vCPU 对应的数据结构体**为`kvm_vcpu`. 因此, 创建 vCPU 的描述符, 简单来说就是**分配相应大小的内存**, 并且进行相应的**初始化**工作.

`kvm_vcpu`中描述符包含的内容有很多, 通常会包含各个**平台通用的内容**和**平台相关的内容**.

在**物理 CPU 上电**之后, 需要进一步初始化才可以使用. 在这个过程中, 硬件会自动将 CPU 初始化成特定的状态. **kvm\_vcpu 的初始化**也是一个**类似的过程**, 将 `kvm_vcpu` 的**各个数据结构体**设置成为可用的状态, 通常需要包含如下内容.

- 分配**vCPU 标识**, 设置`cpu_id`属于**哪个 KVM 虚拟机**, 并且分配对该 vCPU 的**唯一标识符**.
- 初始化**虚拟寄存器组**, 在`VT-x`下, 这些信息包含在**VMCS**中
- 初始化 `kvm_vcpu` 的**状态信息**, 标识该**VCPU**当前所处的**状态**(睡眠、运行等), 主要供**调度器使用**.
- **寄存器/部件信息**, 主要指**未包含在 VMCS！！！** 中的**寄存器**或**CPU 部件**, 比如: **浮点寄存器！！！** 和 **虚拟的 LAPIC！！！** 等.
- 用户**VMM**进行优化或存储额外信息的字段, 如: 存放该**VCPU 私有数据的指针**.

接下来讲述 KVM 中**vCPU 的创建过程**.

在获得了 **fd_vm** 之后, 通过 **ioctl** 调用**KVM_CREATE_VCPU 指令**, 可以对该 `fd_vm` 对应的虚拟机**创建 vCPU**, 其入口函数地址在 **kvm\_vm\_ioctl** 函数(`virt/kvm/kvm\_main.c`)中, 通过`switch`之后, 程序流程将选择进入 **kvm_vm_ioctl_create_vcpu** 函数中进行处理, 其代码如下.

## 6.2. 整体流程

```cpp
kvm_vm_ioctl() // kvm ioctl vm 指令入口
 ├─ kvm_vm_ioctl_create_vcpu() // 为虚拟机创建 VCPU 的 ioctl 调用的入口函数
 │   ├─ kvm_arch_vcpu_precreate() // stable tsc 检查
 │   ├─ kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL); // 给 kvm_vcpu 分配内存, 该 cache 是 kvm 模块初始化时创建的
 │   ├─ page = alloc_page(); // 分配一页内存给 vcpu->run(struct kvm_run)
 │   ├─ kvm_vcpu_init(vcpu, kvm, id); // vcpu 结构体一些变量初始化
 │   ├─ kvm_arch_vcpu_create() // 初始化 kvm_vcpu_arch 结构体, 架构相关
 │   │   ├─ vcpu->arch.mp_state = KVM_MP_STATE_UNINITIALIZED/KVM_MP_STATE_RUNNABLE; // 设置 vcpu 状态
 │   │   ├─ kvm_set_tsc_khz() // tsc 的设置
 │   │   ├─ kvm_mmu_create() // kvm_vcpu_arch 中 mmu 相关初始化, 内存虚拟化, 地址转换的重点
 │   │   ├─  └─ alloc_mmu_pages() // 给 vcpu->arch 的 gust mmu 和 root mmu 分配页面
 │   │   ├─ kvm_create_lapic() // 初始化 lapic
 │   │   ├─ alloc_page(); // 给 kvm_vcpu_arch 的 pio 分配内存页
 │   │   ├─ vcpu->arch.mce_banks = kzalloc(); // 以及其他一些代码实现初始化 mce_banks
 │   │   ├─ alloc_emulate_ctxt(vcpu); // 没有 VMX 时的软件模拟, 没人用...
 │   │   ├─ vcpu->arch.user_fpu = kmem_cache_zalloc(); //给用户态 fpu 分配 kmem cache
 │   │   ├─ vcpu->arch.guest_fpu = kmem_cache_zalloc(); // 虚拟机 fpu 的 kmem cache
 │   │   ├─ kvm_pmu_init(vcpu); //
 │   │   ├─ kvm_hv_vcpu_init(vcpu); //
 │   │   ├─ static_call(kvm_x86_vcpu_create)(vcpu); //对于 intel x86 来说, 最终调用 vmx_create_vcpu
 │   │   │   ├─ vmx->vpid = allocate_vpid(); // 分配 vpid
 │   │   │   ├─ vmx->pml_pg = alloc_page(); //
 │   │   │   ├─ alloc_laded_vmcs(&vmx->vmc01); // loaded_vmcs 的分配以及初始化
 │   │   │   │   ├─ loaded_vmcs->vmcs = alloc_vmcs(); // 分配一个页面
 │   │   │   │   ├─ vmcs_clear(loaded_vmcs->vmcs); // 调用 vmclear
 │   │   │   │   ├─ loaded_vmcs->shadow_vmcs = NULL;
 │   │   │   │   ├─ loaded_vmcs->hv_timer_soft_disabled = false;
 │   │   │   │   ├─ loaded_vmcs->cpu = -1;
 │   │   │   │   ├─ loaded_vmcs->launched = 0; //
 │   │   │   │   ├─ loaded_vmcs->msr_bitmap = (unsigned long *)__get_free_page(GFP_KERNEL_ACCOUNT); // msr_bitmap 分配页面
 │   │   │   │   ├─ memset(&loaded_vmcs->host_state, 0, sizeof(struct vmcs_host_state)); // host_state
 │   │   │   │   └─ memset(&loaded_vmcs->controls_shadow, 0, sizeof(struct vmcs_controls_shadow)); // controls_shadow
 │   │   │   ├─ vmx_disable_intercept_for_msr();
 │   │   │   ├─ vmx->loaded_vmcs = &vmx->vmcs01;
 │   │   │   ├─ vmx_vcpu_load(); // 加载 vcpu 信息
 │   │   │   │   ├─ vmx_vcpu_load_vmcs(); // 加载 vmcs
 │   │   │   │   │   ├─ already_loaded = vmx->loaded_vmcs->cpu == cpu; // 是否已经加载的判断
 │   │   │   │   │   │   ├─ loaded_vmcs_clear(vmx->loaded_vmcs); // 没有加载时, 会调用 vmclear 命令(操作数为 struct vmcs 地址), 用于对该 VMCS 区域初始化, 包括将数据填充到 VMCS 区域和将 VMCS 状态(不可见字段)置为 clear
 │   │   │   │   │   │   └─ list_add(&vmx->loaded_vmcs->loaded_vmcss_on_cpu_link, &per_cpu(loaded_vmcss_on_cpu, cpu)); // 没有加载时, 相应 cpu 上的 loaded_vmcs 链表
 │   │   │   │   │   ├─ per_cpu(current_vmcs, cpu) = vmx->loaded_vmcs->vmcs; // 赋值 cpu 的 current_vmcs
 │   │   │   │   │   ├─ vmcs_load(vmx->loaded_vmcs->vmcs); // vmptrld 指令, 加载这个 vmcs 为 current-VMCS
 │   │   │   │   │   │   ├─ kvm_make_request(KVM_REQ_TLB_FLUSH, vcpu); //
 │   │   │   │   │   │   ├─ vmcs_writel(HOST_TR_BASE, (unsigned long)&get_cpu_entry_area(cpu)->tss.x86_tss); // 没加载时, 写 VMCS 的 TSS
 │   │   │   │   │   │   ├─ vmcs_writel(HOST_GDTR_BASE, (unsigned long)gdt);   // 没加载时, 写 GDT
 │   │   │   │   │   │   └─  vmx->loaded_vmcs->cpu = cpu; // 没加载时, 关联 CPU
 │   │   │   │   │   └─ decache_tsc_multiplier(); // 设置 tsc multiplier
 │   │   │   │   └─ vmx_vcpu_pi_load(); // 加载 posted interrupt
 │   │   │   ├─ init_vmcs(vmx); // 初始化 vmcs, 而 guest-state 在 vmx_vcpu_reset()
 │   │   │   │   ├─ vmcs_write32();
 │   │   │   │   ├─ vmcs_write64(); // 一堆写入 vmcs, 使用 vmwrite 指令
 │   │   │   │   ├─ vmx_set_constant_host_state(vmx); // 设置 host-state 信息域
 │   │   │   │   │   ├─ vmcs_write1(HOST_RIP, (unsigned long)vmx_vmexit); //vmexit 后 vmm 的入口地址, 这里面是个 ret, 详细说明见下面 VCPU_RUN
 │   │   │   │   ├─ vm_exit_controls_set(); // vm-exit 控制域设置
 │   │   │   │   ├─ vm_entry_controls_set(); // vm-entry 控制域设置
 │   │   │   │   └─ set_cr4_guest_host_mask(); // 设置虚拟机 CR4
 │   │   │   ├─ vmx_vcpu_put();
 │   │   │   │   ├─ vmx_vcpu_pi_put();
 │   │   │   │   └─ vmx_prepare_switch_to_host(); //
 │   │   │   ├─ alloc_apic_access_page(); //
 │   │   │   └─ init_rmode_identity_map();
 │   │   ├─ kvm_vcpu_mtrr_init(vcpu); // 初始化 mtrr 链表
 │   │   ├─ vcpu_load(vcpu);  // 加载 vcpu 信息<参数为 kvm_vcpu>, struct vmx_vcpu(vcpu 的一个运行环境)加载,
 │   │   │   ├─ __this_cpu_write(kvm_running_vcpu, vcpu); //
 │   │   │   ├─ preempt_notifier_register(&vcpu->preempt_notifier); //
 │   │   │   ├─ kvm_arch_vcpu_load(vcpu, cpu)
 │   │   │   │   ├─ static_call(kvm_x86_vcpu_load)(vcpu, cpu); // 实际调用 vmx.c 的 vmx_vcpu_load(), 见上面
 │   │   │   │   └─ kvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu); //
 │   │   ├─ kvm_vcpu_reset(vcpu, false); // 对 vcpu 结构进行初始化
 │   │   │   ├─ kvm_lapic_reset(vcpu, init_event);
 │   │   │   ├─ vcpu 很多变量的初始化
 │   │   │   ├─ kvm_clear_interrupt_queue(vcpu);
 │   │   │   ├─ kvm_clear_exception_queue(vcpu);
 │   │   │   ├─ kvm_make_request(KVM_REQ_EVENT, vcpu);
 │   │   │   ├─ kvmclock_reset(vcpu);
 │   │   │   └─ static_call(kvm_x86_vcpu_reset)(vcpu, init_event); // 调用相应架构的 vcpu_reset 函数
 │   │   ├─ kvm_init_mmu(vcpu, false); // 初始化 mmu
 │   │   └─ vcpu_put(vcpu);
 │   │       ├─ kvm_arch_vcpu_put(vcpu);
 │   │       ├─ preempt_notifier_unregister(&vcpu->preempt_notifier);
 │   │       └─ __this_cpu_write(kvm_running_vcpu, NULL);
 │   ├─ km_get_kvm() // 增加 kvm 的引用计数
 │   ├─ ceate_vcpu_fd() // 为新创建的 vcpu 创建对应的 fd, 以便于后续通过该 fd 进行 ioctl 操作
 │   ├─ km->vcpus[vcpu->vcpu_idx]=vcpu; //添加到虚拟机的 vcpus 数组
 │   ├─ aomic_inc(&kvm->online_vcpus); //增加 kvm->online_vcpus 数目
 │   ├─ km_arch_vcpu_postcreate() // 架构相关的善后工作, 比如再次调用 vcpu_load, 以及 tsc 相关处理
 │   │   ├─vcpu_load();
 │   │   └─ kvm_write_tsc();
 │   └─ km_create_vcpu_debugfs() // 创建 vcpu 的 debugfs
```

## 6.3. 代码分析

kvm_vcpu 结构体见上节

### 6.3.1. vCPU 的创建过程 kvm_vm_ioctl_create_vcpu

虚拟机创建 VCPU 的 ioctl 调用的入口函数, 本质为创建 vcpu 结构并初始化, 并将其填入 kvm 结构中.

代码 5-10 kvm\_vm_ioctl\_create\_vcpu 代码

```cpp
// virt/kvm/kvm_main.c
(1366)   static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
(1367)   {
(1368)        int r;
(1369)        struct kvm_vcpu *vcpu, *v;
(1370)        // 创建 vcpu 结构, 架构相关, 对于 intel x86 来说, 最终调用 vmx_create_vcpu
(1371)        vcpu = kvm_arch_vcpu_create(kvm, id);
(1372)        if (IS_ERR(vcpu))
(1373)             return PTR_ERR(vcpu);
(1374)
(1375)        preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
(1376)        /*
               * 设置 vcpu 结构, 主要调用 kvm_x86_ops->vcpu_load, KVM 虚拟机 VCPU 数据结构载入物理 CPU,
               * 并进行虚拟机 mmu 相关设置, 比如进行 ept 页表的相关初始工作或影子页表
               * 相关的设置.
               */
(1377)        r = kvm_arch_vcpu_setup(vcpu);
(1378)        if (r)
(1379)             return r;
(1380)
(1381)        mutex_lock(&kvm->lock);
(1382)        if (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {
(1383)             r = -EINVAL;
(1384)             goto vcpu_destroy;
(1385)        }
(1386)        // 检测分配的 vcpu id 是否已经存在
(1387)        kvm_for_each_vcpu(r, v, kvm)
(1388)             if (v->vcpu_id == id) {
(1389)                  r = -EEXIST;
(1390)                  goto vcpu_destroy;
(1391)             }
(1392)             /* kvm->vcpus[]数组包括该 vm 的所有 vcpu, 定义为 KVM_MAX_VCPUS 大小的数组.
     * 在 kvm 结构初始化时, 其中所有成员都初始化为 0, 在 vcpu 还没有
     * 分配之前, 如果不为 0, 那就是 bug 了.
     */
(1393)        BUG_ON(kvm->vcpus[atomic_read(&kvm->online_vcpus)]);
(1394)
(1395)        /* Now it's all set up, let userspace reach it */
		      // 增加 kvm 的引用计数
(1396)        kvm_get_kvm(kvm);
			 // 为新创建的 vcpu 创建对应的 fd, 以便于后续通过该 fd 进行 ioctl 操作
(1397)        r = create_vcpu_fd(vcpu);
(1398)        if (r < 0) {
(1399)             kvm_put_kvm(kvm);
(1400)             goto vcpu_destroy;
(1401)        }
(1402)        // 将新创建的 vcpu 填入 kvm->vcpus[]数组中
(1403)        kvm->vcpus[atomic_read(&kvm->online_vcpus)] = vcpu;
(1404)        smp_wmb(); // 内存屏障, 防止同时访问 kvm 结构时乱序
(1405)        atomic_inc(&kvm->online_vcpus); // 增加 online vcpu 的数量
(1406)
(1407)   #ifdef CONFIG_KVM_APIC_ARCHITECTURE
(1408)        if (kvm->bsp_vcpu_id == id)
(1409)             kvm->bsp_vcpu = vcpu;
(1410)   #endif
(1411)        mutex_unlock(&kvm->lock);
(1412)        // 架构相关的善后工作, 比如再次调用 vcpu_load, 以及 tsc 相关处理
(1413)        kvm_arch_vcpu_postcreate(vcpu);
(1414)        return r;
(1415)
(1416)   vcpu_destroy:
(1417)        mutex_unlock(&kvm->lock);
(1418)        kvm_arch_vcpu_destroy(vcpu);
(1419)        return r;
(1420)   }
```

#### 6.3.1.1. kvm_arch_vcpu_create 创建 kvm_vcpu

```cpp
int kvm_arch_vcpu_create(struct kvm_vcpu *vcpu)
{
        struct page *page;
        int r;

        if (!irqchip_in_kernel(vcpu->kvm) || kvm_vcpu_is_reset_bsp(vcpu))
                vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
        else
                vcpu->arch.mp_state = KVM_MP_STATE_UNINITIALIZED;

        kvm_set_tsc_khz(vcpu, max_tsc_khz);

        r = kvm_mmu_create(vcpu);
        if (r < 0)
                return r;

        if (irqchip_in_kernel(vcpu->kvm)) {
                r = kvm_create_lapic(vcpu, lapic_timer_advance_ns);
                if (r < 0)
                        goto fail_mmu_destroy;
                if (kvm_apicv_activated(vcpu->kvm))
                        vcpu->arch.apicv_active = true;
        } else
                static_key_slow_inc(&kvm_no_apic_vcpu);

        r = -ENOMEM;

        page = alloc_page(GFP_KERNEL | __GFP_ZERO);
        if (!page)
                goto fail_free_lapic;
        vcpu->arch.pio_data = page_address(page);

        vcpu->arch.mce_banks = kzalloc(KVM_MAX_MCE_BANKS * sizeof(u64) * 4,
                                       GFP_KERNEL_ACCOUNT);
        if (!vcpu->arch.mce_banks)
                goto fail_free_pio_data;
        vcpu->arch.mcg_cap = KVM_MAX_MCE_BANKS;

        if (!zalloc_cpumask_var(&vcpu->arch.wbinvd_dirty_mask,
                                GFP_KERNEL_ACCOUNT))
                goto fail_free_mce_banks;
        // 软件模拟
        if (!alloc_emulate_ctxt(vcpu))
                goto free_wbinvd_dirty_mask;

        vcpu->arch.user_fpu = kmem_cache_zalloc(x86_fpu_cache,
                                                GFP_KERNEL_ACCOUNT);
        if (!vcpu->arch.user_fpu) {
                pr_err("kvm: failed to allocate userspace's fpu\n");
                goto free_emulate_ctxt;
        }

        vcpu->arch.guest_fpu = kmem_cache_zalloc(x86_fpu_cache,
                                                 GFP_KERNEL_ACCOUNT);
        if (!vcpu->arch.guest_fpu) {
                pr_err("kvm: failed to allocate vcpu's fpu\n");
                goto free_user_fpu;
        }
        fx_init(vcpu);

        vcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;

        vcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);

        vcpu->arch.pat = MSR_IA32_CR_PAT_DEFAULT;

        kvm_async_pf_hash_reset(vcpu);
        kvm_pmu_init(vcpu);

        vcpu->arch.pending_external_vector = -1;
        vcpu->arch.preempted_in_kernel = false;

        kvm_hv_vcpu_init(vcpu);

        r = kvm_x86_ops.vcpu_create(vcpu);
        if (r)
                goto free_guest_fpu;

        vcpu->arch.arch_capabilities = kvm_get_arch_capabilities();
        vcpu->arch.msr_platform_info = MSR_PLATFORM_INFO_CPUID_FAULT;
        kvm_vcpu_mtrr_init(vcpu);
        vcpu_load(vcpu);
        kvm_vcpu_reset(vcpu, false);
        kvm_init_mmu(vcpu, false);
        vcpu_put(vcpu);
        return 0;

free_guest_fpu:
        kmem_cache_free(x86_fpu_cache, vcpu->arch.guest_fpu);
free_user_fpu:
        kmem_cache_free(x86_fpu_cache, vcpu->arch.user_fpu);
free_emulate_ctxt:
        kmem_cache_free(x86_emulator_cache, vcpu->arch.emulate_ctxt);
free_wbinvd_dirty_mask:
        free_cpumask_var(vcpu->arch.wbinvd_dirty_mask);
fail_free_mce_banks:
        kfree(vcpu->arch.mce_banks);
fail_free_pio_data:
        free_page((unsigned long)vcpu->arch.pio_data);
fail_free_lapic:
        kvm_free_lapic(vcpu);
fail_mmu_destroy:
        kvm_mmu_destroy(vcpu);
        return r;
}
```

首先, 在 1371 行, 调用`kvm_arch_vcpu_create`函数创建一个**kvm\_vcpu 结构体！！！**. 该创建内容**与架构相关**, 因此, 直接调用**kvm\_x86\_ops**中的`create_vcpu`方法执行.

(`kvm_arch_vcpu_create`在`arch/x86/kvm/x86.c`中, 调用`struct kvm_x86_ops vmx_x86_ops`(定义在 arch/x86/kvm/vmx.c)中的`create_vcpu`(即 vmx\_create\_vcpu, 在 arch/x86/kvm/vmx.c 中))

**每个 vCPU**的创建先 alloc 一个 struct **vcpu\_vmx**里面包含了 msr, vmcs, vcpu 等, 这里不是主要对 kvm\_vcpu 做初始化

虽然代码不同, 但是 AMD 平台和 Intel 平台实现的思路都是类似的:

- **先指定 CPUID 之后**,
- 接着**初始化 MSR！！！** 和**VMCS！！！等寄存器**, (**每个 VCPU 都有**)
- 最后完成**I/O**和**内存部分寄存器的初始化**, 为被**初次调度运行**做好准备.

`kvm_vm_ioctl()` --> `kvm_vm_ioctl_create_vcpu()` -->`kvm_arch_vcpu_create()`--> `kvm_x86_ops->vcpu_create()` --> `vmx_create_vcpu()`:

```cpp
/*
  * Intel x86 架构中创建并初始化 VCPU 中架构相关部分
  */
static int vmx_create_vcpu(struct kvm_vcpu *vcpu)
{
        struct vcpu_vmx *vmx;
        unsigned long *msr_bitmap;
        int i, cpu, err;

        BUILD_BUG_ON(offsetof(struct vcpu_vmx, vcpu) != 0);
        vmx = to_vmx(vcpu);

        err = -ENOMEM;

        vmx->vpid = allocate_vpid();

        /*
         * If PML is turned on, failure on enabling PML just results in failure
         * of creating the vcpu, therefore we can simplify PML logic (by
         * avoiding dealing with cases, such as enabling PML partially on vcpus
         * for the guest), etc.
         */
        if (enable_pml) {
                vmx->pml_pg = alloc_page(GFP_KERNEL_ACCOUNT | __GFP_ZERO);
                if (!vmx->pml_pg)
                        goto free_vpid;
        }

        BUILD_BUG_ON(ARRAY_SIZE(vmx_msr_index) != NR_SHARED_MSRS);

        for (i = 0; i < ARRAY_SIZE(vmx_msr_index); ++i) {
                u32 index = vmx_msr_index[i];
                u32 data_low, data_high;
                int j = vmx->nmsrs;

                if (rdmsr_safe(index, &data_low, &data_high) < 0)
                        continue;
                if (wrmsr_safe(index, data_low, data_high) < 0)
                        continue;

                vmx->guest_msrs[j].index = i;
                vmx->guest_msrs[j].data = 0;
                switch (index) {
                case MSR_IA32_TSX_CTRL:
                        /*
                         * No need to pass TSX_CTRL_CPUID_CLEAR through, so
                         * let's avoid changing CPUID bits under the host
                         * kernel's feet.
                         */
                        vmx->guest_msrs[j].mask = ~(u64)TSX_CTRL_CPUID_CLEAR;
                        break;
                default:
                        vmx->guest_msrs[j].mask = -1ull;
                        break;
                }
                ++vmx->nmsrs;
        }

        err = alloc_loaded_vmcs(&vmx->vmcs01);
        if (err < 0)
                goto free_pml;

        msr_bitmap = vmx->vmcs01.msr_bitmap;
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_IA32_TSC, MSR_TYPE_R);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_FS_BASE, MSR_TYPE_RW);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_GS_BASE, MSR_TYPE_RW);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_KERNEL_GS_BASE, MSR_TYPE_RW);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_IA32_SYSENTER_CS, MSR_TYPE_RW);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_IA32_SYSENTER_ESP, MSR_TYPE_RW);
        vmx_disable_intercept_for_msr(msr_bitmap, MSR_IA32_SYSENTER_EIP, MSR_TYPE_RW);
        if (kvm_cstate_in_guest(vcpu->kvm)) {
                vmx_disable_intercept_for_msr(msr_bitmap, MSR_CORE_C1_RES, MSR_TYPE_R);
                vmx_disable_intercept_for_msr(msr_bitmap, MSR_CORE_C3_RESIDENCY, MSR_TYPE_R);
                vmx_disable_intercept_for_msr(msr_bitmap, MSR_CORE_C6_RESIDENCY, MSR_TYPE_R);
                vmx_disable_intercept_for_msr(msr_bitmap, MSR_CORE_C7_RESIDENCY, MSR_TYPE_R);
        }
        vmx->msr_bitmap_mode = 0;

        vmx->loaded_vmcs = &vmx->vmcs01;
        cpu = get_cpu();
        vmx_vcpu_load(vcpu, cpu);
        vcpu->cpu = cpu;
        // 初始化 vmcs 域, 会调用 vmwrite
        init_vmcs(vmx);
        vmx_vcpu_put(vcpu);
        put_cpu();
        if (cpu_need_virtualize_apic_accesses(vcpu)) {
                err = alloc_apic_access_page(vcpu->kvm);
                if (err)
                        goto free_vmcs;
        }

        if (enable_ept && !enable_unrestricted_guest) {
                err = init_rmode_identity_map(vcpu->kvm);
                if (err)
                        goto free_vmcs;
        }

        if (nested)
                nested_vmx_setup_ctls_msrs(&vmx->nested.msrs,
                                           vmx_capability.ept);
        else
                memset(&vmx->nested.msrs, 0, sizeof(vmx->nested.msrs));

        vmx->nested.posted_intr_nv = -1;
        vmx->nested.current_vmptr = -1ull;

        vcpu->arch.microcode_version = 0x100000000ULL;
        vmx->msr_ia32_feature_control_valid_bits = FEAT_CTL_LOCKED;

        /*
         * Enforce invariant: pi_desc.nv is always either POSTED_INTR_VECTOR
         * or POSTED_INTR_WAKEUP_VECTOR.
         */
        vmx->pi_desc.nv = POSTED_INTR_VECTOR;
        vmx->pi_desc.sn = 1;

        vmx->ept_pointer = INVALID_PAGE;

        return 0;

free_vmcs:
        free_loaded_vmcs(vmx->loaded_vmcs);
free_pml:
        vmx_destroy_pml_buffer(vmx);
free_vpid:
        free_vpid(vmx->vpid);
        return err;
}

static struct kvm_vcpu *vmx_create_vcpu(struct kvm *kvm, unsigned int id)
{
    int err;
    // 从 slab 中, 分配 vcpu_vmx 结构体, 其中包括 VMX 技术硬件相关信息.
    struct vcpu_vmx *vmx = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
    int cpu;

    if (!vmx)
        return ERR_PTR(-ENOMEM);
    // 分配 vpid, vpid 为 VCPU 的唯一标识.
    allocate_vpid(vmx);
    // 初始化 vmx 中的 vcpu 结构
    err = kvm_vcpu_init(&vmx->vcpu, kvm, id);
    if (err)
        goto free_vcpu;
    // 分配 Guest 的 msr 寄存器保存区
    vmx->guest_msrs = kmalloc(PAGE_SIZE, GFP_KERNEL);
    err = -ENOMEM;
    if (!vmx->guest_msrs) {
        goto uninit_vcpu;
    }

    vmx->loaded_vmcs = &vmx->vmcs01;
    /*
     * 分配 VMCS 结构, 该结构用于保存虚拟机和虚拟机监控器的系统编程接口状态.
     * 当执行 VM exit 和 VM entry 操作时, VT-x 自动根据 VMCS 中的内容完成虚拟机和虚拟机监
     * 控器间的系统编程接口状态切换.
     */
    vmx->loaded_vmcs->vmcs = alloc_vmcs();
    if (!vmx->loaded_vmcs->vmcs)
        goto free_msrs;
    // 是否设置了 vmm_exclusive
    if (!vmm_exclusive)
        // VMXON 指令用于开启 VMX 模式
        kvm_cpu_vmxon(__pa(per_cpu(vmxarea, raw_smp_processor_id())));
    loaded_vmcs_init(vmx->loaded_vmcs);
    if (!vmm_exclusive)
        // VMXON 指令用于关闭 VMX 模式
        kvm_cpu_vmxoff();
    // 当前 cpu
    cpu = get_cpu();
    // KVM 虚拟机 VCPU 数据结构载入物理 CPU
    vmx_vcpu_load(&vmx->vcpu, cpu);
    vmx->vcpu.cpu = cpu;
    // 设置 vmx 相关信息
    err = vmx_vcpu_setup(vmx);
    vmx_vcpu_put(&vmx->vcpu);
    put_cpu();
    if (err)
        goto free_vmcs;
    if (vm_need_virtualize_apic_accesses(kvm)) {
        err = alloc_apic_access_page(kvm);
        if (err)
            goto free_vmcs;
    }
    // 是否支持 EPT
    if (enable_ept) {
        if (!kvm->arch.ept_identity_map_addr)
            kvm->arch.ept_identity_map_addr =
                VMX_EPT_IDENTITY_PAGETABLE_ADDR;
        err = -ENOMEM;
        // 分配 identity 页表
        if (alloc_identity_pagetable(kvm) != 0)
            goto free_vmcs;
        // 初始化 identity 页表
        if (!init_rmode_identity_map(kvm))
            goto free_vmcs;
    }

    vmx->nested.current_vmptr = -1ull;
    vmx->nested.current_vmcs12 = NULL;

    return &vmx->vcpu;

free_vmcs:
    free_loaded_vmcs(vmx->loaded_vmcs);
free_msrs:
    kfree(vmx->guest_msrs);
uninit_vcpu:
    kvm_vcpu_uninit(&vmx->vcpu);
free_vcpu:
    free_vpid(vmx);
    kmem_cache_free(kvm_vcpu_cache, vmx);
    return ERR_PTR(err);
}
```

见手册`2.6.5`和`3.1.1`

`init_vmcs(vmx);`中会初始化 vmcs, 其中会设置发生 vmexit 时的 vmm 入口地址.

```cpp
vmcs_write1(HOST_RIP, (unsigned long)vmx_vmexit); //vmexit 后 vmm 的入口地址
```

#### 6.3.1.2. kvm_arch_vcpu_setup 初始化 kvm_vcpu

其次, 在 1377 行调用**kvm\_arch\_vcpu\_setup**函数对**kvm\_vcpu**中的数据结构进行**初始化**.

这里将先调用**kvm\_x86\_ops**中的**put\_vcpu 函数**, 实现将**vCPU 的参数信息**加载入**CPU**中, 并且执行**MMU 初始化**和**CPU 复位操作**.

`kvm_vm_ioctl()` --> `kvm_vm_ioctl_create_vcpu()` --> `kvm_arch_vcpu_setup()`:

```cpp
int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
{
    int r;

    vcpu->arch.mtrr_state.have_fixed = 1;
    // KVM 虚拟机 VCPU 数据结构载入物理 CPU
    r = vcpu_load(vcpu);
    if (r)
        return r;
    // vcpu 重置, 包括相关寄存器、时钟、pmu 等, 最终调用 vmx_vcpu_reset
    kvm_vcpu_reset(vcpu);
    /*
     * 进行虚拟机 mmu 相关设置, 比如进行 ept 页表的相关初始工作或影子页表
     * 相关的设置.
     */
    r = kvm_mmu_setup(vcpu);
    vcpu_put(vcpu);

    return r;
}
```

`kvm_vm_ioctl()` --> `kvm_vm_ioctl_create_vcpu()` --> `kvm_arch_vcpu_setup()` --> `kvm_mmu_setup()` --> `init_kvm_mmu()`:

```cpp
static int init_kvm_mmu(struct kvm_vcpu *vcpu)
{
    if (mmu_is_nested(vcpu))
        // 嵌套虚拟化
        return init_kvm_nested_mmu(vcpu);
    else if (tdp_enabled)
        /*
        * EPT(Extended page table, Intel x86 硬件提供的内存虚拟化技术)相关初始化
        * 主要是设置一些函数指针, 其中比较重要的如缺页异常处理函数
        */
        return init_kvm_tdp_mmu(vcpu);
    else
        // 影子页表(软件实现内存虚拟化技术)相关初始化
        return init_kvm_softmmu(vcpu);
}
```

#### 6.3.1.3. vCPU 检测

在 1381~1391 行中, 进行了**两个检测**.

- 第一个是检测到如果**当前的 vCPU 数量**已经达到了**系统设置的上限** **KVM\_MAX\_VCPU**, 则将销毁刚才创建的实例.
- 第二个是如果**当前的 vCPU**创建出来已经加入了**某一个已有的 KVM 主机**, 则也将销毁该实例.

#### 6.3.1.4. 创建 vcpu_fd

然后, 在 1396~1405 行, 会创建**当前 vCPU** 对应的文件描述符 **vcpu\_fd**, 并且将**kvm\_vcpu**添加入**KVM**的**vCPU 数组**中.

这里有一个特别之处, 是使用了 atom\_read 和 atom\_inc 宏, 这两个宏能够保证在进行 KVM 虚拟机的 vCPU 添加时按照给定的顺序, 不会因为执行中途的中断、进程切换等方式导致添加到不正确的 kvm\_vcpu 数组中.

#### 6.3.1.5. 释放内核锁和返回 vcpu_fd

最后, 释放掉所有的内核锁, 完成本次 vCPU 的创建工作.

返回**vcpu\_fd**

# 7. vCPU 的运行

## 7.1. 基本原理

**虚拟机**运行于**qemu-kvm 的进程上下文**中, 从**硬件的角度**看, **虚拟机的运行过程**, 实质为**相关指令的执行过程**, **虚拟机编译**后的也就是相应的**CPU 指令序列**, 而**虚拟机的指令**跟**Host 机的指令**执行过程并没有太多的差别, 最关键的差别为"**敏感指令**"(通常为 IO、内存等关键操作)的执行, 这也是虚拟化实现的本质所在, 当在**虚拟机**中(**Guest 模式**)执行"**敏感指令**"时, 会触发(由硬件触发)**VM-exit**, 使当前 CPU 从**Guest 模式**(non-root 模式)切换到**root 模式**, 当前 CPU 的控制权随之转交给 VMM(Hypervisor, KVM 中即 Host), 由 VMM 进行相应的处理, 处理完成后再次通过应该硬件指令(如 VMLAUNCH), **重新进入到 Guest 模式**, 从而进入虚拟机运行环境中继续运行.

在创建完 **VM** 和 **vCPU** 并且完成了**初始化工作**之后, 就可以通过**调度程序调度执行**.

因为在 Linux 中, KVM 虚拟机作为一个**系统线程**运行, 因此, KVM 虚拟机的调度程序实际上也就是 Linux 的调度程序, 具体的调度将在后文 qemu 部分进行讨论, 在当前, **KVM 的调用**是从 ioctl 的**KVM\_RUN 指令**字开始的.

```cpp
// virt/kvm/kvm_main.c
static long kvm_vcpu_ioctl(struct file *filp,
			   unsigned int ioctl, unsigned long arg)
{
    case KVM_RUN:
		r = -EINVAL;
		if (arg)
			goto out;
		if (unlikely(vcpu->pid != current->pids[PIDTYPE_PID].pid)) {
			/* The thread running this VCPU changed. */
			struct pid *oldpid = vcpu->pid;
			struct pid *newpid = get_task_pid(current, PIDTYPE_PID);

			rcu_assign_pointer(vcpu->pid, newpid);
			if (oldpid)
				synchronize_rcu();
			put_pid(oldpid);
		}
		r = kvm_arch_vcpu_ioctl_run(vcpu, vcpu->run);
		trace_kvm_userspace_exit(vcpu->run->exit_reason, r);
		break;
}
```

`kvm_vcpu_ioctl`是 kvm ioctl VCPU 指令的入口, 传入的 fd 为`KVM_CREATE_VCPU`中**返回的 fd**. 主要针对**具体的 VCPU**进行**参数设置**. 如: 相关寄存器的读、写、中断控制等


**KVM\_RUN 指令字**针对**fd\_vcpu 描述符**操作, 当**vCPU 准备完成**之后, 即可通过该指令让虚拟机运行起来.

**虚拟机运行**的主要任务则是进行**上下文切换**. 上下文切换的内容较多, 通常包括**通用寄存器**、**浮点寄存器**、**段寄存器**、**控制寄存器**、**MSR**等, 在**KVM**中, 还包括**APIC 状态**、**TLB**等.

通常, 进行**上下文切换的过程**可以归纳为如下步骤.

1) **KVM 保存自己的上下文**.

2) KVM 通过使用将**kvm\_vcpu 结构体**中的**相关上下文**加载到**物理 CPU**中.

3) KVM 执行**kvm\_x86\_ops**中的**run\_vcpu 函数**, 调用具体的平台相关指令, 进入**虚拟机运行环境**中.

由此可见, 上下文切换次数过于频繁会带来不小的性能开销, 因此, 很有必要对这方面进行优化. 和操作系统进行**进程切换的思路**一样, KVM 使用**Lazy Save/Restore** 的方法进行优化. 其基本思想是**尽量不要对寄存器进行恢复/保存操作**, 直到必须要这么做的时候, 才进行类似的操作.

## 7.2. 整体流程

**执行 vCPU**的请求首先发送到 `kvm_vcpu_ioctl` 函数中, 然后**加载 vCPU 参数**, 调用 `kvm_arch_vcpu_ioctl_run` 函数进入**具体的 vCPU 运行**环节. (`arch/x86/kvm/x86.c`)

```cpp
kvm_arch_vcpu_ioctl_run()                	// vcpu 运行
 ├─ vcpu_load(vcpu)                          //  KVM 虚拟机 VCPU 数据结构载入物理 CPU
 ├─ kvm_sigset_activate(vcpu)                // 信号屏蔽, 防止干扰
 ├─ kvm_load_guset_fpu()         			//  加载虚拟机的 fpu
 │   ├─ kvm_save_current_fpu(vcpu->arch.user_fpu); // 将当前进程的 fpu 赋值给 vcpu
 │   ├─ __copy_kernel_to_fpregs(); //
 │   └─ fpregs_mark_activate(); //
 ├─ vcpu_run() // 死循环进入 vcpu_enter_guest, arch/x86/kvm/x86.c
 │   ├─ for(;;) { // 循环受 vcpu_enter_guest()返回值/系统信号控制, 只有异常/有外部信号才退出循环
 │   │   ├─ int r = vcpu_enter_guest()      // 物理 CPU 进入 guest 模式, 返回 1 表明不用退到 userspace, 否则退到 userspace, arch/x86/kvm/x86.c
 │   │   │   ├─ kvm_request_pending(); // 进入 Guest 模式前先处理相关挂起的请求(vcpu->requests), 每个有相应处理
 │   │   │   ├─ kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win  // 检查是否有事件请求
 │   │   │   │   ├─ ++vcpu->stat.req_event;      //
 │   │   │   │   ├─ inject_pending_event(vcpu);      // 注入阻塞的事件, 中断, 异常和 nmi 等
 │   │   │   ├─ kvm_mmu_reload(vcpu); // 加载 mmu
 │   │   │   ├─ kvm_x86_ops.prepare_guest_switch(vcpu); // // 进入 Guest 前期准备, 架构相关, 准备陷入到 guest, 保存 vmexit 时加载的 host 状态
 │   │   │   ├─ local_irq_disable();  // 屏蔽中断响应, 准备进入 guest
 │   │   │   ├─ vcpu->mode = IN_GUEST_MODE;  // 将 vcpu 模式设为 guest 模式
 │   │   │   ├─ guest_enter_irqoff();  // 计算虚拟机系统时间和上下文切换
 │   │   │   ├─ exit_fastpath = static_call(kvm_x86_run)(vcpu);  	// 开始运行 guest, 会调用 vmx_vcpu_run
 │   │   │   │   ├─ __vmx_vcpu_run() // 调用汇编代码, vmlaunch 指令, 再往后就是 vm-exit 的流程了
 │   │   │   │   ├─ vmx->exit_reason =  vmx->fail ? 0xdead : vmcs_read32(VM_EXIT_REASON);  // 获取 vm-exit 原因
 │   │   │   │   ├─ vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD); // 获取
 │   │   │   │   ├─ vmx_recover_nmi_blocking(vmx); // 恢复系统 NMI 中断
 │   │   │   │   └─ vmx_complete_interrupts(vmx);  // 恢复中断
 │   │   │   ├─ hw_breakpoint_restore()	// 恢复硬件断点
 │   │   │   ├─ vcpu->mode = OUTSIDE_GUEST_MODE;	// vcpu mode
 │   │   │   ├─ kvm_x86_ops.handle_exit_irqoff(vcpu);	// vcpu mode
 │   │   │   ├─ local_irq_enable();	// 打开中断
 │   │   │   ├─ preempt_enable();	// 打开抢占
 │   │   │   └─ static_call(kvm_x86_handle_exit)(vcpu, exit_fastpath)	// vmexit 的处理, 由 vmx_handle_exit 实现, 主要设置 vcpu->run->exit_reason, 让外部感知退出原因, 并对应处理.
 │   │   ├─ if (r <= 0) break; // 退出循环
 │   └─ }  // 循环
 ├─ kvm_put_guest_fpu(); //
 ├─ post_kvm_run_save(); //
 ├─ kvm_sigset_deactivate(); //
 └─ vcpu_put(); //
```

## 7.3. 代码分析

```cpp
// include/linux/kvm_host.h
enum {
        // host 模式
        OUTSIDE_GUEST_MODE,
        // 虚拟机模式
        IN_GUEST_MODE,
        // 表明 ipi 将很快发生
        EXITING_GUEST_MODE,
        READING_SHADOW_PAGE_TABLES,
};
```

```cpp
// 如果 fastpath 完成, 那么我们可以直接跳过 exit handler 的调用处理和整个 run loop, 从而直接进入 guest, 但是在一些条件下不能立即进入 guest.
// 这个函数就是不能立即进入 guest 的条件
// We need to check some conditions before enter guest again immediately,
// we skip invoking the exit handler and go through full run loop if complete fastpath but there is stuff preventing we enter guest again immediately.
bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu)
{
	return vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu) ||
		need_resched() || signal_pending(current);
}
EXPORT_SYMBOL_GPL(kvm_vcpu_exit_request);
```

```cpp
// 运行 VCPU(即运行虚拟机)的入口函数
int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)
{
        int r;
        // KVM 虚拟机 VCPU 数据结构载入物理 CPU
        vcpu_load(vcpu);
        // 保证在 vCPU 的初始化过程中, 不会因为来自其他线程的信号干扰而中断
        kvm_sigset_activate(vcpu);
        kvm_load_guest_fpu(vcpu);
        // 当 vcpu 状态为 KVM_MP_STATE_UNINITIALIZED 时
        if (unlikely(vcpu->arch.mp_state == KVM_MP_STATE_UNINITIALIZED)) {
                if (kvm_run->immediate_exit) {
                        r = -EINTR;
                        goto out;
                }
                // 阻塞 VCPU, 其实就是 schdule()调度出去, 但在有特殊情况时(比如有挂起的定时器或信号时), 不进行调度而直接退出
                kvm_vcpu_block(vcpu);
                kvm_apic_accept_events(vcpu);
                kvm_clear_request(KVM_REQ_UNHALT, vcpu);
                r = -EAGAIN;
                if (signal_pending(current)) {
                        r = -EINTR;
                        vcpu->run->exit_reason = KVM_EXIT_INTR;
                        ++vcpu->stat.signal_exits;
                }
                goto out;
        }

        if (vcpu->run->kvm_valid_regs & ~KVM_SYNC_X86_VALID_FIELDS) {
                r = -EINVAL;
                goto out;
        }

        if (vcpu->run->kvm_dirty_regs) {
                r = sync_regs(vcpu);
                if (r != 0)
                        goto out;
        }

        /* re-sync apic's tpr */
        if (!lapic_in_kernel(vcpu)) {
                if (kvm_set_cr8(vcpu, kvm_run->cr8) != 0) {
                        r = -EINVAL;
                        goto out;
                }
        }

        if (unlikely(vcpu->arch.complete_userspace_io)) {
                int (*cui)(struct kvm_vcpu *) = vcpu->arch.complete_userspace_io;
                vcpu->arch.complete_userspace_io = NULL;
                r = cui(vcpu);
                if (r <= 0)
                        goto out;
        } else
                WARN_ON(vcpu->arch.pio.count || vcpu->mmio_needed);

        if (kvm_run->immediate_exit)
                r = -EINTR;
        else
                r = vcpu_run(vcpu);

out:
        kvm_put_guest_fpu(vcpu);
        if (vcpu->run->kvm_valid_regs)
                store_regs(vcpu);
        post_kvm_run_save(vcpu);
        kvm_sigset_deactivate(vcpu);

        vcpu_put(vcpu);
        return r;
}
```

1) 通过调用**sigprocmask 函数**, 保证在**vCPU 的初始化**过程中, 不会因为来自**其他线程的信号干扰而中断**.

3) 配置**APIC**和**mmio**的**中断信息**.

4) 对要进入的虚拟机进行一些**关键指令的测试**, 在测试中主要针对**内存读/写**情况进行测试.

5) 将**vCPU**中保存的**上下文信息(寄存器状态等**)写入**指定的位置**.

6) 接下来才开始实质性的工作, 调用`vcpu_run`函数进行后续处理.

`vcpu_run`函数的代码如下.

```cpp
// arch/x86/kvm/x86.c
static int vcpu_run(struct kvm_vcpu *vcpu)
{
        int r;
        struct kvm *kvm = vcpu->kvm;

        vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
        vcpu->arch.l1tf_flush_l1d = true;

        for (;;) {
                // 判断 vcpu 状态, KVM_MP_STATE_RUNNABLE
                if (kvm_vcpu_running(vcpu)) {
                        /* 进入 Guest 模式, 最终通过 VMLAUNCH 指令实现*/
                        r = vcpu_enter_guest(vcpu);
                } else {
                        r = vcpu_block(kvm, vcpu);
                }

                if (r <= 0)
                        break;

                kvm_clear_request(KVM_REQ_PENDING_TIMER, vcpu);
                if (kvm_cpu_has_pending_timer(vcpu))
                        kvm_inject_pending_timer_irqs(vcpu);

                if (dm_request_for_irq_injection(vcpu) &&
                        kvm_vcpu_ready_for_interrupt_injection(vcpu)) {
                        r = 0;
                        vcpu->run->exit_reason = KVM_EXIT_IRQ_WINDOW_OPEN;
                        ++vcpu->stat.request_irq_exits;
                        break;
                }

                kvm_check_async_pf_completion(vcpu);

                if (signal_pending(current)) {
                        r = -EINTR;
                        vcpu->run->exit_reason = KVM_EXIT_INTR;
                        ++vcpu->stat.signal_exits;
                        break;
                }
                /*这是 kvm 中的一个调度时机点, 即选择新 VCPU 运行的时机点*/
                if (need_resched()) {
                        srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);
                        cond_resched();
                        vcpu->srcu_idx = srcu_read_lock(&kvm->srcu);
                }
        }

        srcu_read_unlock(&kvm->srcu, vcpu->srcu_idx);

        return r;
}
```

正常情况下, 将 `kvm_vcp->arch.mp_state` 的取值作为**单机未运行**的取值: `KVM_MP_STATE_RUNNABLE`; 如果 vCPU 在 VM 中处于**其他状态**, 则会**出错**. 在运行中有一个**循环**, 直到确认了 `vcpu_enter_guest()` 函数执行完毕, 即**物理 CPU 进入了 GUEST 状态**并且执行完成后, 才会执行下一步操作.

`vcpu_run` 最终调用 `vcpu_enter_guest`, 该函数实现了**进入 Guest**, 并执行**Guest OS 具体指令**的操作. 对应于 Intel 平台, 该函数为`vmx_vcpu_run`(设置**Guest CR3**和**其他寄存器**、**EPT/影子页表相关设置**、汇编代码 VMLAUNCH 切换到非根模式, 执行 Guest 目标代码).

`vcpu_enter_guest`返回 **1** 的话表明不用退出到 userspace 而继续虚拟机运行循环, 否则, **返回该值给 userspace**.

```cpp
// arch/x86/kvm/x86.c
/*
 * Returns 1 to let vcpu_run() continue the guest execution loop without
 * exiting to the userspace.  Otherwise, the value will be returned to the
 * userspace.
 */
static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
{
        int r;
        bool req_int_win =
                dm_request_for_irq_injection(vcpu) &&
                kvm_cpu_accept_dm_intr(vcpu);
        enum exit_fastpath_completion exit_fastpath = EXIT_FASTPATH_NONE;

        bool req_immediate_exit = false;
         /*进入 Guest 模式前先处理相关挂起的请求*/
        if (kvm_request_pending(vcpu)) {
                if (kvm_check_request(KVM_REQ_GET_VMCS12_PAGES, vcpu)) {
                        if (unlikely(!kvm_x86_ops.get_vmcs12_pages(vcpu))) {
                                r = 0;
                                goto out;
                        }
                }
                /*卸载 MMU*/
                if (kvm_check_request(KVM_REQ_MMU_RELOAD, vcpu))
                        kvm_mmu_unload(vcpu);
                /*定时器迁移*/
                if (kvm_check_request(KVM_REQ_MIGRATE_TIMER, vcpu))
                        __kvm_migrate_timers(vcpu);
                /*主时钟更新*/
                if (kvm_check_request(KVM_REQ_MASTERCLOCK_UPDATE, vcpu))
                        kvm_gen_update_masterclock(vcpu->kvm);
                /*全局时钟更新*/
                if (kvm_check_request(KVM_REQ_GLOBAL_CLOCK_UPDATE, vcpu))
                        kvm_gen_kvmclock_update(vcpu);
                /*虚拟机时钟更新*/
                if (kvm_check_request(KVM_REQ_CLOCK_UPDATE, vcpu)) {
                        r = kvm_guest_time_update(vcpu);
                        if (unlikely(r))
                                goto out;
                }
                /*更新 mmu*/
                if (kvm_check_request(KVM_REQ_MMU_SYNC, vcpu))
                        kvm_mmu_sync_roots(vcpu);
                if (kvm_check_request(KVM_REQ_LOAD_MMU_PGD, vcpu))
                        kvm_mmu_load_pgd(vcpu);
                /*刷新 TLB*/
                if (kvm_check_request(KVM_REQ_TLB_FLUSH, vcpu)) {
                        kvm_vcpu_flush_tlb_all(vcpu);

                        /* Flushing all ASIDs flushes the current ASID... */
                        kvm_clear_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu);
                }
                if (kvm_check_request(KVM_REQ_TLB_FLUSH_CURRENT, vcpu))
                        kvm_vcpu_flush_tlb_current(vcpu);
                if (kvm_check_request(KVM_REQ_HV_TLB_FLUSH, vcpu))
                        kvm_vcpu_flush_tlb_guest(vcpu);

                if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
                        vcpu->run->exit_reason = KVM_EXIT_TPR_ACCESS;
                        r = 0;
                        goto out;
                }
                if (kvm_check_request(KVM_REQ_TRIPLE_FAULT, vcpu)) {
                        vcpu->run->exit_reason = KVM_EXIT_SHUTDOWN;
                        vcpu->mmio_needed = 0;
                        r = 0;
                        goto out;
                }
                if (kvm_check_request(KVM_REQ_APF_HALT, vcpu)) {
                        /* Page is swapped out. Do synthetic halt */
                        vcpu->arch.apf.halted = true;
                        r = 1;
                        goto out;
                }
                if (kvm_check_request(KVM_REQ_STEAL_UPDATE, vcpu))
                        record_steal_time(vcpu);
                if (kvm_check_request(KVM_REQ_SMI, vcpu))
                        process_smi(vcpu);
                if (kvm_check_request(KVM_REQ_NMI, vcpu))
                        process_nmi(vcpu);
                if (kvm_check_request(KVM_REQ_PMU, vcpu))
                        kvm_pmu_handle_event(vcpu);
                if (kvm_check_request(KVM_REQ_PMI, vcpu))
                        kvm_pmu_deliver_pmi(vcpu);
                if (kvm_check_request(KVM_REQ_IOAPIC_EOI_EXIT, vcpu)) {
                        BUG_ON(vcpu->arch.pending_ioapic_eoi > 255);
                        if (test_bit(vcpu->arch.pending_ioapic_eoi,
                                     vcpu->arch.ioapic_handled_vectors)) {
                                vcpu->run->exit_reason = KVM_EXIT_IOAPIC_EOI;
                                vcpu->run->eoi.vector =
                                                vcpu->arch.pending_ioapic_eoi;
                                r = 0;
                                goto out;
                        }
                }
                if (kvm_check_request(KVM_REQ_SCAN_IOAPIC, vcpu))
                        vcpu_scan_ioapic(vcpu);
                if (kvm_check_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu))
                        vcpu_load_eoi_exitmap(vcpu);
                if (kvm_check_request(KVM_REQ_APIC_PAGE_RELOAD, vcpu))
                        kvm_vcpu_reload_apic_access_page(vcpu);
                if (kvm_check_request(KVM_REQ_HV_CRASH, vcpu)) {
                        vcpu->run->exit_reason = KVM_EXIT_SYSTEM_EVENT;
                        vcpu->run->system_event.type = KVM_SYSTEM_EVENT_CRASH;
                        r = 0;
                        goto out;
                }
                if (kvm_check_request(KVM_REQ_HV_RESET, vcpu)) {
                        vcpu->run->exit_reason = KVM_EXIT_SYSTEM_EVENT;
                        vcpu->run->system_event.type = KVM_SYSTEM_EVENT_RESET;
                        r = 0;
                        goto out;
                }
                if (kvm_check_request(KVM_REQ_HV_EXIT, vcpu)) {
                        vcpu->run->exit_reason = KVM_EXIT_HYPERV;
                        vcpu->run->hyperv = vcpu->arch.hyperv.exit;
                        r = 0;
                        goto out;
                }

                /*
                 * KVM_REQ_HV_STIMER has to be processed after
                 * KVM_REQ_CLOCK_UPDATE, because Hyper-V SynIC timers
                 * depend on the guest clock being up-to-date
                 */
                if (kvm_check_request(KVM_REQ_HV_STIMER, vcpu))
                        kvm_hv_process_stimers(vcpu);
                if (kvm_check_request(KVM_REQ_APICV_UPDATE, vcpu))
                        kvm_vcpu_update_apicv(vcpu);
        }
        //检查是否有事件请求
        if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win) {
                ++vcpu->stat.req_event;
                kvm_apic_accept_events(vcpu);
                if (vcpu->arch.mp_state == KVM_MP_STATE_INIT_RECEIVED) {
                        r = 1;
                        goto out;
                }
                // 注入阻塞的事件, 中断, 异常和 nmi 等
                // 注入中断在 vcpu 加载到真实 cpu 上后, 相当于某些位已经被设置
                if (inject_pending_event(vcpu) != 0)
                        req_immediate_exit = true;
                else {
                        /* Enable SMI/NMI/IRQ window open exits if needed.
                         *
                         * SMIs have three cases:
                         * 1) They can be nested, and then there is nothing to
                         *    do here because RSM will cause a vmexit anyway.
                         * 2) There is an ISA-specific reason why SMI cannot be
                         *    injected, and the moment when this changes can be
                         *    intercepted.
                         * 3) Or the SMI can be pending because
                         *    inject_pending_event has completed the injection
                         *    of an IRQ or NMI from the previous vmexit, and
                         *    then we request an immediate exit to inject the
                         *    SMI.
                         */
                        if (vcpu->arch.smi_pending && !is_smm(vcpu))
                                if (!kvm_x86_ops.enable_smi_window(vcpu))
                                        req_immediate_exit = true;
                        /* 使能 NMI/IRQ window, 参见 Intel64 System Programming Guide 25.3 节(P366)
                         * 当使能了 interrupt-window exiting 或 NMI-window exiting(由 VMCS 中相关字段控制),
                         * 表示在刚进入虚拟机后, 就会立刻因为有 pending 或注入的中断导致 VM-exit
                         */
                        if (vcpu->arch.nmi_pending)
                                kvm_x86_ops.enable_nmi_window(vcpu);
                        if (kvm_cpu_has_injectable_intr(vcpu) || req_int_win)
                                kvm_x86_ops.enable_irq_window(vcpu);
                        WARN_ON(vcpu->arch.exception.pending);
                }

                if (kvm_lapic_enabled(vcpu)) {
                        update_cr8_intercept(vcpu);
                        kvm_lapic_sync_to_vapic(vcpu);
                }
        }
        // 加载 MMU
        r = kvm_mmu_reload(vcpu);
        if (unlikely(r)) {
                goto cancel_injection;
        }

        preempt_disable();
        // 进入 Guest 前期准备, 架构相关
        kvm_x86_ops.prepare_guest_switch(vcpu);

        /*
         * Disable IRQs before setting IN_GUEST_MODE.  Posted interrupt
         * IPI are then delayed after guest entry, which ensures that they
         * result in virtual interrupt delivery.
         */
        // 关闭中断了, 外部中断全部不接收
        local_irq_disable();
        vcpu->mode = IN_GUEST_MODE;

        srcu_read_unlock(&vcpu->kvm->srcu, vcpu->srcu_idx);

        /*
         * 1) We should set ->mode before checking ->requests.  Please see
         * the comment in kvm_vcpu_exiting_guest_mode().
         *
         * 2) For APICv, we should set ->mode before checking PID.ON. This
         * pairs with the memory barrier implicit in pi_test_and_set_on
         * (see vmx_deliver_posted_interrupt).
         *
         * 3) This also orders the write to mode from any reads to the page
         * tables done while the VCPU is running.  Please see the comment
         * in kvm_flush_remote_tlbs.
         */
        smp_mb__after_srcu_read_unlock();

        /*
         * This handles the case where a posted interrupt was
         * notified with kvm_vcpu_kick.
         */
        if (kvm_lapic_enabled(vcpu) && vcpu->arch.apicv_active)
                kvm_x86_ops.sync_pir_to_irr(vcpu);
        /*
         * 如果 VCPU 处于 EXITING_GUEST_MODE 或者 vcpu->requests(?)或者需要调度或者
         * 有挂起的信号, 则放弃
         */
        if (vcpu->mode == EXITING_GUEST_MODE || kvm_request_pending(vcpu)
            || need_resched() || signal_pending(current)) {
                vcpu->mode = OUTSIDE_GUEST_MODE;
                smp_wmb();
                // 打开外部中断
                local_irq_enable();
                preempt_enable();
                vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);
                r = 1;
                goto cancel_injection;
        }
        // req_immediate_exit 在前面使能 NMI/IRQ window 失败时设置, 此时需要立即退出, 触发重新调度
        if (req_immediate_exit) {
                kvm_make_request(KVM_REQ_EVENT, vcpu);
                kvm_x86_ops.request_immediate_exit(vcpu);
        }

        trace_kvm_entry(vcpu->vcpu_id);
        // 计算虚拟机的 enter 时间
        guest_enter_irqoff();

        fpregs_assert_state_consistent();
        if (test_thread_flag(TIF_NEED_FPU_LOAD))
                switch_fpu_return();
        // 调试相关
        if (unlikely(vcpu->arch.switch_db_regs)) {
                set_debugreg(0, 7);
                set_debugreg(vcpu->arch.eff_db[0], 0);
                set_debugreg(vcpu->arch.eff_db[1], 1);
                set_debugreg(vcpu->arch.eff_db[2], 2);
                set_debugreg(vcpu->arch.eff_db[3], 3);
                set_debugreg(vcpu->arch.dr6, 6);
                vcpu->arch.switch_db_regs &= ~KVM_DEBUGREG_RELOAD;
        }
        // 调用架构相关的 run 接口(vmx_vcpu_run), 进入 Guest 模式
        kvm_x86_ops.run(vcpu);
        // 此处开始, 说明已经发生了 VM-exit, 退出了 Guest 模式
        /*
         * Do this here before restoring debug registers on the host.  And
         * since we do this before handling the vmexit, a DR access vmexit
         * can (a) read the correct value of the debug registers, (b) set
         * KVM_DEBUGREG_WONT_EXIT again.
         */
        if (unlikely(vcpu->arch.switch_db_regs & KVM_DEBUGREG_WONT_EXIT)) {
                WARN_ON(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP);
                kvm_x86_ops.sync_dirty_debug_regs(vcpu);
                kvm_update_dr0123(vcpu);
                kvm_update_dr6(vcpu);
                kvm_update_dr7(vcpu);
                vcpu->arch.switch_db_regs &= ~KVM_DEBUGREG_RELOAD;
        }

        /*
         * If the guest has used debug registers, at least dr7
         * will be disabled while returning to the host.
         * If we don't have active breakpoints in the host, we don't
         * care about the messed up debug address registers. But if
         * we have some of them active, restore the old state.
         */
        if (hw_breakpoint_active())
                hw_breakpoint_restore();
        /*记录 Guest 退出前的 TSC 时钟*/
        vcpu->arch.last_guest_tsc = kvm_read_l1_tsc(vcpu, rdtsc());
        // 设置模式
        vcpu->mode = OUTSIDE_GUEST_MODE;
        smp_wmb();

        kvm_x86_ops.handle_exit_irqoff(vcpu, &exit_fastpath);

        /*
         * Consume any pending interrupts, including the possible source of
         * VM-Exit on SVM and any ticks that occur between VM-Exit and now.
         * An instruction is required after local_irq_enable() to fully unblock
         * interrupts on processors that implement an interrupt shadow, the
         * stat.exits increment will do nicely.
         */
        kvm_before_interrupt(vcpu);
        // 打开中断
        local_irq_enable();
        ++vcpu->stat.exits;
        // 关闭中断
        local_irq_disable();
        kvm_after_interrupt(vcpu);
        // 计算虚拟机的退出时间
        guest_exit_irqoff();
        if (lapic_in_kernel(vcpu)) {
                s64 delta = vcpu->arch.apic->lapic_timer.advance_expire_delta;
                if (delta != S64_MIN) {
                        trace_kvm_wait_lapic_expire(vcpu->vcpu_id, delta);
                        vcpu->arch.apic->lapic_timer.advance_expire_delta = S64_MIN;
                }
        }
        // 开中断
        local_irq_enable();
        // 开抢占
        preempt_enable();

        vcpu->srcu_idx = srcu_read_lock(&vcpu->kvm->srcu);

        /*
         * Profile KVM exit RIPs:
         * Profile(采样计数, 用于性能分析和调优)相关
         */
        if (unlikely(prof_on == KVM_PROFILING)) {
                unsigned long rip = kvm_rip_read(vcpu);
                profile_hit(KVM_PROFILING, (void *)rip);
        }

        if (unlikely(vcpu->arch.tsc_always_catchup))
                kvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);

        if (vcpu->arch.apic_attention)
                kvm_lapic_sync_from_vapic(vcpu);
        /*
         * 调用 vmx_handle_exit()处理虚拟机异常, 异常原因及其它关键信息
         * 已经在之前获取.
         */
        r = kvm_x86_ops.handle_exit(vcpu, exit_fastpath);
        return r;

cancel_injection:
        kvm_x86_ops.cancel_injection(vcpu);
        if (unlikely(vcpu->arch.apic_attention))
                kvm_lapic_sync_from_vapic(vcpu);
out:
        return r;
}
```



```cpp
// 注入 pending 事件
static int inject_pending_event(struct kvm_vcpu *vcpu)
{
        int r;

        /* try to reinject previous events if any */
        // 如果之前的事件
        if (vcpu->arch.exception.injected)
                kvm_x86_ops.queue_exception(vcpu);
        /*
         * Do not inject an NMI or interrupt if there is a pending
         * exception.  Exceptions and interrupts are recognized at
         * instruction boundaries, i.e. the start of an instruction.
         * Trap-like exceptions, e.g. #DB, have higher priority than
         * NMIs and interrupts, i.e. traps are recognized before an
         * NMI/interrupt that's pending on the same instruction.
         * Fault-like exceptions, e.g. #GP and #PF, are the lowest
         * priority, but are only generated (pended) during instruction
         * execution, i.e. a pending fault-like exception means the
         * fault occurred on the *previous* instruction and must be
         * serviced prior to recognizing any new events in order to
         * fully complete the previous instruction.
         */
        else if (!vcpu->arch.exception.pending) {
                if (vcpu->arch.nmi_injected)
                        kvm_x86_ops.set_nmi(vcpu);
                else if (vcpu->arch.interrupt.injected)
                        //
                        kvm_x86_ops.set_irq(vcpu);
        }

        WARN_ON_ONCE(vcpu->arch.exception.injected &&
                     vcpu->arch.exception.pending);

        /*
         * Call check_nested_events() even if we reinjected a previous event
         * in order for caller to determine if it should require immediate-exit
         * from L2 to L1 due to pending L1 events which require exit
         * from L2 to L1.
         */
        if (is_guest_mode(vcpu)) {
                r = kvm_x86_ops.nested_ops->check_events(vcpu);
                if (r != 0)
                        return r;
        }

        /* try to inject new event if pending */
        if (vcpu->arch.exception.pending) {
                trace_kvm_inj_exception(vcpu->arch.exception.nr,
                                        vcpu->arch.exception.has_error_code,
                                        vcpu->arch.exception.error_code);

                vcpu->arch.exception.pending = false;
                vcpu->arch.exception.injected = true;

                if (exception_type(vcpu->arch.exception.nr) == EXCPT_FAULT)
                        __kvm_set_rflags(vcpu, kvm_get_rflags(vcpu) |
                                             X86_EFLAGS_RF);

                if (vcpu->arch.exception.nr == DB_VECTOR) {
                        /*
                         * This code assumes that nSVM doesn't use
                         * check_nested_events(). If it does, the
                         * DR6/DR7 changes should happen before L1
                         * gets a #VMEXIT for an intercepted #DB in
                         * L2.  (Under VMX, on the other hand, the
                         * DR6/DR7 changes should not happen in the
                         * event of a VM-exit to L1 for an intercepted
                         * #DB in L2.)
                         */
                        kvm_deliver_exception_payload(vcpu);
                        if (vcpu->arch.dr7 & DR7_GD) {
                                vcpu->arch.dr7 &= ~DR7_GD;
                                kvm_update_dr7(vcpu);
                        }
                }

                kvm_x86_ops.queue_exception(vcpu);
        }

        /* Don't consider new event if we re-injected an event */
        if (kvm_event_needs_reinjection(vcpu))
                return 0;

        if (vcpu->arch.smi_pending &&
            kvm_x86_ops.smi_allowed(vcpu, true)) {
                vcpu->arch.smi_pending = false;
                ++vcpu->arch.smi_count;
                enter_smm(vcpu);
        } else if (vcpu->arch.nmi_pending &&
                   kvm_x86_ops.nmi_allowed(vcpu, true)) {
                --vcpu->arch.nmi_pending;
                vcpu->arch.nmi_injected = true;
                kvm_x86_ops.set_nmi(vcpu);
        } else if (kvm_cpu_has_injectable_intr(vcpu) &&
                   kvm_x86_ops.interrupt_allowed(vcpu, true)) {
                // 获得当前中断号, 将中断记录到 vcpu 中
                kvm_queue_interrupt(vcpu, kvm_cpu_get_interrupt(vcpu), false);
                // 写入 vmcs 结构中
                kvm_x86_ops.set_irq(vcpu);
        }

        return 0;
}
```

见上面注释, 调用架构相关的 run 接口(`vmx_vcpu_run`), 进入 Guest 模式

```cpp
/*
 * 运行虚拟机, 进入 Guest 模式, 即 non root 模式
 */
static void vmx_vcpu_run(struct kvm_vcpu *vcpu)
{
        struct vcpu_vmx *vmx = to_vmx(vcpu);
        unsigned long cr3, cr4;
        // nmi 注入?跟 nmi_watchdog 相关?
        /* Record the guest's net vcpu time for enforced NMI injections. */
        if (unlikely(!enable_vnmi &&
                     vmx->loaded_vmcs->soft_vnmi_blocked))
                vmx->loaded_vmcs->entry_time = ktime_get();

        /* Don't enter VMX if guest state is invalid, let the exit handler
           start emulation until we arrive back to a valid state */
        if (vmx->emulation_required)
                return;

        if (vmx->ple_window_dirty) {
                vmx->ple_window_dirty = false;
                vmcs_write32(PLE_WINDOW, vmx->ple_window);
        }

        /*
         * We did this in prepare_switch_to_guest, because it needs to
         * be within srcu_read_lock.
         */
        WARN_ON_ONCE(vmx->nested.need_vmcs12_to_shadow_sync);
        // 写入 Guest 的 RSP 寄存器信息至 VMCS 相关位置中
        if (kvm_register_is_dirty(vcpu, VCPU_REGS_RSP))
                vmcs_writel(GUEST_RSP, vcpu->arch.regs[VCPU_REGS_RSP]);
        // 写入 Guest 的 RIP 寄存器信息至 VMCS 相关位置中
        if (kvm_register_is_dirty(vcpu, VCPU_REGS_RIP))
                vmcs_writel(GUEST_RIP, vcpu->arch.regs[VCPU_REGS_RIP]);

        cr3 = __get_current_cr3_fast();
        if (unlikely(cr3 != vmx->loaded_vmcs->host_state.cr3)) {
                vmcs_writel(HOST_CR3, cr3);
                vmx->loaded_vmcs->host_state.cr3 = cr3;
        }

        cr4 = cr4_read_shadow();
        if (unlikely(cr4 != vmx->loaded_vmcs->host_state.cr4)) {
                vmcs_writel(HOST_CR4, cr4);
                vmx->loaded_vmcs->host_state.cr4 = cr4;
        }

        /* When single-stepping over STI and MOV SS, we must clear the
         * corresponding interruptibility bits in the guest state. Otherwise
         * vmentry fails as it then expects bit 14 (BS) in pending debug
         * exceptions being set, but that's not correct for the guest debugging
         * case. */
        // 单步调试时, 需要禁用 Guest 中断
        if (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)
                vmx_set_interrupt_shadow(vcpu, 0);

        kvm_load_guest_xsave_state(vcpu);

        if (static_cpu_has(X86_FEATURE_PKU) &&
            kvm_read_cr4_bits(vcpu, X86_CR4_PKE) &&
            vcpu->arch.pkru != vmx->host_pkru)
                __write_pkru(vcpu->arch.pkru);

        pt_guest_enter(vmx);

        if (vcpu_to_pmu(vcpu)->version)
                atomic_switch_perf_msrs(vmx);
        atomic_switch_umwait_control_msr(vmx);

        if (enable_preemption_timer)
                vmx_update_hv_timer(vcpu);

        if (lapic_in_kernel(vcpu) &&
                vcpu->arch.apic->lapic_timer.timer_advance_ns)
                kvm_wait_lapic_expire(vcpu);

        /*
         * If this vCPU has touched SPEC_CTRL, restore the guest's value if
         * it's non-zero. Since vmentry is serialising on affected CPUs, there
         * is no need to worry about the conditional branch over the wrmsr
         * being speculatively taken.
         */
        x86_spec_ctrl_set_guest(vmx->spec_ctrl, 0);

        /* L1D Flush includes CPU buffer clear to mitigate MDS */
        if (static_branch_unlikely(&vmx_l1d_should_flush))
                vmx_l1d_flush(vcpu);
        else if (static_branch_unlikely(&mds_user_clear))
                mds_clear_cpu_buffers();

        if (vcpu->arch.cr2 != read_cr2())
                write_cr2(vcpu->arch.cr2);
        // 执行 VMLAUNCH 指令进入 Guest 模式, 虚拟机开始运行
        // &vcpu->arch.regs 用来在 vm 退出后保存 guest 寄存器的值
        // vmx->loaded_vmcs->launched 表明当前 vcpu 是否已经 vmlaunch
        vmx->fail = __vmx_vcpu_run(vmx, (unsigned long *)&vcpu->arch.regs,
                                   vmx->loaded_vmcs->launched);
        // cr2, 线性地址
        vcpu->arch.cr2 = read_cr2();

        /*
         * We do not use IBRS in the kernel. If this vCPU has used the
         * SPEC_CTRL MSR it may have left it on; save the value and
         * turn it off. This is much more efficient than blindly adding
         * it to the atomic save/restore list. Especially as the former
         * (Saving guest MSRs on vmexit) doesn't even exist in KVM.
         *
         * For non-nested case:
         * If the L01 MSR bitmap does not intercept the MSR, then we need to
         * save it.
         *
         * For nested case:
         * If the L02 MSR bitmap does not intercept the MSR, then we need to
         * save it.
         */
        if (unlikely(!msr_write_intercepted(vcpu, MSR_IA32_SPEC_CTRL)))
                vmx->spec_ctrl = native_read_msr(MSR_IA32_SPEC_CTRL);

        x86_spec_ctrl_restore_host(vmx->spec_ctrl, 0);

        /* All fields are clean at this point */
        if (static_branch_unlikely(&enable_evmcs))
                current_evmcs->hv_clean_fields |=
                        HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;

        if (static_branch_unlikely(&enable_evmcs))
                current_evmcs->hv_vp_id = vcpu->arch.hyperv.vp_index;

        /* MSR_IA32_DEBUGCTLMSR is zeroed on vmexit. Restore it if needed */
        if (vmx->host_debugctlmsr)
                update_debugctlmsr(vmx->host_debugctlmsr);

#ifndef CONFIG_X86_64
        /*
         * The sysexit path does not restore ds/es, so we must set them to
         * a reasonable value ourselves.
         *
         * We can't defer this to vmx_prepare_switch_to_host() since that
         * function may be executed in interrupt context, which saves and
         * restore segments around it, nullifying its effect.
         */
        loadsegment(ds, __USER_DS);
        loadsegment(es, __USER_DS);
#endif

        vcpu->arch.regs_avail = ~((1 << VCPU_REGS_RIP) | (1 << VCPU_REGS_RSP)
                                  | (1 << VCPU_EXREG_RFLAGS)
                                  | (1 << VCPU_EXREG_PDPTR)
                                  | (1 << VCPU_EXREG_SEGMENTS)
                                  | (1 << VCPU_EXREG_CR3));
        vcpu->arch.regs_dirty = 0;

        pt_guest_exit(vmx);

        /*
         * eager fpu is enabled if PKEY is supported and CR4 is switched
         * back on host, so it is safe to read guest PKRU from current
         * XSAVE.
         */
        if (static_cpu_has(X86_FEATURE_PKU) &&
            kvm_read_cr4_bits(vcpu, X86_CR4_PKE)) {
                vcpu->arch.pkru = rdpkru();
                if (vcpu->arch.pkru != vmx->host_pkru)
                        __write_pkru(vmx->host_pkru);
        }

        kvm_load_host_xsave_state(vcpu);

        vmx->nested.nested_run_pending = 0;
        vmx->idt_vectoring_info = 0;
        // vm->exit_reason
        vmx->exit_reason = vmx->fail ? 0xdead : vmcs_read32(VM_EXIT_REASON);
        // 处理 mce 异常
        if ((u16)vmx->exit_reason == EXIT_REASON_MCE_DURING_VMENTRY)
                kvm_machine_check();

        if (vmx->fail || (vmx->exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY))
                return;
        // 设置已经 vmlaunch
        vmx->loaded_vmcs->launched = 1;
        // 从硬件 VMCS 中读取中断向量表信息
        vmx->idt_vectoring_info = vmcs_read32(IDT_VECTORING_INFO_FIELD);
        /*NMI 中断*/
        vmx_recover_nmi_blocking(vmx);
        vmx_complete_interrupts(vmx);
}
```

调用 `__vmx_vcpu_run` 进入虚拟化模式, 这是一段汇编代码, 如下.

```x86asm
/**
 * __vmx_vcpu_run - Run a vCPU via a transition to VMX guest mode
 * @vmx:        struct vcpu_vmx * (forwarded to vmx_update_host_rsp)
 * @regs:       unsigned long * (to guest registers)
 * @launched:   %true if the VMCS has been launched
 *
 * Returns:
 *      0 on VM-Exit, 1 on VM-Fail
 */
SYM_FUNC_START(__vmx_vcpu_run)
        /* 将 host 寄存器压栈 */

        /* RBP 压栈, 栈底指针寄存器压栈保存*/
        push %_ASM_BP
        // 将栈顶设为栈底, 所以栈底和栈顶指针相等了, 不会影响以前栈的数据
        mov  %_ASM_SP, %_ASM_BP
        // rbx, rbp！！！, r12, r13, r14, r15 都是数据存储寄存器
        // 被调用者随便用, 在调用子函数之前要备份它, 以防他被修改
#ifdef CONFIG_X86_64
        push %r15
        push %r14
        push %r13
        push %r12
#else
        push %edi
        push %esi
#endif
        // RBX 寄存器压栈
        push %_ASM_BX

        /*
         * Save @regs, _ASM_ARG2 may be modified by vmx_update_host_rsp() and
         * @regs is needed after VM-Exit to save the guest's register values.
         */
        // 压栈保存虚拟机 vcpu 寄存器
        push %_ASM_ARG2
        // 拷贝 @launched 到 bl
        /* Copy @launched to BL, _ASM_ARG3 is volatile. */
        mov %_ASM_ARG3B, %bl

        /* Adjust RSP to account for the CALL to vmx_vmenter(). */
        // 调整 RSP, 将 vcpu 寄存器内存地址给 RSP
        lea -WORD_SIZE(%_ASM_SP), %_ASM_ARG2
        // 此时还未进入 guest 模式, 会更新 host rsp, vmcs_write, 见下面
        call vmx_update_host_rsp

        /* Load @regs to RAX. */
        // 将 vcpu 寄存器复制给 RAX
        mov (%_ASM_SP), %_ASM_AX
        /*判断 vcpu_vmx->__launched, 确认是否需要执行 VMLAUNCH*/
        /* Check if vmlaunch or vmresume is needed */
        cmpb $0, %bl

        /* Load guest registers.  Don't clobber flags. */
        /* 加载 guest 寄存器到物理寄存器 */
        mov VCPU_RCX(%_ASM_AX), %_ASM_CX
        mov VCPU_RDX(%_ASM_AX), %_ASM_DX
        mov VCPU_RBX(%_ASM_AX), %_ASM_BX
        mov VCPU_RBP(%_ASM_AX), %_ASM_BP
        mov VCPU_RSI(%_ASM_AX), %_ASM_SI
        mov VCPU_RDI(%_ASM_AX), %_ASM_DI
#ifdef CONFIG_X86_64
        mov VCPU_R8 (%_ASM_AX),  %r8
        mov VCPU_R9 (%_ASM_AX),  %r9
        mov VCPU_R10(%_ASM_AX), %r10
        mov VCPU_R11(%_ASM_AX), %r11
        mov VCPU_R12(%_ASM_AX), %r12
        mov VCPU_R13(%_ASM_AX), %r13
        mov VCPU_R14(%_ASM_AX), %r14
        mov VCPU_R15(%_ASM_AX), %r15
#endif
        /* Load guest RAX.  This kills the @regs pointer! */
        // 加载 guest rax 寄存器
        mov VCPU_RAX(%_ASM_AX), %_ASM_AX

        /* Enter guest mode */
        // 进入 guest 模式, 见下面
        call vmx_vmenter

        /* Jump on VM-Fail. */
        // 无符号小于等于则跳转, VM-Fail 则不保存虚拟机寄存器
        // 因为 VM-Fail 表明没有执行任何虚拟机指令
        jbe 2f
        // 暂时存储虚拟机 RAX 寄存器
        /* Temporarily save guest's RAX. */
        push %_ASM_AX

        /* Reload @regs to RAX. */
        // RSP 存储着 vcpu 的寄存器内存地址
        mov WORD_SIZE(%_ASM_SP), %_ASM_AX
        // 保存所有 vcpu 寄存器到 vcpu 结构, 这个
        /* Save all guest registers, including RAX from the stack */
        __ASM_SIZE(pop) VCPU_RAX(%_ASM_AX)
        mov %_ASM_CX,   VCPU_RCX(%_ASM_AX)
        mov %_ASM_DX,   VCPU_RDX(%_ASM_AX)
        mov %_ASM_BX,   VCPU_RBX(%_ASM_AX)
        mov %_ASM_BP,   VCPU_RBP(%_ASM_AX)
        mov %_ASM_SI,   VCPU_RSI(%_ASM_AX)
        mov %_ASM_DI,   VCPU_RDI(%_ASM_AX)
#ifdef CONFIG_X86_64
        mov %r8,  VCPU_R8 (%_ASM_AX)
        mov %r9,  VCPU_R9 (%_ASM_AX)
        mov %r10, VCPU_R10(%_ASM_AX)
        mov %r11, VCPU_R11(%_ASM_AX)
        mov %r12, VCPU_R12(%_ASM_AX)
        mov %r13, VCPU_R13(%_ASM_AX)
        mov %r14, VCPU_R14(%_ASM_AX)
        mov %r15, VCPU_R15(%_ASM_AX)
#endif

        /* Clear RAX to indicate VM-Exit (as opposed to VM-Fail). */
        xor %eax, %eax

        /*
         * Clear all general purpose registers except RSP and RAX to prevent
         * speculative use of the guest's values, even those that are reloaded
         * via the stack.  In theory, an L1 cache miss when restoring registers
         * could lead to speculative execution with the guest's values.
         * Zeroing XORs are dirt cheap, i.e. the extra paranoia is essentially
         * free.  RSP and RAX are exempt as RSP is restored by hardware during
         * VM-Exit and RAX is explicitly loaded with 0 or 1 to return VM-Fail.
         */
1:      xor %ecx, %ecx
        xor %edx, %edx
        xor %ebx, %ebx
        xor %ebp, %ebp
        xor %esi, %esi
        xor %edi, %edi
#ifdef CONFIG_X86_64
        xor %r8d,  %r8d
        xor %r9d,  %r9d
        xor %r10d, %r10d
        xor %r11d, %r11d
        xor %r12d, %r12d
        xor %r13d, %r13d
        xor %r14d, %r14d
        xor %r15d, %r15d
#endif
        // 加载恢复 host 寄存器
        /* "POP" @regs. */
        add $WORD_SIZE, %_ASM_SP
        pop %_ASM_BX

#ifdef CONFIG_X86_64
        pop %r12
        pop %r13
        pop %r14
        pop %r15
#else
        pop %esi
        pop %edi
#endif
        // 原有 host 的堆栈恢复, 栈底恢复
        pop %_ASM_BP
        // 返回
        ret

        /* VM-Fail.  Out-of-line to avoid a taken Jcc after VM-Exit. */
        // VM-Fail 直接到这里, eax 寄存器存储返回值
2:      mov $1, %eax
        jmp 1b
SYM_FUNC_END(__vmx_vcpu_run)
```

这里逻辑主要是

1. 保护 host 原有堆栈, 将栈底指针寄存器 RBP 压栈保存, 将栈顶(RSP)设为栈底(RBP), 所以不会影响原有 host 的堆栈
2. rbx, rbp(第一步), r12, r13, r14, r15(x32 对应的是 edi, esi)数据寄存器压栈保存, 因为这些 host 和 guest 都可以使用
3. 压栈保存虚拟机 vcpu 寄存器
4. 加载虚拟机 vcpu 寄存器到物理寄存器
5. 执行`call vmx_vmenter`进入 guest 模式, 见下面汇编
6. 在之前创建 vcpu 时候, 有代码`vmcs_write1(HOST_RIP, (unsigned long)vmx_vmexit);`设置了`vm-exit`后 host 的入口地址, 具体代码如下(其实就是一个 ret), 这里涉及到了 call 和 ret 汇编
7. 执行到这里要么因为 VM-Fail 要么是虚拟机 VM-exit, 而 VM-Fail 表明没有执行任何虚拟机指令
8. 虚拟机 vm-exit 的话, 先保存所有 vcpu 寄存器到 vcpu 结构, 再加载恢复 host 那些数据寄存器, 然后返回

```x86asm
/**
 * vmx_vmenter - VM-Enter the current loaded VMCS
 *
 * %RFLAGS.ZF:  !VMCS.LAUNCHED, i.e. controls VMLAUNCH vs. VMRESUME
 *
 * Returns:
 *      %RFLAGS.CF is set on VM-Fail Invalid
 *      %RFLAGS.ZF is set on VM-Fail Valid
 *      %RFLAGS.{CF,ZF} are cleared on VM-Success, i.e. VM-Exit
 *
 * Note that VMRESUME/VMLAUNCH fall-through and return directly if
 * they VM-Fail, whereas a successful VM-Enter + VM-Exit will jump
 * to vmx_vmexit.
 */
SYM_FUNC_START(vmx_vmenter)
        /* EFLAGS.ZF is set if VMCS.LAUNCHED == 0 */
        // 检查 ZF, zf 等于 0(即第一次)则跳转执行 vmlaunch
        je 2f
        // 如果已经曾经加载过 VM 了, 执行 VMRESUME 指令, 快速重新启动 VM
1:      vmresume
        ret

2:      vmlaunch
        ret

3:      cmpb $0, kvm_rebooting
        je 4f
        ret
4:      ud2

        _ASM_EXTABLE(1b, 3b)
        _ASM_EXTABLE(2b, 3b)

SYM_FUNC_END(vmx_vmenter)

/**
 * vmx_vmexit - Handle a VMX VM-Exit
 *
 * Returns:
 *      %RFLAGS.{CF,ZF} are cleared on VM-Success, i.e. VM-Exit
 *
 * This is vmx_vmenter's partner in crime.  On a VM-Exit, control will jump
 * here after hardware loads the host's state, i.e. this is the destination
 * referred to by VMCS.HOST_RIP.
 */
SYM_FUNC_START(vmx_vmexit)
#ifdef CONFIG_RETPOLINE
        ALTERNATIVE "jmp .Lvmexit_skip_rsb", "", X86_FEATURE_RETPOLINE
        /* Preserve guest's RAX, it's used to stuff the RSB. */
        push %_ASM_AX

        /* IMPORTANT: Stuff the RSB immediately after VM-Exit, before RET! */
        FILL_RETURN_BUFFER %_ASM_AX, RSB_CLEAR_LOOPS, X86_FEATURE_RETPOLINE

        pop %_ASM_AX
.Lvmexit_skip_rsb:
#endif
        ret
SYM_FUNC_END(vmx_vmexit)
```

在执行`call vmx_vmenter`时候会将当前 ip 压栈(即下一条指令`jbe 2f`), 在`vmx_vmenter`中会进入虚拟机模式, 当虚拟机 vm-exit 时候, 会调用到`vmx_vmexit`, 而这里面是一个`ret`, 会执行`pop ip`, 从而在这里虚拟机 vm-exit 后会执行`call vmx_vmenter`的下一条指令(`jbe 2f`). 总结来说, 本质上就是先进行函数调用进入虚拟机模式, 然后在`vm-exit`后从这个函数返回, 也就是整个流程都是在一个函数中.

```cpp
void vmx_update_host_rsp(struct vcpu_vmx *vmx, unsigned long host_rsp)
{
        if (unlikely(host_rsp != vmx->loaded_vmcs->host_state.rsp)) {
                vmx->loaded_vmcs->host_state.rsp = host_rsp;
                vmcs_writel(HOST_RSP, host_rsp);
        }
}
```

Guest OS 运行在 VMX non-root 模式中, 当执行默写特权执行时, 则会引发 VM Exit. Guest Exit Reason 保存在 MSR 寄存器中.  `arch/x86/kvm/vmx.c:kvm_vmx_exit_handlers` 定义了 guest Exit 的**内核处理函数**.  例如 `[EXIT_REASON_CR_ACCESS] = handle_cr`, 当 Guest OS 访问 cr 寄存器时, 即会产生 VM Exit, 将控制权交予 kvm, 调用`handle_cr`处理. 对应到**KVM**就是`vCPU->kvm_run->exit_reason`. KVM 根据`exit_reason`做相应的处理.

**VM Exit 退出的代码**是`vmx.c:vmx_vcpu_run`函数**后半段开始执行**, 执行路径与**vm entry 相反**, 一层层**回调处理**到 qemu-kvm 中的`kvm_exec_cpu`



Guest 代码执行到**敏感指令**或因**其他原因**(比如中断/异常), **VM-Exit 退出非根模式**, 返回到`vcpu_enter_guest`函数继续执行.

vcpu_enter_guest 函数中会判断 VM-Exit 原因, 并进行相应处理.

处理完成后 VM-Entry 到 Guest 重新执行 Guest 代码, 或重新等待下次调度.

### 7.3.1. SVM 的 VMRUN

伪代码和指令说明见 AMD 手册`3- General Purpose and System Instructions`.