

# 7. 影子页表(Shadow Page Table, SPT)

作用: **GVA**直接到**HPA**的地址翻译, 真正被 VMM 载入到**物理 MMU**中的**页表**是**影子页表**;

而通过影子页表, 则可以实现客户机虚拟地址到宿主机物理地址的直接转换. 如下图所示:

![config](./images/2.png)

KVM 通过维护记录`GVA->HPA`的影子页表 SPT, 减少了地址转换带来的开销, 可以**直接**将 **GVA 转换为 HPA**.

在软件虚拟化的内存转换中, GVA 到 GPA 的转换通过查询 CR3 寄存器来完成, CR3 中保存了 Guest 的页表基地址, 然后载入 MMU 中进行地址转换.

在加入了 **SPT** 技术后, 当 **Guest 访问 CR3** 时, KVM 会捕获到这个操作`EXIT_REASON_CR_ACCESS`, 之后 **KVM** 会载入**特殊的 CR3** 和**影子页表**, 欺骗 Guest 这就是真实的 CR3. 之后就和传统的访问内存方式一致, 当需要**访问物理内存**的时候, 只会经过一层影子页表的转换.

![2020-04-12-21-56-57.png](./images/2020-04-12-21-56-57.png)

影子页表由 KVM 维护, 实际上就是一个 Guest 页表到 Host 页表的映射. KVM 会将 Guest 的页表设置为只读, 当 Guest OS 对页表进行修改时就会触发 Page Fault, VM-EXIT 到 KVM, 之后 KVM 会对 GVA 对应的页表项进行访问权限检查, 结合**错误码**进行判断:

- 如果是 Guest OS 引起的, 则**将该异常注入回去**, Guest OS 将调用**自己的缺页处理函数**, 申请一个 Page, 并将 Page 的 GPA 填充到上级页表项中
- 如果是 Guest OS 的页表和 SPT 不一致引起的, 则同步 SPT, 根据 Guest 页表和 mmap 映射找到 GPA 到 HVA 的映射关系, 然后在 SPT 中增加/更新 GVA-HPA 表项

当 Guest 切换进程时, 会把带切换进程的页表基址载入到 Guest 的 CR3 中, 导致 VM-EXIT 到 KVM 中. KVM 再通过哈希表找到对应的 SPT, 然后加载到机器的 CR3 中.

影子页表的引入, 减少了 GVA->HPA 的转换开销, 但是缺点在于需要为 Guest 的每个进程都维护一个影子页表, 这将带来很大的内存开销. 同时影子页表的建立是很耗时的, 如果 Guest 的进程过多, 将导致影子页表频繁切换. 因此 Intel 和 AMD 在此基础上提供了基于硬件的虚拟化技术.

**影子页表**简化了地址转换过程, 实现了**客户机虚拟地址空间**到**宿主机物理地址空间**的**直接映射**. 但是由于**客户机**中**每个进程**都有**自己的虚拟地址空间**, 所以**KVM**需要为**客户机**中的**每个进程页表**都要**维护一套相应的影子页表**.

在**客户机**访问**内存**时, 真正被装入**宿主机 MMU**的是**客户机当前页表**所对应的**影子页表**, 从而实现了从客户机虚拟地址到宿主机物理地址的直接转换. 而且, 在 **TLB 和 CPU 缓存**上缓存的是来自**影子页表**中**客户机虚拟地址**和**宿主机物理地址**之间的映射, 也因此提高了缓存的效率.

在**影子页表**中, **每个页表项**指向的都是**宿主机的物理地址**. 这些**表项**是随着**客户机操作系统**对**客户机页表**的**修改**而**相应地建立**的. 客户机中的**每一个页表项**都有**一个影子页表项**与之相对应. 如下图 3 所示:

![config](./images/3.png)

为了**快速检索**客户机页表所对应的的**影子页表**, KVM 为**每个客户机**都维护了一个**哈希表**, **影子页表**和**客户机页表**通过此**哈希表**进行**映射**.

对于**每一个客户机**来说, **客户机的页目录**和**页表**都有**唯一**的**客户机物理地址**, 通过**页目录 / 页表的客户机物理地址**就可以在**哈希链表**中快速地找到**对应的影子页目录 / 页表**.

在**检索哈希表**时, **KVM** 把**客户机页目录** / **页表**的**客户机物理地址低 10 位作为键值**进行**索引**, 根据其**键值**定位到**对应的链表**, 然后**遍历此链表**找到**对应的影子页目录/页表**. 当然, 如果**不能发现对应的影子页目录 / 页表**, 说明 **KVM** 还**没有为其建立**, 于是 KVM 就为其**分配新的物理页**并加入此**链表**, 从而建立起客户机页目录 / 页表和对应的影子页目录 / 页表之间的映射.

当**客户机切换进程**时, **客户机操作系统**会把**待切换进程的页表基址载入 CR3**, 而 KVM 将会**截获这一特权指令**, 进行新的处理, 也即在**哈希表**中找到与**此页表基址**对应的**影子页表基址**, 载入**客户机 CR3**, 使**客户机在恢复运行**时 CR3 实际指向的是**新切换进程对应的影子页表**.

## 7.1. 影子映射关系

SPD 是 PD 的影子页表, SPT1/SPT2 是 PT1/PT2 的影子页表. 由于客户 PDE 和 PTE 给出的页表基址和页基址并不是真正的物理地址, 所以我们采用虚线表示 PDE 到 GUEST 页表以及 PTE 到普通 GUEST 页的映射关系.

![2020-03-30-11-03-59.png](./images/2020-03-30-11-03-59.png)

## 7.2. 影子页表的建立

- 开始时, VMM 中的与 guest OS 所拥有的页表相对应的影子页表是空的;
- 而影子页表又是载入到 CR3 中真正为物理 MMU 所利用进行寻址的页表, 因此开始时任何的内存访问操作都会引起缺页异常; 导致 vm 发生 VM Exit; 进入 `handle_exception()`;

```cpp
if (is_page_fault(intr_info)) {
		/* EPT won't cause page fault directly */
		BUG_ON(enable_ept);
		cr2 = vmcs_readl(EXIT_QUALIFICATION);
		trace_kvm_page_fault(cr2, error_code);

		if (kvm_event_needs_reinjection(vcpu))
			kvm_mmu_unprotect_page_virt(vcpu, cr2);
		return kvm_mmu_page_fault(vcpu, cr2, error_code, NULL, 0);
	}
```

获得缺页异常发生时的 CR2,及当时访问的虚拟地址;
进入 kvm_mmu_page_fault()(vmx.c)->
r = vcpu->arch.mmu.page_fault(vcpu, cr2, error_code);(mmu.c)->
FNAME(page_fault)(struct kvm_vcpu *vcpu, gva_t addr, u32 error_code)(paging_tmpl.h)->
FNAME(walk_addr)() 查 guest 页表, 物理地址是否存在,  这时肯定是不存在的
The page is not mapped by the guest. Let the guest handle it.
inject_page_fault()->kvm_inject_page_fault() 异常注入流程;

Guest OS 修改从 GVA->GPA 的映射关系填入页表;
继续访问, 由于影子页表仍是空, 再次发生缺页异常;
FNAME(page_fault)->
FNAME(walk_addr)() 查 guest 页表, 物理地址映射均是存在->
FNAME(fetch):
遍历影子页表, 完成创建影子页表(填充影子页表);
在填充过程中, 将客户机页目录结构页对应影子页表页表项标记为写保护, 目的截获对于页目录的修改(页目录也是内存页的一部分, 在页表中也是有映射的, guest 对页目录有写权限, 那么在影子页表的页目录也是可写的, 这样对页目录的修改导致 VMM 失去截获的机会)


## 7.3. 影子页表的填充

```cpp
shadow_page = kvm_mmu_get_page(vcpu, table_gfn, addr, level-1, direct, access, sptep);
index = kvm_page_table_hashfn(gfn);
hlist_for_each_entry_safe
if (sp->gfn == gfn)
{......}
else
{sp = kvm_mmu_alloc_page(vcpu, parent_pte);}
```

为了快速检索 GUEST 页表所对应的的影子页表, KVM 为每个 GUEST 都维护了一个哈希
表, 影子页表和 GUEST 页表通过此哈希表进行映射. 对于每一个 GUEST 来说, GUEST
的页目录和页表都有唯一的 GUEST 物理地址, 通过页目录/页表的客户机物理地址就
可以在哈希链表中快速地找到对应的影子页目录/页表.

## 7.4. 影子页表的缓存

* Guest OS 修改从 GVA->GPA 的映射关系, 为保证一致性, VMM 必须对影子页表也做相应的维护, 这样, VMM 必须截获这样的内存访问操作;
* 导致 VM Exit 的机会
  * INVLPG
  * MOV TO CR3
  * TASK SWITCH(发生 MOV TO CR3 )
* 以 INVLPG 触发 VM Exit 为例:
* static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva)
  * Paging_tmpl.h
  * 影子页表项的内容无效
* GUEST 在切换 CR3 时, VMM 需要清空整个 TLB, 使所有影子页表的内容无效. 在多进程 GUEST 操作系统中, CR3 将被频繁地切换, 某些影子页表的内容可能很快就会被再次用到, 而重建影子页表是一项十分耗时的工作, 这里需要缓存影子页表, 即 GUEST 切换 CR3 时不清空影子页表.


## 7.5. 影子页表异常处理机制

在通过**影子页表**进行**寻址**的过程中, 有**两种原因**会引起**影子页表的缺页异常**, 一种是由**客户机本身所引起的缺页异常**, 具体来说就是客户机所访问的**客户机页表项存在位 (Present Bit) 为 0**, 或者写一个**只读的客户机物理页**, 再者所访问的**客户机虚拟地址无效**等. 另一种异常是由**客户机页表**和**影子页表不一致**引起的异常.

当**缺页异常发生**时, **KVM** 首先**截获该异常**, 然后对发生异常的**客户机虚拟地址**在**客户机页表**中所对应**页表项**的访问权限进行检查, 并根据**引起异常的错误码**, 确定出此**异常的原因**, 进行相应的处理.

如果该异常是由**客户机本身引起**的, KVM 则直接把该**异常**交由**客户机的缺页异常处理机制**来进行处理.

如果该异常是由**客户机页表**和**影子页表不一致**引起的, KVM 则根据**客户机页表同步影子页表**. 为此, KVM 要建立起**相应的影子页表数据结构**, 填充**宿主机物理地址**到**影子页表的页表项**, 还要根据客户机页表项的访问权限修改影子页表对应页表项的访问权限.

由于**影子页表**可被载入**物理 MMU** 为**客户机直接寻址**使用,  所以客户机的**大多数内存访问**都可以在**没有 KVM 介入**的情况下正常执行, **没有额外的地址转换开销**, 也就大大提高了客户机运行的效率. 但是影子页表的引入也意味着 KVM 需要为**每个客户机**的**每个进程的页表**都要维护一套**相应的影子页表**, 这会带来**较大内存上的额外开销**, 此外, **客户机页表**和和**影子页表的同步**也比较复杂.

因此, Intel 的 EPT(Extent Page Table) 技术和 AMD 的 NPT(Nest Page Table) 技术都对内存虚拟化提供了硬件支持. 这两种技术原理类似, 都是在**硬件层面**上实现客户机虚拟地址到宿主机物理地址之间的转换. 下面就以 EPT 为例分析一下 KVM 基于硬件辅助的内存虚拟化实现.

## 7.6. 影子页表方案总结

内存虚拟化的两次转换:
- GVA->GPA (GUEST 的页表实现)
- GPA->HPA (VMM 进行转换)

影子页表将两次转换合一:

根据`GVA->GPA->HPA`计算出`GVA->HPA`,填入影子页表

优点:

由于影子页表可被载入物理 MMU 为客户机直接寻址使用, 所以客户机的大多数内存访问都可以在没有 KVM 介入的情况下正常执行, 没有额外的地址转换开销, 也就大大提高了客户机运行的效率.

缺点:

1、KVM 需要为每个客户机的每个进程的页表都要维护一套相应的影子页表, 这会带来较大内存上的额外开销;

2、客户在读写 CR3、执行 INVLPG 指令或客户页表不完整等情况下均会导致 VM exit, 这导致了内存虚拟化效率很低

3、客户机页表和和影子页表的同步也比较复杂.

因此, Intel 的 EPT(Extent Page Table) 技术和 AMD 的 NPT(Nest Page Table) 技术都对内存虚拟化提供了硬件支持. 这两种技术原理类似, 都是在硬件层面上实现客户机虚拟地址到宿主机物理地址之间的转换.
