
# 1. OOM

OOM 的全称是`out-of-memory`, 是内核在处理系统内存不足而又回收无果的情况下采取的一种措施, 内核会经过选择杀死一些进程, 以释放一些内存, 满足当前内存申请的需求.

所以 oom 是一种系统行为, 对应到 memcg 的 oom, 其原理和动机跟全局 oom 是一样的, 区别只在于对象的不同, **全局 oom**的对象是**整个系统**中**所有进程**, 而**memcg oom**只针对**memcg 中的进程**(如果**使能了 hierarchy**, 还包括所有**子 memcg 中的进程**), 这里的对象主要是指 oom 时内核选择从哪些进程中杀死一些进程, 所以 memcg 的 oom**只**可能杀死**属于该 memcg 的进程**.

# 2. 猜测

linux 内存管理中 oom killer 机制存在于分配内存的 `__alloc_pages_slowpath()` 阶段

所以猜测 memcg 的 oom killer 机制是在 `charge`(统计计数) 阶段

# 3. 查看最初的代码

通过`tig mm/memcontrol.c`查看最开始代码, 能得到 oom 最初的代码

## 3.1. 相关 commit

Memory controller: OOM handling, c7ba5c9e8176704bfac0729875fa62798037584d, 2008-02-07, 08:42

> oom(Out of memory)处理用于当 cgroup 超过其限制. 从超过限制的 cgroup 中拿到一个进程, 利用现有的 oom 逻辑 kill 掉这个进程.

## 3.2. 代码分析

```diff
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -329,6 +329,7 @@ int mem_cgroup_charge(struct page *page, struct mm_struct *mm)
                }

                css_put(&mem->css);
+               mem_cgroup_out_of_memory(mem, GFP_KERNEL);
                goto free_pc;
        }
```

reset 回这个 commit 查看当时的逻辑.

```cpp
// mm/memcontrol.c
int mem_cgroup_charge(struct page *page, struct mm_struct *mm)
{
        ......
        /*
         * If we created the page_cgroup, we should free it on exceeding
         * the cgroup limit.
         */
        // 下面逻辑都是创建了新的 page_cgroup, 即
        // 当前 memcg 使用的内存统计计数 + PAGE_SIZE
        // 如果大于这个 memcg 的 limit, 则进入里面的流程
        while (res_counter_charge(&mem->res, PAGE_SIZE)) {
                // 回收释放这个 memcg 的 page, 释放成功返回 1(即进行下一次循环)
                if (try_to_free_mem_cgroup_pages(mem))
                        continue;

                /*
                 * try_to_free_mem_cgroup_pages() might not give us a full
                 * picture of reclaim. Some pages are reclaimed and might be
                 * moved to swap cache or just unmapped from the cgroup.
                 * Check the limit again to see if the reclaim reduced the
                 * current usage of the cgroup before giving up
                 */
                // 上面调用可能不会提供完整的回收信息
                // 一些页面被回收可能仅仅被移至交换缓存或仅从 cgroup 取消映射
                // 在放弃回收之前, 再次检查限制, 查看回收是否减少了 cgroup 的当前使用率
                // 在 limit 内返回 true(下一次循环), 否则 false(高于 limit)
                if (res_counter_check_under_limit(&mem->res))
                        continue;
                        /*
                         * Since we control both RSS and cache, we end up with a
                         * very interesting scenario where we end up reclaiming
                         * memory (essentially RSS), since the memory is pushed
                         * to swap cache, we eventually end up adding those
                         * pages back to our list. Hence we give ourselves a
                         * few chances before we fail
                         */
                //5 次的回收机会
                else if (nr_retries--) {
                        congestion_wait(WRITE, HZ/10);
                        continue;
                }

                css_put(&mem->css);
                // 回收失败则 oom killer
                mem_cgroup_out_of_memory(mem, GFP_KERNEL);
                goto free_pc;
        }
        ......
}
```

**5 次回收失败**则调用了`mem_cgroup_out_of_memory(mem, GFP_KERNEL);`,

```cpp
//mm/oom_kill.c

#ifdef CONFIG_CGROUP_MEM_CONT
void mem_cgroup_out_of_memory(struct mem_cgroup *mem, gfp_t gfp_mask)
{
        unsigned long points = 0;
        struct task_struct *p;

        cgroup_lock();
        rcu_read_lock();
retry:
        // 找出该 memcg 下最该被 kill 的进程
        p = select_bad_process(&points, mem);
        if (PTR_ERR(p) == -1UL)
                goto out;
        // 没有选出, 就使用当前的
        if (!p)
                p = current;
        // 杀掉选中的进程及与其共用 mm 的进程
        // 杀进程的目的是释放内存, 所以当然要把 mm 的所有引用都干掉
        // 里面的实现会优先 kill 子进程
        // 不成功, 则重试
        if (oom_kill_process(p, gfp_mask, 0, points,
                                "Memory cgroup out of memory"))
                goto retry;
out:
        rcu_read_unlock();
        cgroup_unlock();
}
#endif
```

跟全局 oom 一样, memcg 的 oom 也分成`select_bad_process`和`oom_kill_process`两个过程, 而这两个都直接使用了内核的函数.

这里`select_bad_process()`只不过多加了个参数, 用来**兼容 memcg**.

```diff
--- a/mm/oom_kill.c
+++ b/mm/oom_kill.c
@@ -25,6 +25,7 @@
 #include <linux/cpuset.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
+#include <linux/memcontrol.h>

 int sysctl_panic_on_oom;
 int sysctl_oom_kill_allocating_task;
@@ -50,7 +51,8 @@ static DEFINE_SPINLOCK(zone_scan_mutex);
  *    of least surprise ... (be careful when you change it)
  */

-unsigned long badness(struct task_struct *p, unsigned long uptime)
+unsigned long badness(struct task_struct *p, unsigned long uptime,
+                       struct mem_cgroup *mem)
 {
        unsigned long points, cpu_time, run_time, s;
        struct mm_struct *mm;
@@ -63,6 +65,13 @@ unsigned long badness(struct task_struct *p, unsigned long uptime)
                return 0;
        }
        // 关键部分
+#ifdef CONFIG_CGROUP_MEM_CONT
+       // 在 memcg 情况下, 如果进程 mm 的 memcg 不是当前这个, 则不处理这个进程, 返回 0
+       // 确保 bad 进程是 memcg 的
+       if (mem != NULL && mm->mem_cgroup != mem) {
+               task_unlock(p);
+               return 0;
+       }
+#endif
+
        /*
         * The memory size of the process is the basis for the badness.
         */
@@ -193,7 +202,8 @@ static inline enum oom_constraint constrained_alloc(struct zonelist *zonelist,
  *
  * (not docbooked, we don't want this one cluttering up the manual)
  */
-static struct task_struct *select_bad_process(unsigned long *ppoints)
+static struct task_struct *select_bad_process(unsigned long *ppoints,
+                                               struct mem_cgroup *mem)
 {
        struct task_struct *g, *p;
        struct task_struct *chosen = NULL;
@@ -247,7 +257,7 @@ static struct task_struct *select_bad_process(unsigned long *ppoints)
                if (p->oomkilladj == OOM_DISABLE)
                        continue;

-               points = badness(p, uptime.tv_sec);
+               points = badness(p, uptime.tv_sec, mem);
                if (points > *ppoints || !chosen) {
                        chosen = p;
                        *ppoints = points;
```

跟全局 oom 一样, memcg 的 oom 也分成`select_bad_process`和`oom_kill_process`两个过程:

a. `select_bad_process`会遍历系统中所有的 thread, 找出该 memcg 下最该被 kill 的进程;

b. `oom_kill_process`杀掉选中的进程及与其共用 mm 的进程(杀进程的目的是释放内存, 所以当然要把 mm 的所有引用都干掉);

在最初的这一版中, 是直接调用内核的 `select_bad_process` 和 `oom_kill_process`.

至此第一版的 memcg oom killer 代码分析结束.

# 4. 最新的方案

代码版本:

```
VERSION = 5
PATCHLEVEL = 13
SUBLEVEL = 0
EXTRAVERSION = -rc1
NAME = Frozen Wasteland
```

* mm: oom: deduplicate victim selection code for memcg and global oom, 7c5f64f84483bd13886348edda8b3e7b799a7fdb
* mm: memcg: do not trap chargers with full callstack on OOM, 3812c8c8f3953921ef18544110dafc3505c1ac62
* memcg, oom: move out_of_memory back to the charge path, 29ef680ae7c21110af8e6416d84d8a72fc147b14
* memcg: killed threads should not invoke memcg OOM killer, 7775face207922ea62a4e96b9cd45abfdc7b9840
* mm, oom: fortify task_will_free_mem(), 1af8bb43269563e458ebcf0ece812e9a970864b3

```cpp
try_charge(struct mem_cgroup *memcg, gfp_t gfp_mask, unsigned int nr_pages)
        -> mem_cgroup_oom(mem_over_limit, gfp_mask, get_order(nr_pages * PAGE_SIZE));
                -> mem_cgroup_out_of_memory(memcg, mask, order)
```

```cpp
// mm/memcontrol.c
static bool mem_cgroup_out_of_memory(struct mem_cgroup *memcg, gfp_t gfp_mask,
                                     int order)
{
        struct oom_control oc = {
                .zonelist = NULL,
                .nodemask = NULL,
                .memcg = memcg,
                .gfp_mask = gfp_mask,
                .order = order,
        };
        bool ret = true;
        // 拿锁成功则返回 0; 返回 true 则表明获取锁失败
        if (mutex_lock_killable(&oom_lock))
                return true;
        //
        if (mem_cgroup_margin(memcg) >= (1 << order))
                goto unlock;

        /*
         * A few threads which were not waiting at mutex_lock_killable() can
         * fail to bail out. Therefore, check again after holding oom_lock.
         */
        //
        // current 不属于下面的几种状态, 则进行 oom
        ret = should_force_charge() || out_of_memory(&oc);

unlock:
        mutex_unlock(&oom_lock);
        return ret;
}
```

位置 1 的注释不是很理解那个意思, 查看相应的 commit

```cpp
static inline bool should_force_charge(void)
{
        // tsk->signal->oom_mm 或
        // fatal signal pending 或
        // current 在 EXITING 状态
        return tsk_is_oom_victim(current) || fatal_signal_pending(current) ||
                (current->flags & PF_EXITING);
}
```










## select 部分

在`3.10`中, memcg 实现了自己的 select_bad_process, 即在 memcg 的代码中自己来找到要杀死的进程. 虽然函数调用不同, 但是找到要杀死的进程的原理都是类似的, select 的过程会给 memcg(或及其子 memcg)下的**每个进程打一个分**, **得分最高者**被选中. 评分因素每个版本不尽相同, 主要会考虑以下因素:

a. 进程**拥有 page**和**swap entry 越多**, 分得**越高**;

b. 可以通过`/proc/$pid/oom_score_adj`进行一些分值干预;

c. 拥有 `CAP_SYS_ADMIN` 的 root 进程分值会被调低;


```cpp
static void select_bad_process(struct oom_control *oc)
{
        oc->chosen_points = LONG_MIN;
        // 针对 oc 是 memcg 的处理
        if (is_memcg_oom(oc))
                // 扫描, 对于 task 的评估通过 oom_evaluate_task
                mem_cgroup_scan_tasks(oc->memcg, oom_evaluate_task, oc);
        else {
                ......
        }
}
```

```cpp
int mem_cgroup_scan_tasks(struct mem_cgroup *memcg,
                          int (*fn)(struct task_struct *, void *), void *arg)
{
        struct mem_cgroup *iter;
        int ret = 0;
        // 如果是 root memcg, oops
        BUG_ON(memcg == root_mem_cgroup);
        // 迭代这个 memcg 树下的所有 cgroup
        for_each_mem_cgroup_tree(iter, memcg) {
                struct css_task_iter it;
                struct task_struct *task;
                // 初始化 task 的迭代
                css_task_iter_start(&iter->css, CSS_TASK_ITER_PROCS, &it);
                while (!ret && (task = css_task_iter_next(&it)))
                        ret = fn(task, arg);
                //
                css_task_iter_end(&it);
                if (ret) {
                        mem_cgroup_iter_break(memcg, iter);
                        break;
                }
        }
        return ret;
}
```

对于 task 的评估使用 `oom_evaluate_task`, 和 kernel 原本方法一样



## kill 部分


kill 的过程比较简单, 简单的说就是向要杀死的进程发送 SIGKILL 信号, 但其中依然有一些细节:

a. 如果被选中的进程有一些子进程跟他不共用同一个 mm, 并且也是可以被杀死的, 那么就挑选这些子进程中 badness 得分最高的一个来代替父进程被杀死, 这样是为了确保我们在释放内存的同时失去更少的东西;

b. 上面已经说了, oom_kill 的过程会杀死选中的进程及与其共用 mm 的进程, 所以会遍历所有用户态进程, 找到并杀死与选中进程共用同一个 mm 的进程;

c. 遍历进程的过程中, 会过滤掉通过`/proc/$pid/oom_score_adj`干预的不可被 oom_kill 掉的进程(目前是设置为 OOM_SCORE_ADJ_MIN 的进程);

在 oom 的过程中, 另外值得一说的是其中的同步过程.

oom 过程会向选中的进程发送 SIGKILL 信号, 但是距离进程处理信号、释放空间, 还是需要经历一定时间的. 如果系统负载较高, 则这段时间内很可能有其他上下文也需要却得不到 page, 而触发新的 oom. 那么如果大量 oom 在短时间内爆发, 可能会大面积杀死系统中的进程, 带来一场浩劫.

所以 oom 过程需要同步: 在给选中的进程发送 SIGKILL 后, 会设置其 TIF_MEMDIE 标记. 而在 select 被杀死进程的过程中如果发现记有 TIF_MEMDIE 的进程, 则终止当前的 oom 过程, 并等待上一个 oom 过程结束. 这样做可以避免 oom 时大面积的 kill 进程.

而在进程退出时, 会先将 task->mm 置为 NULL, 再 mmput(mm)释放掉引用计数, 从而导致内存空间被释放(如果引用计数减为 0 的话). 所以, 只要 task->mm 被置为 NULL(内存即将开始释放), 就没人认得它是属于哪个 memcg 的了, 针对那个 memcg 的新的 oom 过程就可以开始.


### oom.group

mm, oom: introduce memory.oom.group, 3d8b38eb81cac81395f6a823f6bf401b327268e6, Tue Aug 21 21:53:54 2018

```cpp
struct mem_cgroup *mem_cgroup_get_oom_group(struct task_struct *victim,
                                            struct mem_cgroup *oom_domain)
{
        struct mem_cgroup *oom_group = NULL;
        struct mem_cgroup *memcg;

#ifndef CONFIG_MEM_QOS
        if (!cgroup_subsys_on_dfl(memory_cgrp_subsys))
                return NULL;
#endif

        // oc->memcg 没有
        if (!oom_domain)
                oom_domain = root_mem_cgroup;

        rcu_read_lock();

        memcg = mem_cgroup_from_task(victim);
        if (memcg == root_mem_cgroup)
                goto out;

        /*
         * Traverse the memory cgroup hierarchy from the victim task's
         * cgroup up to the OOMing cgroup (or root) to find the
         * highest-level memory cgroup with oom.group set.
         */
        // 一直往上层找, 一直到 oc->memcg/root(约束), 结果是最高层的 oom_group 为 1 的
        for (; memcg; memcg = parent_mem_cgroup(memcg)) {
                if (memcg->oom_group)
                        oom_group = memcg;

                if (memcg == oom_domain)
                        break;
        }

        if (oom_group)
                css_get(&oom_group->css);
out:
        rcu_read_unlock();

        return oom_group;
}
```

```
  /sys/fs/cgroup/memory(根/)
          /   \
         /     \
       cg0    cg1
       /  \
      /    \
   0-0-0  0-0-1


```






```cpp
//
static int try_charge(struct mem_cgroup *memcg, gfp_t gfp_mask,
                      unsigned int nr_pages)
{
        ......
retry:
        /*
         * keep retrying as long as the memcg oom killer is able to make
         * a forward progress or bypass the charge if the oom killer
         * couldn't make any progress.
         */
        // 只要 memcg oom Killer 能够取得前进, 就可以持续重试
        // 如果 oom killer 无法取得任何进展, 则绕开 charge.
        oom_status = mem_cgroup_oom(mem_over_limit, gfp_mask,
                       get_order(nr_pages * PAGE_SIZE));
        switch (oom_status) {
        case OOM_SUCCESS:
                // oom 成功, 持续重试
                nr_retries = MAX_RECLAIM_RETRIES;
                goto retry;
        case OOM_FAILED:
                // oom 失败
                // 强制 charge, 暂时会超过 limit
                goto force;
        default:
                goto nomem;
        }
nomem:
        if (!(gfp_mask & __GFP_NOFAIL))
                return -ENOMEM;
force:
        /*
         * The allocation either can't fail or will lead to more memory
         * being freed very soon.  Allow memory usage go over the limit
         * temporarily by force charging it.
         */
        // 分配要么不会失败, 要么会导致很快释放更多的内存
        // 通过强制 charge 使内存使用量暂时超过限制
        page_counter_charge(&memcg->memory, nr_pages);
        if (do_memsw_account())
                page_counter_charge(&memcg->memsw, nr_pages);

        return 0;
        ......
```








# 5.

通过`struct mem_cgroup`中 oom 相关的结构体变量以及`mm/memcontrol.c`中相关变量(`memcg_oom_mutex`等), 查找最初的 memcg oom killer 代码

> 因为结构体位置有变化(从`mm/memcontrol.c`到了`include/linux/memcontrol.h`), 以及代码覆盖情况(时间太久了), 所以有过多次 reset 动作

先是关注`struct mem_cgroup`的变量, 如下

```cpp
struct mem_cgroup {
    /* OOM-Killer disable */
    int             oom_kill_disable;

    /* For oom notifier event fd */
    struct list_head oom_notify;
}
```

得到最终 patch set, 2010-05-26, 14:42

* memcg: oom wakeup filter, dc98df5a1b7be402a0e1c71f1b89ccf249ac15ee
* memcg: oom notifier, 9490ff275606da012d5b373342a49610ad61cb81
* memcg: oom kill disable and oom status, 3c11ecf448eff8f12922c498b8274ce98587eb74

但是查看 git show





* memcg: fix oom kill behavior, 867578cbccb0893cc14fc29c670f7185809c90d6, 2010-03-10 15:22

























最终代码:
* arch: mm: remove obsolete init OOM protection, 94bce453c78996cc4373d5da6cfabe07fcc6d9f9
* arch: mm: do not invoke OOM killer on kernel fault OOM, 871341023c771ad233620b7a1fb3d9c7031c4e5c
* arch: mm: pass userspace fault flag to generic fault handler, 759496ba6407c6994d6a5ce3a5e74937d7816208
* x86: finish user fault error path with fatal signal, 3a13c4d761b4b979ba8767f42345fed3274991b0
* mm: memcg: enable memcg OOM killer only for user faults, 519e52473ebe9db5cdef44670d5a97f1fd53d721
* mm: memcg: rework and document OOM waiting and wakeup, fb2a6fc56be66c169f8b80e07ed999ba453a2db2
* mm: memcg: do not trap chargers with full callstack on OOM, 3812c8c8f3953921ef18544110dafc3505c1ac62




improve memcg oom killer robustness (提升 memcg oom killer 的健壮性)

* v1
    * patch set: https://lkml.org/lkml/2013/7/25/653 ,
    * lwn: https://lwn.net/Articles/560868/

* v2
    * patch set: https://lore.kernel.org/lkml/1375549200-19110-1-git-send-email-hannes@cmpxchg.org/ , https://lkml.org/lkml/2013/8/3/81 ,
    * lwn: https://lwn.net/Articles/562091/


第一版代码分析

在分配内存失败的情况下, memcg 代码会导致 task trap, 直到解决 OOM 情况为止. 此时, 它们可以持有各种锁(fs, mm), 这容易导致死锁.

此系列 patch 将 memcg OOM 处理转换为在 charge 上下文中启动的两步过程, 但是在完全解开错误堆栈后将进行任何等待.

1-4 为支持新的 memcg 要求的体系结构处理程序做准备, 但是这样做还可以消除旧的残废并统一整个体系结构的内存不足行为.

补丁 5 禁用了针对系统调用, 预读, 内核故障的 memcg OOM 处理, 因为它们可以使用-ENOMEM 正常展开堆栈.  OOM 处理仅限于没有其他选择的用户触发的故障.

补丁 6 实现了由两部分组成的 OOM 处理, 以使任务永远不会在 OOM 情况下被充满电荷的堆栈所困.








最终代码:

*

* mm: memcg: enable memcg OOM killer only for user faults: 519e52473ebe9db5cdef44670d5a97f1fd53d721


# memcg priority oom killer

## ali 方案


https://github.com/alibaba/cloud-kernel/commit/52e375fcb7a71d62566dc89764ce107e2f6af9ee#diff-8fa1dddd53606ceb933c5c6a12e714ed41e11d37a2b7bc48e91d15b54171d033



在内存压力下, 将发生回收和 oom. 在一个有多个 cgroup 的系统中, 当有其他候选时, 我们可能需要这些 cgroup 的一些内存或任务在回收和 oom 中幸存下来.

@memory.low 和 @memory.min 已在回收期间发生这种情况, 此补丁引入了 memcg 优先级 oom 来满足 oom 中的上述要求.

优先级是从 0 到 12, 数字越高优先级越高.  当 oom 发生时, 它总是从低优先级的 memcg 中选择受害者. 它既适用于 memcg oom, 也适用于全局 oom, 可以通过 `@memory.use_priority_oom` 启用/禁用, 对于通过**根 memcg**的 `@memory.use_priority_oom` 进行的全局缩放, 默认情况下处于禁用状态.



每个 mem_cgroup 结构体引入了几个和 memcg priority 的变量

```diff
@@ -252,6 +255,12 @@ struct mem_cgroup {
	bool		oom_lock;
	int		under_oom;

	/* memcg priority */
	bool use_priority_oom;
	int priority;
	int num_oom_skip;
	struct mem_cgroup *next_reset;

	int	swappiness;
```

原有逻辑也是调用 kernel 的 `out_of_memory()`, 然后调用`select_bad_process`和`oom_kill_process`

在原有逻辑中, `select_bad_process`阶段, 如果是 memcg, 进行调用 memcg 自己的函数`mem_cgroup_scan_tasks`

新方案, 如果 oom_control 是 memcg 或者`root_memcg_use_priority_oom()` root_memcg 使用 priority_oom, 则调用自己实现的`mem_cgroup_select_bad_process(oc);`

>注: 所以可能在内存分配上下文(即非 memcg 的 charge 阶段), 可能也会调用到 memcg 的 select bad process;
> 而在 select 中, 如果是内存 page 分配上下文(oc->memcg 为空), 则`memcg = root_mem_cgroup`;

如果 memcg(可能是当前 memcg`<在 charge 上下文>`或 root_memcg)使用了`priority_oom`, 先调用`mem_cgroup_select_victim_cgroup()`选择一个受害者 memcgroup, 然后调用之前的`mem_cgroup_scan_tasks`从这个受害者 memcgroup 中扫描进程(以前方案只有在 memcg charge 上下文会发生, 所以只会当前 memcg 的扫描 task)

>注:
>新方案只要开启 root_memcg 的 priority_oom 都会调用 mem_cgroup 的 scan_tasks 方法? 是否合理
>如果当前 memcg 没有开启 priority_oom, 则也不会根据 priority 选择 mem_cgroup


> task_struct->css_set->cgroup_subsys_state->cgroup

在`mem_cgroup_select_victim_cgroup()`中,
1. 如果这个 memcg 没有 hierarchy, 则返回当前 memcg
2. 获得 memcg 的 subsystem(parent)
3. 获得 parent css 的 memcg(parent_memcg)
4. while(parent)

- 如果 parent 的 task 数目小于等于 其对应的 memcg 不可 kill 的 task 数目(num_oom_skip), 跳出循环
- 受害者等于 parent
- chosen_priority = 12 + 1 (最高优先级+1)
- 遍历 parent subsystem 的 children(子链表串)css
        - 如果子 css 的 task 数目小于等于 其对应的 memcg 不可 kill 的 task 数目(num_oom_skip), 下一个子 css
        - 子 css 的 memcg 的 priority 大于 chosen_priority, 下一个子 css



## 我的方案









mm: memcg: do not trap chargers with full callstack on OOM: 3812c8c8f3953921ef18544110dafc3505c1ac62

[RFC PATCH] memcg, oom: move out_of_memory back to the charge path: https://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1716129.html

memcg, oom: move out_of_memory back to the charge path, 29ef680ae7c21110af8e6416d84d8a72fc147b14


# 参考

内核 oom 过程简单分析, http://0fd.org/2015/06/11/the-memory-cgroup-oom-process/