# 缓存一致性

之前一直认为 linux 中很多东西是用来保证缓存一致性的, 其实不是. 

**缓存一致性**绝大部分是靠**硬件机制实现**的, 只有在带 lock 前缀的指令执行时才与 cache 有一点关系. (这话说得绝对, 但我目前看来就是这样)我们更多的时候是为了保证顺序一致性. 

所谓缓存一致性, 就是在多处理器系统中, 每个 cpu 都有自己的 L1 cache. 很可能两个不同 cpu 的 L1 cache 中缓存的是同一片内存的内容, 如果一个 cpu 更改了自己被缓存的内容, 它要保证另一个 cpu 读这块数据时也要读到这个最新的. 不过你不要担心, 这个复杂的工作完全是由硬件来完成的, 通过实现一种 MESI 协议, 硬件可以轻松的完成缓存一致性的工作. 不要说一个读一个写, 就是多个同时写都没问题. 一个 cpu 读时总能读入最新的数据, 不管它是在自己的 cache 中, 还是在其它 cpu 的 cache 中, 还是在内存中, 这就是缓存一致性. 


# 顺序一致性


所谓顺序一致性, 说的则是与缓存一致性完全不同的概念, 虽然它们都是处理器发展的产物. 

因为**编译器的技术**不断发展, 它可能**为了优化你的代码**, 而将**某些操作的顺序更改执行**. 处理器中也早就有了**多发射**、**乱序执行**的概念. 这样的结果, 就是**实际执行的指令顺序**会与编程时**代码的编码顺序**略有不同. 

这在**单处理器**下当然没什么, 毕竟只要自己的代码不过问, 就没人过问, 编译器和处理器就是在保证自己的代码发现不了的情况下打乱执行顺序的. 

但**多处理器**不是这样, 可能**一个处理器上指令的完成顺序**, 会对**其它处理器**上执行的**代码**造成很大影响. 

所以就有了顺序一致性的概念, 即保证**一个处理器上线程的执行顺序**, 在**其它的处理器上的线程**看来, 都是**一样**的. 这个问题的解决不是光靠处理器或者编译器就能解决的, 需要**软件的干预**. 


# 内存屏障


软件干预的方式也非常简单, 那就是**插入内存屏障**(memory barrier). 

其实内存屏障这个词, 是由搞处理器的人造的, 弄得我们很不好理解. 

内存屏障, 很容易让我们串到缓存一致性去, 乃至怀疑是否这样做才能让其它 cpu 看到被修改过的 cache, 这样想就错了. 

所谓内存屏障, 从处理器角度来说, 是用来**串行化读写操作**的, 从软件角度来讲, 就是用来**解决顺序一致性问题**的. **编译器**不是要**打乱代码执行顺序**吗, **处理器**不是要**乱序执行**吗, 你插入一个内存屏障, 就相当于告诉编译器, **屏障前后的指令顺序不能颠倒**, 告诉处理器, 只有等屏障前的指令执行完了, **屏障后的指令**才能开始执行. 

当然, **内存屏障**能阻挡**编译器乱来**, 但**处理器**还是有办法. 处理器中不是有**多发射**、**乱序执行**、**顺序完成**的概念吗, 它在内存屏障时只要保证前面指令的读写操作, 一定在后面指令的读写操作完成之前完成, 就可以了. 所以内存屏障才会对应有读屏障、写屏障和读写屏障三类. 如 x86 之前保证写操作都是顺序完成的, 所以不需要写屏障, 但现在也有部分 ia32 处理器的写操作变成乱序完成, 所以也需要写屏障. 

其实, 除了专门的读写屏障指令, 还有很多指令的执行是带有**读写屏障功能**的, 比如带 lock 前缀的指令. 在专门的读写屏障指令出现之前, linux 就是靠 lock 熬过来的. 

至于在那里插入读写屏障, 要视软件的需求而定. 读写屏障无法完全实现顺序一致性, 但多处理器上的线程也不会一直盯着你的执行顺序看, 只要保证在它看过来的时候, 认为你符合顺序一致性, 执行不会出现你代码中没有预料到的情况. 所谓预料外的情况, 举例而言, 你的线程是先给变量 a 赋值, 再给变量 b 赋值, 结果别的处理器上运行的线程看过来, 发现 b 赋值了, a 却没有赋值, (注意这种不一致不是由缓存不一致造成的, 而是处理器写操作完成的顺序不一致造成的), 这时就要在 a 赋值与 b 赋值之间, 加一个写屏障. 


# 多处理器间同步


有了 SMP 之后, 线程就开始同时在多个处理器上运行. 只要是线程就有通信和同步的要求. 幸好 SMP 系统是共享内存的, 也就是所有处理器看到的内存内容都一样, 虽然有独立的 L1 cache, 但还是由硬件完成了缓存一致性处理的问题. 那不同处理器上的线程要访问同一数据, 需要临界区, 需要同步. 靠什么同步?之前在 UP 系统中, 我们上靠信号量, 下靠关中断和读修改写指令. 现在在 SMP 系统中, 关中断已经废了, 虽然为了同步同一处理器上的线程还是需要的, 但只靠它已经不行了. 读修改写指令?也不行了. 在你指令中读操作完成写操作还没进行时, 就可能有另外的处理器进行了读操作或者写操作. 缓存一致性协议是先进, 但还没有先进到预测这条读操作是哪种指令发出来的. 所以 x86 又发明了带 lock 前缀的指令. 在此指令执行时, 会将所有包含指令中读写地址的 cache line 失效, 并锁定内存总线. 这样别的处理器要想对同样的地址或者同一个 cache line 上的地址读写, 既无法从 cache 中进行(cache 中相关 line 已经失效了), 也无法从内存总线上进行(整个内存总线都锁了), 终于达到了原子性执行的目的. 当然, 从 P6 处理器开始, 如果带 lock 前缀指令 要访问的地址本来就在 cache 中, 就无需锁内存总线, 也能完成原子性操作了(虽然我怀疑这是因为加了多处理器内部公共的 L2 cache 的缘故). 


因为会锁内存总线, 所以带 lock 前缀指令执行前, 也会先将未完成的读写操作完成, 也起到内存屏障的功能. 

现在多处理器间线程的同步, 上用自旋锁, 下用这种带了 lock 前缀的读修改写指令. 当然, 实际的同步还有加上禁止本处理器任务调度的, 有加上任务关中断的, 还会在外面加上信号量的外衣. linux 中对这种自旋锁的实现, 已历经四代发展, 变得愈发高效强大. 

内存屏障的实现

```cpp
#ifdef CONFIG_SMP   
#define smp_mb()    mb()   
#define smp_rmb()   rmb()   
#define smp_wmb()   wmb()   
#else   
#define smp_mb()    barrier()   
#define smp_rmb()   barrier()   
#define smp_wmb()   barrier()   
#endif
```

`CONFIG_SMP`就是用来**支持多处理器**的. 如果是 UP(uniprocessor)系统, 就会翻译成 barrier(). 

```cpp
#define barrier() __asm__ __volatile__("": : :"memory")  
```

barrier()的作用, 就是告诉编译器, 内存的变量值都改变了, 之前存在寄存器里的变量副本无效, 要访问变量还需再访问内存. 这样做足以满足 UP 中所有的内存屏障. 

```cpp
#ifdef CONFIG_X86_32   
/* 
 * Some non-Intel clones support out of order store. wmb() ceases to be a 
 * nop for these. 
 */  
#define mb() alternative("lock; addl $0,0(%%esp)", "mfence", X86_FEATURE_XMM2)   
#define rmb() alternative("lock; addl $0,0(%%esp)", "lfence", X86_FEATURE_XMM2)   
#define wmb() alternative("lock; addl $0,0(%%esp)", "sfence", X86_FEATURE_XMM)   
#else   
#define mb()    asm volatile("mfence":::"memory")   
#define rmb()   asm volatile("lfence":::"memory")   
#define wmb()   asm volatile("sfence" ::: "memory")   
#endif
```

如果是 SMP 系统, 内存屏障就会翻译成对应的 mb()、rmb()和 wmb(). 这里 CONFIG_X86_32 的意思是说这是一个 32 位 x86 系统, 否则就是 64 位的 x86 系统. 现在的 linux 内核将 32 位 x86 和 64 位 x86 融合在同一个 x86 目录, 所以需要增加这个配置选项. 
可以看到, 如果是 64 位 x86, 肯定有 mfence、lfence 和 sfence 三条指令, 而 32 位的 x86 系统则不一定, 所以需要进一步查看 cpu 是否支持这三条新的指令, 不行则用加锁的方式来增加内存屏障. 


SFENCE,LFENCE,MFENCE 指令提供了高效的方式来保证读写内存的排序,这种操作发生在产生弱排序数据的程序和读取这个数据的程序之间.  

- SFENCE——串行化发生在 SFENCE 指令之前的写操作但是不影响读操作.  
- LFENCE——串行化发生在 SFENCE 指令之前的读操作但是不影响写操作.  
- MFENCE——串行化发生在 MFENCE 指令之前的读写操作.  

- sfence:在 sfence 指令前的写操作当必须在 sfence 指令后的写操作前完成.  
- lfence: 在 lfence 指令前的读操作当必须在 lfence 指令后的读操作前完成.  
- mfence: 在 mfence 指令前的读写操作当必须在 mfence 指令后的读写操作前完成.  




至于带 lock 的内存操作, 会在锁内存总线之前, 就把之前的读写操作结束, 功能相当于 mfence, 当然执行效率上要差一些. 


说起来, 现在写点底层代码真不容易, 既要注意 SMP 问题, 又要注意 cpu 乱序读写问题, 还要注意 cache 问题, 还有设备 DMA 问题, 等等. 
————————————————
版权声明: 本文为 CSDN 博主「hustyangju」的原创文章, 遵循 CC 4.0 BY-SA 版权协议, 转载请附上原文出处链接及本声明. 
原文链接: https://blog.csdn.net/hustyangju/article/details/40394003

# 参考

https://blog.csdn.net/hustyangju/article/details/40394003