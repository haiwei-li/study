
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 内存管理概述](#1-内存管理概述)
- [2. 内存大小](#2-内存大小)
  - [1.2.1 DTS 上报](#121-dts-上报)
      - [memblock](#memblock)
    - [1.2.2 ACPI 上报](#122-acpi-上报)
- [3. 物理内存映射](#3-物理内存映射)
- [4. zone 初始化](#4-zone-初始化)
- [5. 空间划分](#5-空间划分)
- [6. 物理内存初始化](#6-物理内存初始化)
- [7 小结](#7-小结)
  - [7.1 内存空间](#71-内存空间)
  - [7.2](#72)

<!-- /code_chunk_output -->

本节思考:

1. 在系统启动时, ARM Linux 内核如何知道系统中有**多大的内存空间**?
2. 在 32bit Linux 内核中, **用户空间和内核空间的比例**通常是 3:1,可以**修改**成 2:2 吗?
3. **物理内存页面**如何添加到**伙伴系统**中, 是一页一页添加, 还是以 2 的几次幂来加入呢?

在内存管理的上下文中, 初始化(initialization)可以有多种含义.在许多 CPU 上,必须**显式设置**适用于 Linux 内核的**内存模型**.在 x86_32 上需要切换到保护模式, 然后内核才能检测到可用内存和寄存器.

在初始化过程中, 还必须**建立内存管理的数据结构**,以及很多事务.因为内核在**内存管理完全初始化之前**就需要**使用内存**. 在系统启动过程期间,使用了额外的简化的内存管理模块,然后在初始化完成后,将旧的模块丢弃掉.

对**相关数据结构的初始化**是从全局启动函数**start_kernel**中开始的,该函数在加载内核并激活各个子系统之后执行. 由于内存管理是内核一个非常重要的部分,因此在特定体系结构的设置步骤中检测并确定系统中内存的分配情况后, 会立即执行内存管理的初始化.

现在大部分计算机使用**DDR**(Dual Data Rate SDRAM)的**存储设备**, DDR 包括 DDR3L、DDR4L、LPDDR3/4 等. **DDR 初始化**一般在**BIOS 或 boot loader 中**, BIOS 或 boot loader 将 DDR 大小传给内核, 因此从**Linux 内核角度**看其实就是**一段物理内存空间**.

# 1. 内存管理概述

**分层描述**的话, 内存空间可以分为 3 个层次, 分别是用户空间层、内核空间层和硬件层. 如图 2.1.

图 2.1  内存管理框图:

![config](images/1.jpg)

![config](images/4.png)

| 层次 | 描述 |
|:---:|:----|
| **用户空间层** |可以理解为 Linux 内核内存管理**为用户空间暴露的系统调用接口**. 例如**brk**(), **mmap**()等**系统调用**. 通常 libc 库会将系统调用封装成大家常见的 C 库函数, 比如 malloc(), mmap()等. |
| **内核空间层** | 包含的模块相当丰富, 用户空间和内核空间的接口时系统调用, 因此内核空间层首先需要处理这些内存管理相关的系统调用, 例如 sys_brk, sys_mmap, sys_madvise 等. 接下来就包括 VMA 管理, 缺页中断管理, 匿名页面, page cache, 页面回收, 反向映射, slab 分配器, 页面管理等模块. |
| **硬件层** | 包含**处理器**的**MMU**, **TLB**和**cache**部件, 以及板载的**物理内存**, 例如 LPDDR 或者 DDR |

用户空间和内核空间的接口是系统调用, 因此内核空间层首先需要处理这些**内存管理相关**的**系统调用**, 例如 sys_brk、sys_mmap、sys_madvise 等. 接下来就包括 VMA 管理、缺页中断管理、匿名页面、page cache、页面回收、反向映射、slab 分配器、页表管理等模块了.

最下面是硬件层, 包括处理器的 MMU、TLB 和 cache 部件, 以及板载的物理内存, 例如 LPDDR 或 DDR.

首先, 需要知道整个用户和内核空间是如何划分的(3:1、2:2), 然后从 Node->Zone->Page 的层级进行初始化, 直到内存达到可用状态.

关于 Nodes、Zones、Pages 三者之间的关系, 《ULVMM》 Figure 2.1 介绍, 虽然 zone_mem_map 一层已经被替代, 但是仍然反映了他们之间的层级树形关系.

pg_data_t 对应一个 Node, node_zones 包含了不同 Zone; **Zone**下又**定义了 per_cpu_pageset**, 将**page 和 cpu 绑定**.

![config](images/5.png)

# 2. 内存大小

## 1.2.1 DTS 上报

ARM Linux, 所有的设备的相关属性描述都采用 DTS(Device Tree Source)方式.

总结:



ARM Linux 中, **各种设备的相关属性描述(！！！**)都**采用 DTS 方式(！！！**)呈现. **DTS 是 device tree source**, 最早由 PowerPC 等其他体系结构使用的 FDT(Flattened Device Tree)转变的, ARM Linux 社区自 2011 年被 Linus 公开批评后全面支持 DTS.

在**ARM Vexpress**平台中, 内存的定义在 vexpress-v2p-ca9.dts 文件中. 该 DTS 文件定义了内存的起始地址为 0x60000000,大小为 0x40000000,即 1GB 大小内存空间.

```cpp
// [arch/arm/boot/dts/vexpress-v2p-ca9.dts]
//  http://elixir.free-electrons.com/linux/v4.13.11/source/arch/arm/boot/dts/vexpress-v2p-ca9.dts#L65

memory@60000000 {
    device_type = "memory";
    reg = <0x60000000 0x40000000>;
};
```

ARM64 平台类似, 起始地址为 `0x80000000`, 大小 `0x80000000(2GB)`.

```cpp
// http://elixir.free-electrons.com/linux/v4.13.11/source/arch/arm64/boot/dts/arm/vexpress-v2f-1xv7-ca53x2.dts#L61
memory@80000000 {
	device_type = "memory";
	reg = <0 0x80000000 0 0x80000000>; /* 2GB @ 2GB */
};
```

内核启动中, 需要解析这些 DTS 文件, 在[early_init_dt_scan_memory()](http://elixir.free-electrons.com/linux/v4.13.11/source/drivers/of/fdt.c#L1058)函数中. 代码调用关系是: start_kernel()\->setup_arch()\->setup_machine_fdt()\->early_init_dt_scan_nodes()\->**of_scan_flat_dt**(**遍历 Nodes**)->early_init_scan_memory(**初始化单个内存 node**).

```cpp
[drivers/of/fdt.c]
void __init early_init_dt_scan_nodes(void)
{
	/* Retrieve various information from the /chosen node */
	of_scan_flat_dt(early_init_dt_scan_chosen, boot_command_line);

	/* Initialize {size,address}-cells info */
	of_scan_flat_dt(early_init_dt_scan_root, NULL);

	/* Setup memory, calling early_init_dt_add_memory_arch */
	of_scan_flat_dt(early_init_dt_scan_memory, NULL);
}
```
最终**early_init_dt_scan_nodes**()调用了**early_init_dt_scan_memory**函数读取 DTS 的信息并初始化内存信息.
```cpp
[drivers/of/fdt.c]

/**
 * early_init_dt_scan_memory - Look for and parse memory nodes
 */
int __init early_init_dt_scan_memory(unsigned long node, const char *uname,
				     int depth, void *data)
{
	const char *type = of_get_flat_dt_prop(node, "device_type", NULL);
	const __be32 *reg, *endp;
	int l;
	bool hotpluggable;

	/* We are scanning "memory" nodes only */
	if (type == NULL) {
		/*
		 * The longtrail doesn't have a device_type on the
		 * /memory node, so look for the node called /memory@0.
		 */
		if (!IS_ENABLED(CONFIG_PPC32) || depth != 1 || strcmp(uname, "memory@0") != 0)
			return 0;
	} else if (strcmp(type, "memory") != 0)
		return 0;

	reg = of_get_flat_dt_prop(node, "linux,usable-memory", &l);
	if (reg == NULL)
		reg = of_get_flat_dt_prop(node, "reg", &l);
	if (reg == NULL)
		return 0;

	endp = reg + (l / sizeof(__be32));
	hotpluggable = of_get_flat_dt_prop(node, "hotpluggable", NULL);

	pr_debug("memory scan node %s, reg size %d,\n", uname, l);

	while ((endp - reg) >= (dt_root_addr_cells + dt_root_size_cells)) {
		u64 base, size;

		base = dt_mem_next_cell(dt_root_addr_cells, &reg);
		size = dt_mem_next_cell(dt_root_size_cells, &reg);

		if (size == 0)
			continue;
		pr_debug(" - %llx ,  %llx\n", (unsigned long long)base,
		    (unsigned long long)size);

		early_init_dt_add_memory_arch(base, size);

		if (!hotpluggable)
			continue;

		if (early_init_dt_mark_hotplug_memory_arch(base, size))
			pr_warn("failed to mark hotplug range 0x%llx - 0x%llx\n",
				base, base + size);
	}

	return 0;
}
```

解析 "memory" 描述的信息从而**得到内存的 base_address 和 size 信息**, 最后**内存块信息**通过**early_init_dt_add_memory_arch**()\-\> **memblock_add**() \-\> **memblock_add_range**函数**添加到 memblock 子系统**中.

```
struct memblock {
    bool bottom_up;  /* is bottom up direction? */
    phys_addr_t current_limit;
    struct memblock_type memory;   #添加物理内存区域
    struct memblock_type reserved; #添加预留内存区域
#ifdef CONFIG_HAVE_MEMBLOCK_PHYS_MAP
    struct memblock_type physmem;
#endif
};
```

memblock_add 用于添加**region**到**memblock.memory**中; 在**内核初始化阶段**很多地方(比如**arm_memblock_init**)使用**memblock_reserve**将**region 添加到 memblock.reserved**.

**memblock_remove**用于将**一个 region**从**memblock.memory 中移除**, **memblock_free**等用于将**一个 region**从**memblock.reserved 中移除**.

这里面的地址都是**物理地址**, 所有的信息都在**memblock 这个全局变量**中.

```cpp
[mm/memblock.c]
int __init_memblock memblock_add_range(struct memblock_type *type,
                phys_addr_t base, phys_addr_t size,
                int nid, unsigned long flags)
{
    bool insert = false;
    phys_addr_t obase = base;
    phys_addr_t end = base + memblock_cap_size(base, &size);
    int i, nr_new;

    if (!size)
        return 0;

    /* special case for empty array */
    if (type->regions[0].size == 0) {
        WARN_ON(type->cnt != 1 || type->total_size);
        type->regions[0].base = base;
        type->regions[0].size = size;
        type->regions[0].flags = flags;
        memblock_set_region_node(&type->regions[0], nid);
        type->total_size = size;
        return 0;
    }
repeat:
    /*
     * The following is executed twice.  Once with %false @insert and
     * then with %true.  The first counts the number of regions needed
     * to accomodate the new area.  The second actually inserts them.
     */
    ...
}
```

#### memblock

在**内核启动阶段**, 也有内存管理的需求, 但是此时**伙伴系统并没有完成初始化**. 在早期内核中使用**bootmem 机制**, 作为内核初始化阶段的**内存分配器**.

后来使用 memblock 作为内核初始化阶段内存分配器, 用于内存分配和释放.

**CONFIG_NO_BOOTMEM**用于决定是否使用 bootmem, Vexpress 使能, 所以使用 memblock 作为初始化阶段的内存分配器.

因为 bootmem 和 memblock 两者**API 兼容**, 所以使用者无感. 使用**memblock**的时候编译**mm/nobootmem.c**, 调用 memblock.c 中的分配器接口.

### 1.2.2 ACPI 上报

待补充

# 3. 物理内存映射

由于没有打开 CONFIG_ARM_LPAE, Linux 页表采用两层映射. 所以 PGD->PUD->PMD->PTE 中间的 PUD/PMD 被省略的, pmd_off_k 的返回值实际就是 pgd_offset_k.

```cpp
[arch\arm\mm\mm.h]
static inline pmd_t *pmd_off_k(unsigned long virt)
{
    return pmd_offset(pud_offset(pgd_offset_k(virt), virt), virt);
}

[arch\arm\include\asm\pgtable.h]
#define pgd_index(addr)        ((addr) >> PGDIR_SHIFT)
#define pgd_offset(mm, addr)    ((mm)->pgd + pgd_index(addr))

/* to find an entry in a kernel page-table-directory */
// 实际就是 addr 右移 PGDIR_SHIFT 位, 然后相对于 init_mm.pgd 即 swapper_pg_dir 的偏移.
#define pgd_offset_k(addr)    pgd_offset(&init_mm, addr)
#swapper_pg_dir 是存放内核页表的地方.
```

在内核**使用内存前**, 需要**初始化内核的页表**, 初始化页表主要在**map_lowmem**()函数中. 在**映射页表之前**, 需要**把页表的页表项清 0**, 主要在**prepare_page_table**()函数中实现.

```cpp
[start_kernel() ->setup_arch() ->paging_init() -> prepare_page_table()]
[arch/arm/mm/mmu.c]
static inline void prepare_page_table(void)
{
    unsigned long addr;
    phys_addr_t end;

    /*
     * Clear out all the mappings below the kernel image.
     */
    for (addr = 0; addr < MODULES_VADDR; addr += PMD_SIZE) #清除 0~MODULES_VADDR 地址段一级页表.
        pmd_clear(pmd_off_k(addr));

#ifdef CONFIG_XIP_KERNEL
    /* The XIP kernel is mapped in the module area -- skip over it */
    addr = ((unsigned long)_etext + PMD_SIZE - 1) & PMD_MASK;
#endif
    for ( ; addr < PAGE_OFFSET; addr += PMD_SIZE) #清除 MODULES_VADDR~PAGE_OFFSET 地址段一级页表.
        pmd_clear(pmd_off_k(addr));

    /*
     * Find the end of the first block of lowmem.
     */
    end = memblock.memory.regions[0].base + memblock.memory.regions[0].size;
    if (end >= arm_lowmem_limit) #end=0x60000000+0x40000000, arm_lowmem_limit=0x8f800000
        end = arm_lowmem_limit;

    /*
     * Clear out all the kernel space mappings, except for the first
     * memory bank, up to the vmalloc region.
     */
    for (addr = __phys_to_virt(end);
         addr < VMALLOC_START; addr += PMD_SIZE) #此处 end 取 0x8f800000, 转成虚拟地址 0xef800000.
        pmd_clear(pmd_off_k(addr)); #清除 0xef800000~VMALLOC_START 地址段一级页表.
}
```

这里对如下 3 段地址调用 pmd_clear()函数来**清除一级页表项**的内容.

- 0x0 \~ MODULES_VADDR.
- MODULES_VADDR \~ PAGE_OFFSET.
- arm_lowmem_limit(0xef800000)\~ VMALLOC_START.

```cpp
[start_kernel() ->setup_arch() ->paging_init() ->map_lowmem()]
[arch/arm/mm/mmu.c]
static void __init map_lowmem(void)
{
    struct memblock_region *reg;
    phys_addr_t kernel_x_start = round_down(__pa(_stext), SECTION_SIZE); #kernel_x_start=0x60000000
    phys_addr_t kernel_x_end = round_up(__pa(__init_end), SECTION_SIZE); #kernel_x_end=60800000

    /* Map all the lowmem memory banks. */
    for_each_memblock(memory, reg) {
        phys_addr_t start = reg->base;       #start=0x60000000
        phys_addr_t end = start + reg->size; #end=0x60000000+0x40000000
        struct map_desc map;

        if (end > arm_lowmem_limit)
            // 因为 arm_lowmem_limit=0x8f800000, 所以 end=0x8f800000
            end = arm_lowmem_limit;
        if (start >= end)
            break;

        if (end < kernel_x_start) {
            map.pfn = __phys_to_pfn(start);
            map.virtual = __phys_to_virt(start);
            map.length = end - start;
            map.type = MT_MEMORY_RWX;

            create_mapping(&map);
        } else if (start >= kernel_x_end) {
            map.pfn = __phys_to_pfn(start);
            map.virtual = __phys_to_virt(start);
            map.length = end - start;
            map.type = MT_MEMORY_RW;

            create_mapping(&map);
        } else {
            /* This better cover the entire kernel */
            if (start < kernel_x_start) {
                map.pfn = __phys_to_pfn(start);
                map.virtual = __phys_to_virt(start);
                map.length = kernel_x_start - start;
                map.type = MT_MEMORY_RW;

                create_mapping(&map);
            }

            map.pfn = __phys_to_pfn(kernel_x_start);
            map.virtual = __phys_to_virt(kernel_x_start);
            map.length = kernel_x_end - kernel_x_start;
            map.type = MT_MEMORY_RWX;
            // 创建虚拟地址 0xc0000000 - 0xc0800000 到物理地址 0x60000000 - 0x60800000 的映射关系, 属性为 MT_MEMORY_RWX.
            create_mapping(&map);

            if (kernel_x_end < end) {
                map.pfn = __phys_to_pfn(kernel_x_end);
                map.virtual = __phys_to_virt(kernel_x_end);
                map.length = end - kernel_x_end;
                map.type = MT_MEMORY_RW;
                // 创建虚拟地址 0xc0800000 - 0xef800000 到物理地址 0x60800000 - 0x8f800000 的映射关系, 属性为 MT_MEMORY_RW.
                create_mapping(&map);
            }
        }
    }
}
```

真正创建页表是在**map_lowmem()函数**中, 会从内存开始的地方覆盖到 arm_lowmem_limit 处. 这里需要考虑 kernel 代码段的问题, kernel 的代码段从_stext 幵始, 到_init_end 结束. 以 ARM Vexpress 平台为例.

- 内存开始地址 0x60000000.
- _stext: 0x60000000.
- _init_end: 0x60800000(该值与实际内核配置和 image 大小相关).
- arm_lowmem_limit: 0x8f800000.

其中, arm_lowmem_limit 地址需要考虑高端内存的情况, 该值的计算是在 sanity_check_meminfo()函数中. 在 ARM Vexpress 平台中, arm_lowmem_limit 等于 vmalloc_min, 其定义如下:

```cpp
static void * __initdata vmalloc_min =
    (void *) (VMALLOC_END - (240 « 20) - VMALLOC_OFFSET);

phys_addr_t vmalloc_limit = __pa(vmalloc_min - 1) + 1
```

map_lowmem()会对两个内存区间创建映射.

(1)区间 1

- 物理地址: 0x60000000\~0x60800000.
- 虚拟地址: 0xc0000000\~0xc0800000.
- 属性: 可读、可写并且可执行(MT_MEMORY_RWX).
- 主要用于存放 Kernel 代码数据段, 还包括 swapper_pg_dir 内容.

(2)区间 2

- 物理地址: 0x60800000\~0x8f800000.
- 虚拟地址: 0xc0800000\~0xef800000.
- 属性: 可读、可写、不可执行(MT_MEMORY_RW ).
- Normal Memory 部分.

MT_MEMORY_RWX 和 MT_MEMORY_RW 的区别在于 ARM 页表项有一个 XN 比特位, XN 比特位置为 1 , 表示这段内存区域不允许执行.

映射函数为 create_mapping(),这里创建的映射就是**物理内存直接映射**, 即**线性映射**, 该函数会在第 2.2 节中详细介绍.

# 4. zone 初始化

对**页表的初始化**完成之后, 内核就可以**对内存进行管理**了, 但是**内核并不是统一对待这些页面**, 而是**采用层次化管理**.

Linux 把**物理内存**划分为**三个层次**来管理

| 层次 | 描述 |
|:----|:----|
| **存储节点(Node**) |  CPU 被划分为**多个节点(node**), **内存则被分簇**, **每个 CPU**对应一个**本地物理内存**, 即**一个 CPU\-node**对应一个**内存簇 bank**, 即**每个内存簇**被认为是**一个节点** |
| **管理区(Zone**)   | **每个物理内存节点 node**被划分为**多个内存管理区域**, 用于表示**不同范围的内存**, 内核可以使用**不同的映射方式(！！！**)映射物理内存 |
| **页面(Page**) | 内存被细分为**多个页面帧**, **页面**是**最基本的页面分配的单位**　｜

为了支持 NUMA 模型, 也即 CPU 对不同内存单元的访问时间可能不同, 此时系统的物理内存被划分为几个节点(node), 一个 node 对应一个内存簇 bank, 即每个内存簇被认为是一个节点

- 首先, 内存被划分为**结点**. **每个节点**关联到系统中的**一个处理器**, 内核中表示为**pg_data_t 的实例**. 定义了一个**大小为 MAX_NUMNODES 类型为 pg_data_t**的**数组 node_data**,数组的大小根据**CONFIG_NODES_SHIFT**的配置决定. 对于 UMA 来说, NODES_SHIFT 为 0, 所以 MAX_NUMNODES 的值为 1.    而对于 PC 这种**UMA 结构**的机器来说, 只使用了一个成为**contig_page_data**的静态 pg_data_t 结构.

- 各个节点又被划分为内存管理区域, 一个**管理区域**通过**struct zone_struct**描述, 其被定义为**zone_t**, 用以表示内存的某个范围,**低端范围的 16MB**被描述为**ZONE_DMA**,某些**工业标准体系结构中的(ISA)设备**需要用到它,然后是可**直接映射到内核**的**普通内存域 ZONE_NORMAL**,最后是超出了内核段的物理地址域 ZONE_HIGHMEM, 被称为高端内存. 是系统中预留的可用内存空间, 不能被内核直接映射.

- 最后**页帧(page frame**)代表了系统内存的最小单位, 堆内存中的每个页都会创建一个 struct page 的一个实例. 传统上, 把内存视为连续的字节, 即内存为字节数组, 内存单元的编号(地址)可作为字节数组的索引. 分页管理时, 将若干字节视为一页, 比如 4K byte. 此时, 内存变成了连续的页, 即内存为页数组, 每一页物理内存叫页帧, 以页为单位对内存进行编号, 该编号可作为页数组的索引, 又称为页帧号.

在一个**单独的节点**内, **任一给定 CPU**访问页面**所需的时间都是相同**的. 然而, 对**不同的 CPU**, 这个时间可能就不同. 对每个 CPU 而言, 内核都试图把耗时节点的访问次数减到最少这就要小心地选择 CPU 最常引用的内核数据结构的存放位置.

其中 zone 结构的定义用 struct zone. struct zone 数据结构的主要成员如下:

```cpp
struct zone {
    /* Read-mostly fields */

    /* zone watermarks, access with *_wmark_pages(zone) macros */
    unsigned long watermark[NR_WMARK];
    long lowmem_reserve[MAX_NR_ZONES];

#ifdef CONFIG_NUMA
    int node;
#endif
    struct pglist_data  *zone_pgdat;
    struct per_cpu_pageset __percpu *pageset;

    /* zone_start_pfn == zone_start_paddr >> PAGE_SHIFT */
    unsigned long       zone_start_pfn;
    unsigned long       managed_pages;
    unsigned long       spanned_pages;
    unsigned long       present_pages;

    const char      *name;

    /* Write-intensive fields used from the page allocator */
    ZONE_PADDING(_pad1_)           ## 重要
    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];
    /* zone flags, see below */
    unsigned long       flags;
    /* Primarily protects free_area */
    spinlock_t      lock;         ## 重要

    /* Write-intensive fields used by compaction and vmstats. */
    ZONE_PADDING(_pad2_)
    spinlock_t  lru_lock;         ## 重要
    struct lruvec  lruvec;         ## 重要

    ZONE_PADDING(_pad3_)         ## 重要
    /* Zone statistics */
    atomic_long_t       vm_stat[NR_VM_ZONE_STAT_ITEMS];
} ____cacheline_internodealigned_in_smp;
```

首先 struct zone 是经常会被访问到的, 因此这个数据结构要求**以 L1 Cache 对齐**. 另外, 这里的**ZONE_PADDING**()是让 zone->lock 和 zone->lru_lock 这两个很热门的锁可以分布在不同的 cache line 中. **一个内存节点最多也就几个 zone**, 因此 zone 数据结构**不需要**像**struct page**—样关注**数据结构的大小**, 因此这里 ZONE_PADDING()可以**为了性能而浪费空间**. 在内存管理开发过程中, 内核开发者逐步发现有一些**自旋锁**会**竞争**得非常厉害, **很难获取**. 像 zone->lock 和 zone->lru_lock 这两个锁有时需要**同时获取锁**, 因此保证它们**使用不同的 cache line**是内核常用的一种优化技巧.

- watermark: 每个 zone 在系统启动时会计算出 3 个水位值, 分别是 WMARK_MIN、WMARK_LOW 和 WMARK_HIGH 水位, 这在**页面分配器**和**kswapd 页面回收**中会用到.
- lowmem_reserve: zone 中预留的内存.
- zone_pgdat: 指向**内存节点**.
- pageset: 用于维护 Per-CPU 上的**一系列页面**, 以**减少自旋锁的争用**.
- zone_start_pfn: zone 中**开始页面**的**页帧号**.
- managed_pages: zone 中被**伙伴系统管理**的**页面数量**.
- spanned_pages: zone 包含的**页面数量**.
- present_pages: zone 里**实际管理的页面数量**. 对一些体系结构来说, 其值和 spanned_pages 相等.
- free_area: 管理**空闲区域的数组**, 包含管理链表等.
- lock: 并行访问时用于对**zone 保护的自旋锁**.
- lru_lock: 用于对 zone 中**LRU 链表**并行访问时进行保护的**自旋锁**.
- lruvec: **LRU 链表集合**.
- vm_stat: **zone 计数**.

通常情况下, 内核的 zone 分为 ZONE_DMA、ZONE_DMA32、ZONE_NORMAL 和 ZONE_HIGHMEM. 在**ARM Vexpress**平台中, 没有定义 CONFIG_ZONE_DMA 和 CONFIG_ZONE_DMA32,所以只有**ZONE_NORMAL**和**ZONE_HIGHMEM**两种. zone 类型的定义在 include/linux/mmzone.h 文件中.

```cpp
enum zone_type {
    ZONE_NORMAL,
#ifdef CONFIG_HIGHMEM
    ZONE_HIGHMEM,
#endif
    ZONE_MOVABLE,
    _MAX_NR_ZONES
};
```

**zone 的初始化函数**集中在**bootmem_init**()中完成, 所以需要确定**每个 zone 的范围**. 在**find_limits**()函数中会计算出 min_low_pfn、max_low_pfn 和 max_pfn 这 3 个值. 其中, min_low_pfn 是**内存块**的**开始地址**的**页帧号**(0x60000), max_low_pfn(0x8f800)表示**normal 区域**的**结束页帧号**, 它由 arm_lowmem_limit 这个变量得来, max_pfn(0xa0000) 是**内存块**的**结束地址的页帧号**.

下面是 ARM Vexpress 平台运行之后打印出来的 zone 的信息.

```
Normal zone: 1520 pages used for memmap
Normal zone: 0 pages reserved
Normal zone: 194560 pages, LIFO batch:31 //ZONE_NORMAL
HighMem zone: 67584 pages, LIFO batch:15 //ZONE_HIGHMEM

Virtual kernel memory layout:
    vector  : 0xffff0000 - 0xffff1000       (   4 KB)
    fixmap  :  0xffc00000 - 0xfff00000      (3072 KB)
    vmalloc : 0x£0000000 - 0xff000000       ( 240 MB)
    lowmem : 0xc0000000 - 0xef800000        ( 760 MB)
    pkmap  : 0xbfe00000 - 0xc0000000        (   2 MB)
    modules  :  0xbf000000 - 0xbfe00000     (  14 MB)
    .text : 0xc0008000 - 0xc0676768         (6586 KB)
    .init : 0xc0677000 - 0xc07a0000         (1188 KB)
    .data : 0xc07a0000 - 0xc07cf938         ( 191 KB)
    .bss : 0xc07cf938 - 0xc07f9378          ( 167 KB)
```

可以看出 ARM Vexpress 平台分为两个 zone, ZONE_NORMAL 和 ZONE_HIGHMEM. 其中 ZONE_NORMAL 是从 0xc0000000 到 0xef800000, 这个地址空间有多少个页面呢?

```
(Oxef800000 - Oxc0000000 ) / 4096 = 194560
```

所以 ZONE_NORMAL 有 194560 个页面.

另外 ZONE_NORMAL 的虚拟地址的结束地址是 Oxef800000, 减去 PAGE_OFFSET(Oxc00000), 再加上 PHY_OFFSET(0x60000000), 正好等于 0x8f80_0000,这个值等于我们之前计算出的 arm_lowmem_limit.

zone 的初始化函数在 free_area_init_core()中.

```cpp[start_kernel->setup_arch->paging_init->bootmem_init->zone_sizes_init->free_area_init_node -> free_area_init_core]
[mm/page_alloc.c]
static void __paginginit free_area_init_core(struct pglist_data *pgdat)
{
	enum zone_type j;
	int nid = pgdat->node_id;
	int ret;

	pgdat_resize_init(pgdat);
#ifdef CONFIG_NUMA_BALANCING
	spin_lock_init(&pgdat->numabalancing_migrate_lock);
	pgdat->numabalancing_migrate_nr_pages = 0;
	pgdat->numabalancing_migrate_next_window = jiffies;
#endif
#ifdef CONFIG_TRANSPARENT_HUGEPAGE
	spin_lock_init(&pgdat->split_queue_lock);
	INIT_LIST_HEAD(&pgdat->split_queue);
	pgdat->split_queue_len = 0;
#endif
	init_waitqueue_head(&pgdat->kswapd_wait);
	init_waitqueue_head(&pgdat->pfmemalloc_wait);
#ifdef CONFIG_COMPACTION
	init_waitqueue_head(&pgdat->kcompactd_wait);
#endif
	pgdat_page_ext_init(pgdat);

	for (j = 0; j < MAX_NR_ZONES; j++) {
		struct zone *zone = pgdat->node_zones + j;
		unsigned long size, realsize, freesize, memmap_pages;
		unsigned long zone_start_pfn = zone->zone_start_pfn;

		size = zone->spanned_pages;
		realsize = freesize = zone->present_pages;

		/*
		 * Adjust freesize so that it accounts for how much memory
		 * is used by this zone for memmap. This affects the watermark
		 * and per-cpu initialisations
		 */
		memmap_pages = calc_memmap_size(size, realsize);
		if (!is_highmem_idx(j)) {
			if (freesize >= memmap_pages) {
				freesize -= memmap_pages;
				if (memmap_pages)
					printk(KERN_DEBUG
					       "  %s zone: %lu pages used for memmap\n",
					       zone_names[j], memmap_pages);
			} else
				pr_warn("  %s zone: %lu pages exceeds freesize %lu\n",
					zone_names[j], memmap_pages, freesize);
		}

		/* Account for reserved pages */
		if (j == 0 && freesize > dma_reserve) {
			freesize -= dma_reserve;
			printk(KERN_DEBUG "  %s zone: %lu pages reserved\n",
					zone_names[0], dma_reserve);
		}

		if (!is_highmem_idx(j))
			nr_kernel_pages += freesize;
		/* Charge for highmem memmap if there are enough kernel pages */
		else if (nr_kernel_pages > memmap_pages * 2)
			nr_kernel_pages -= memmap_pages;
		nr_all_pages += freesize;

		/*
		 * Set an approximate value for lowmem here, it will be adjusted
		 * when the bootmem allocator frees pages into the buddy system.
		 * And all highmem pages will be managed by the buddy system.
		 */
		zone->managed_pages = is_highmem_idx(j) ? realsize : freesize;
#ifdef CONFIG_NUMA
		zone->node = nid;
		zone->min_unmapped_pages = (freesize*sysctl_min_unmapped_ratio)
						/ 100;
		zone->min_slab_pages = (freesize * sysctl_min_slab_ratio) / 100;
#endif
		zone->name = zone_names[j];
		spin_lock_init(&zone->lock);
		spin_lock_init(&zone->lru_lock);
		zone_seqlock_init(zone);
		zone->zone_pgdat = pgdat;
		zone_pcp_init(zone);

		/* For bootup, initialized properly in watermark setup */
		mod_zone_page_state(zone, NR_ALLOC_BATCH, zone->managed_pages);

		lruvec_init(&zone->lruvec);
		if (!size)
			continue;

		set_pageblock_order();
		setup_usemap(pgdat, zone, zone_start_pfn, size);
		ret = init_currently_empty_zone(zone, zone_start_pfn, size);
		BUG_ON(ret);
		memmap_init(size, nid, j, zone_start_pfn);
	}
}
```

另外系统中会有一个**zondist 的数据结构**,**伙伴系统**分配器会**从 zonelist 开始分配内存**, zonelist 有一个**zoneref 数组**, 数组里有一个成员会**指向 zone 数据结构**. zoneref 数组的第一个成员指向的 zone 是页面分配器的第一个候选者, 其他成员则是第一个候选者分配失败之后才考虑, **优先级逐渐降低**. zonelist 的初始化路径如下:

```cpp
[start_kernel->build_all_zonelists->build_all_zonelists_init->
__build_all_zonelists->build_zonelists->build_zonelists_node]
static int build_zonelists_node(pg_data_t *pgdat, struct zonelist *zonelist,
                    int nr_zones)
{
    struct zone *zone;
    enum zone_type zone_type = MAX_NR_ZONES;

    do {
        zone_type--;
        zone = pgdat->node_zones + zone_type;
        if (populated_zone(zone)) {
            zoneref_set_zone(zone,
                &zonelist->_zonerefs[nr_zones++]);
            check_highest_zone (zone_type);
        }
    } while (zone_type);

    return nr_zones;
}
```

从最高的 MAX_NR_ZONES 的 zone 开始, 设置到_zonerefs[0]数组中. 在 ARM Vexpress 平台中, 运行结果如下:

```
HighMem  _zonerefs[0]->zone_index=l
Normal   _zonerefs[1]->zone_index=0
```

这个页面分配器在 2.4 会讲.

另外, 系统中还有一个非常重要的**全局变量 mem_map**, 它是一个**struct page 的数组**, 可以实现快速地把**虚拟地址**映射到**物理地址**中, 这里指**内核空间的线性映射**, 它的初始化是在 free_area_init_node()->alloc_node_mem_map()函数中.

# 5. 空间划分

在 32bit Linux 中 , 一共能使用的**虚拟地址空间是 4GB**,用户空间和内核空间的划分通常是按照 3:1 来划分, 也可以按照 2:2 来划分.

```cpp
[arch/arm/Kconfig]
choice
    prompt "Memory split"
    depends on MMU
    default VMSPLIT_3G
    help
      Select the desired split between kernel and user memory.

      If you are not absolutely sure what you are doing, leave this
      option alone!

    config VMSPLIT_3G
        bool "3G/1G user/kernel split"
    config VMSPLIT_3G_OPT
        depends on !ARM_LPAE
        bool "3G/1G user/kernel split (for full 1G low memory)"
    config VMSPLIT_2G                     ### !!!
        bool "2G/2G user/kernel split"
    config VMSPLIT_1G
        bool "1G/3G user/kernel split"
endchoice

config PAGE_OFFSET
    hex
    default PHYS_OFFSET if !MMU
    default 0x40000000 if VMSPLIT_1G
    default 0x80000000 if VMSPLIT_2G
    default 0xB0000000 if VMSPLIT_3G_OPT
    default 0xC0000000
```

在 ARM Linux 中有一个配置选项"memory split", 可以用于**调整内核空间和用户空间的大小划分**. 通常使用"VMSPLIT_3G"选项, 用户空间大小是 3GB , 内核空间大小是 1GB ,那么**PAGE_OFFSET**描述**内核空间的偏移量**就等于**0xC0000000**(**等于 2\^31+2\^30=3GB**). 也可以选择"VMSPLIT_2G"选项, 这时内核空间和用户空间的大小都是 2GB,PAGE_OFFSET 就等于**0x80000000**(**等于 2\^31=2GB**).

这样配置的结果就是生成的 autoconf.h(**include/generated/autoconf.h**)定义了#define CONFIG_PAGE_OFFSET 0xC0000000.

内核中通常会使用**PAGE_OFFSET 这个宏**来计算**内核线性映射中虚拟地址和物理地址的转换**.

```
[arch/arm/include/asm/memory.h]

/* PAGE_OFFSET - the virtual address of the start of the kernel image */
#define PAGE_OFFSET  UL(CONFIG_PAGE_OFFSET)
```

线性映射的**物理地址**等于**虚拟地址**vaddr 减去 PAGE_OFFSET (0xC000_0000)再**加上 PHYS_OFFSET**(在部分 ARM 系统中该值为 0).

```
[arch/arm/include/asm/memory.h]

static inline phys_addr_t __virt_to_phys_nodebug(unsigned long x)
{
    return (phys_addr_t)x - PAGE_OFFSET + PHYS_OFFSET;
}

static inline unsigned long __phys_to_virt(phys_addr_t x)
{
    return x - PHYS_OFFSET + PAGE_OFFSET;
}
```

# 6. 物理内存初始化

在内核启动时, 内核知道物理内存 DDR 的大小并且计算出**高端内存**的**起始地址**和**内核空间的内存布局**后, 物理内存页面 page 就要加入到伙伴系统中, 那么**物理内存页面**如何添加到**伙伴系统**中呢?

伙伴系统(**Buddy System**)是操作系统中最常用的一种**动态存储管理方法**, 在用户提出申请时, 分配一块大小合适的内存块给用户, 反之在用户释放内存块时回收. 在伙伴系统中, **内存块是 2 的 order 次幂**. Linux 内核中**order 的最大值用 MAX_ORDER**来表示, 通常是 11,也就是把所有的空闲页面分组成**11 个内存块链表**, 每个内存块链表分别包括 1、2、4、8、16、32、...、1024 个**连续的页面**(**连续页面！！！**). **1024 个页面对应着 4MB 大小的连续物理内存**.

**物理内存**在 Linux 内核中分出**几个 zone**来管理, zone 根据内核的配置来划分, 例如在 ARM Vexpress 平台中, zone 分为 ZONE_NORMAL 和 ZONE_HIGHMEM.

伙伴系统的空闲页块的管理如图 2.2 所示, **zone 数据结构**中有一个**free_area 数组**, **数组的大小是 MAX_ORDER**. free_area 数据结构中包含了**MIGRATE_TYPES 个链表**, 这里相当于 zone 中根据 order 的大小有 0 到 MAX_ORDER - l 个 free_area, 每个 free_area 根据 MIGRATE_TYPES 类型有几个相应的链表.

图 2.2  伙伴系统的空闲页块管理:

![config](images/2.jpg)

```
[include/linux/mmzone.h]

struct zone{
    ...
    /* free areas of different sizes */
    struct free_area    free_area[MAX_ORDER];
    ...
};

struct free_area {
    struct list_head    free_list[MIGRATE_TYPES];
    unsigned long       nr_free;
};
```

MIGRATE_TYPES 类型的定义也在 mmzone.h 文件中.

```
[include/1inux/mmzone.h]

enum migratetype {
    MIGRATE_UNMOVABLE,
    MIGRATE_MOVABLE,
    MIGRATE_RECLAIMABLE,
    MIGRATE_PCPTYPES,   /* the number of types on the pcp lists */
    MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
    MIGRATE_CMA,
#endif
#ifdef CONFIG_MEMORY_ISOLATION
    MIGRATE_ISOLATE,    /* can't allocate from here */
#endif
    MIGRATE_TYPES
};
```

MIGRATE_TYPES 类型包含 MIGRATE_UNMOVABLE、MIGRATE_RECLAIMABLE、MIGRATE_MOVABLE 等几种类型. 当前页面分配的状态可以从**/proc/pagetypeinfo**中获取得到.

图 2.3  ARM Vexpress 平台 pagetypeinfo 信息:

![config](images/3.png)

从 pagetypeinfo 可以看出两个特点:

- 大部分物理内存页面都存放在 MIGRATE_MOVABLE 链表中.
- 大部分物理内存页面初始化时存放在**2 的 10 次幂的链表**中.

Linux 内核初始化时究竟有多少页面是 MIGRATE_MOVABLE?

内存管理中有一个**pageblock**的概念, 一个 pageblock 的大小通常是(MAX_ORDER - l)个页面. 如果体系结构中提供了**HUGETLB_PAGE**特性, 那么 pageblock_order 定义为**HUGETLB_PAGE_ORDER**.

```
[include/linux/pageblock-flags.h]

#ifdef CONFIG_HUGETLB_PAGE

#ifdef CONFIG_HUGETLB_PAGE_SIZE_VARIABLE

/* Huge page sizes are variable */
extern unsigned int pageblock_order;

#else /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */

/* Huge pages are a constant size */
#define pageblock_order     HUGETLB_PAGE_ORDER
#endif /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */

#else /* CONFIG_HUGETLB_PAGE */

/* If huge pages are not used, group by MAX_ORDER_NR_PAGES */
#define pageblock_order     (MAX_ORDER-1)

#endif /* CONFIG_HUGETLB_PAGE */
```

**每个 pageblock**有一个**相应的 MIGRATE_TYPES 类型**. **zone 数据结构**中有一个成员指针**pageblock_flags**,它指向用于存放**每个 pageblock**的**MIGRATE_TYPES 类型的内存空间**. pageblock_flags 指向的内存空间的大小通过 usemap_size()函数来计算, 每个 pageblock 用 4 个比特位来存放 MIGRATE_TYPES 类型.

zone 的初始化函数 free_area_init_core()会调用 setup_usemap()函数来计算和分配 pageblock_flags 所需要的大小, 并且分配相应的内存.

```
[free_area_init_core -> setup_usemap -> usemap_size]

[mm/page_alloc.c]

static unsigned long __init usemap_size(unsigned long zone_start_pfn, unsigned long zonesize)
{
    unsigned long usemapsize;

    zonesize += zone_start_pfn & (pageblock_nr_pages-1);
    usemapsize = roundup(zonesize, pageblock_nr_pages);
    usemapsize = usemapsize >> pageblock_order;
    usemapsize *= NR_PAGEBLOCK_BITS;
    usemapsize = roundup(usemapsize, 8 * sizeof(unsigned long));

    return usemapsize / 8;
}
```

usemap_size()函数**首先计算 zone 有多少个 pageblock**,每个 pageblock 需要 4bit 来存放 MIGRATE_TYPES 类型, 最后可以计算出需要多少 Byte. 然后通过 memblock_virt_alloc_try_nid_nopanic()来分配内存, 并且 zone->pageblock_flags 成员指向这段内存.

例如在 ARM Vexpress 平台, ZONE_NORMAL 的大小是 760MB, 每个 pageblock 大小是 4MB,那么就有 190 个 pageblock,每个 pageblock 的 MIGRATE_TYPES 类型需要 4bit,所以管理这些 pageblock, 需要 96Byte.

内核有两个函数来管理这些迁移类型: get_pageblock_migratetype()和 set_pageblock_migratetype(). 内核**初始化**时**所有的页面**最初都标记为**MIGRATE_MOVABLE**类型, 见 free_area_init_core()->memmap_init()函数.

```cpp
// [start_kernel()->setup_arch()->paging_init()->bootmem_init()->zone_sizes_init()
->free_area_init_node()->free_area_init_core()->memmap_init()]

void __meminit memmap_init_zone (unsigned long size, int nid, unsigned long zone,
        unsigned long start_jpfn, enum memmap_context context)
{
    struct page *page;
    unsigned long end_pfn = start_pfn + size;
    unsigned long pfn;
    struct zone *z;

    z =  &NODE_DATA (nid) ->node zones [zone];
    for (pfn = start_pfn; pfn < end_pfn; pfn++) {
        page = pfn_to._page (pfn);
        init_page_count(page);
        page_mapcount_reset(page);
        page_cpupid—reset—last(page);
        SetPageReserved(page);

        if ((z->zone_start_pfn <= pfn)
            && (pfn < zone end_pfn(z))
            && ! (pfn & (pageblock_nr_pages - 1)))
            set_pageblock_migratetype  (page, MIGRATE_MOVABLE);

        INIT_LIST_HEAD(&page->lru);
    }
}
```

set_pageblock_migratetype()用于设置指定 pageblock 的 MIGRATE_TYPES 类型, 最后调用 set_pfnblock_flags_mask()来设置 pagelock 的迁移类型.

**物理页面是如何加入到伙伴系统的?是一页一页地添加, 还是以 2 的几次幂来加入吗**?

在 free_low_memory_core_early()函数中, 通过 for_each_free_mem_range()函数来**遍历所有的 memblock 内存块**, 找出内存块的起始地址和结束地址.

```cpp
// [staxt_kemel-> mm_init-> mem_init-> free_all_bootmem-> free_low_memory_core_early]

[mm/nobootmem.c]

static unsigned long __init free_low_memory_core_early(void)
{
    unsigned long count = 0;
    phys_addr_t start, end;
    u64 i;

    memblock_clear_hotplug(0, -1);

    for_each_free_mem_range(i, NUMA_NO_NODE, &start, &end,NULL)
        count += __free_memory_core(start, end);

    return count;
}
```

把内存块传递函数中 , 该函数定义如下:

```cpp
// [mm/nobootmem.c]

static inline unsigned long _ffs(unsigned long x)
{
    return ffs(x) - 1;
}

static void __init __free_pages_memory(unsigned long start, unsigned long end)
{
    int order;

    while (start < end) {
        order = min(MAX_ORDER - 1UL, __ffs(start));

        while (start + (1UL << order) > end)
            order--;

        __free_pages_bootmem(pfn_to_page(start), start, order);
        start += (1UL << order);
    }
}
```

注意这里参数**start 和 end 指页帧号**, while 循环一直从起始页帧号 start 遍历到 end, 循环的**步长和 order 有关**. 首先计算 order 的大小, 取**MAX_ORDER-l**和__ffs(start)的最小值. ffs(start)函数**计算 start 中第一个 bit 为 1 的位置**, 注意__ffs()=ffs()-1. 因为伙伴系统的链表都是**2 的 n 次幂**,最大的链表是**2 的 10 次方**, 也就是 1024,即**0x400**. 所以, 通过 ffs()函数可以很方便地计算出地址的对齐边界. 例如 start 等于 0x63300, 那么__ffs(0x63300)等于**8**, 那么这里**order 选用 8**.

得到 order 值后, 我们就可以把这块内存通过__free_pages_bootmem()函数添加到伙伴系统了.

```
void __init __free_pages_bootmem(struct page *page, unsigned int order)
{
    unsigned int nr_pages = 1 << order;
    struct page *p = page;

    page_zone(page)->managed_pages += nr_pages;
    set_page_refcounted (page);
    __free_pages(page, order};
}
```

__free_pages()函数是伙伴系统的**核心函数**, 这里**按照 order 的方式添加到伙伴系统**中, 该函数在第 2.4 节中会详细介绍.

下面是向系统中添加一段内存的情况, 页帧号范围为[0x8800e, Oxaecea], **以 start 为起始来计算其 order**, 一开始 order 的数值还比较凌乱, 等到 start 和 0x400 对齐, **以后基本上 order 都取值为 10**了, 也就是都挂入 order 为 10 的 free_list 链表中.

```
__free_pages_memory:  start=0x8800e, end=0xaecea
__free_pages_memory:  start=0x8800e, order=1, __ffs()=1, ffs()=2
__free_pages_memory:  start=0x88010, order=4, __ffs()=4, ffs()=5
__free_pages_memory:  start=0x88020, order=5, __ffs()=5, ffs()=6
__free_pages_memory:  start=0x88040, order=6, __ffs()=6, ffs()=7
__free_pages_memory:  start=0x88080, order=7, __ffs()=7, ffs()=8
__free_pages_memory:  start=0x88100, order=8, __ffs()=8, ffs()=9
__free_pages_memory:  start=0x88200, order=9, __ffs()=9, ffs()=10
__free_pages_memory:  start=0x88400, order=10, __ffs()=10, ffs()=11
__free_pages_memory:  start=0x88800, order=10, __ffs()=11, ffs()=12
__free_pages_memory:  start=0x88c00, order=10, __ffs()=10, ffs()=11
__free_pages_memory:  start=0x89000, order=10, __ffs()=12, ffs()=13
__free_pages_memory:  start=0x89400, order=10, __ffs()=10, ffs()=11
__free_pages_memory:  start=0x89800, order=10, __ffs()=11, ffs()=12
__free_pages_memory:  start=0x89c00, order=10, __ffs()=10, ffs()=11
```

# 7 小结

## 7.1 内存空间

内存空间分三层

![config](./images/1.jpg)

![config](./images/4.png)

| 层次 | 描述 |
|:---:|:----|
| **用户空间层** |可以理解为 Linux 内核内存管理**为用户空间暴露的系统调用接口**. 例如**brk**(), **mmap**()等**系统调用**. 通常 libc 库会将系统调用封装成大家常见的 C 库函数, 比如 malloc(), mmap()等. |
| **内核空间层** | 包含的模块相当丰富, 用户空间和内核空间的接口时系统调用, 因此内核空间层首先需要处理这些内存管理相关的系统调用, 例如 sys_brk, sys_mmap, sys_madvise 等. 接下来就包括 VMA 管理, 缺页中断管理, 匿名页面, page cache, 页面回收, 反向映射, slab 分配器, 页面管理等模块. |
| **硬件层** | 包含**处理器**的**MMU**, **TLB**和**cache**部件, 以及板载的**物理内存**, 例如 LPDDR 或者 DDR |

pg_data_t 对应一个 Node, node_zones 包含了不同 Zone; **Zone**下又**定义了 per_cpu_pageset**, 将**page 和 cpu 绑定**.

## 7.2

ARM Linux, 各种设备的相关属性描述都采用 DTS 方式呈现.

内核启动, 解析 DTS 文件, 得到内存的 base_address 和 size, 最后内存块信息通过 memblock_add()添加到 memblock 子系统中, 内核启动阶段, 内存管理(分配和释放)便使用 memblock 机制作为内核初始化阶段的内存分配器.

根据配置项和处理器, 确定 Linux 页表(PGD\-\>PUD\-\>PMD\-\>PTE)使用哪些.

内核使用内存前, 需要初始化内核的页表, 即建立页表映射.

对**页表的初始化**完成之后, 内核就可以**对内存进行管理**了, 但是**内核并不是统一对待这些页面**, 而是**采用层次化管理**.

Linux 把**物理内存**划分为**三个层次**来管理

| 层次 | 描述 |
|:----|:----|
| **存储节点(Node**) |  CPU 被划分为**多个节点(node**), **内存则被分簇**, **每个 CPU**对应一个**本地物理内存**, 即**一个 CPU\-node**对应一个**内存簇 bank**, 即**每个内存簇**被认为是**一个节点** |
| **管理区(Zone**)   | **每个物理内存节点 node**被划分为**多个内存管理区域**, 用于表示**不同范围的内存**, 内核可以使用**不同的映射方式(！！！**)映射物理内存 |
| **页面(Page**) | 内存被细分为**多个页面帧**, **页面**是**最基本的页面分配的单位**　｜

为了支持 NUMA 模型, 也即 CPU 对不同内存单元的访问时间可能不同, 此时系统的物理内存被划分为几个节点(node), 一个 node 对应一个内存簇 bank, 即每个内存簇被认为是一个节点

- 首先, 内存被划分为**结点**. **每个节点**关联到系统中的**一个处理器**, 内核中表示为**pg_data_t 的实例**. 定义了一个**大小为 MAX_NUMNODES 类型为 pg_data_t**的**数组 node_data**,数组的大小根据**CONFIG_NODES_SHIFT**的配置决定. 对于 UMA 来说, NODES_SHIFT 为 0, 所以 MAX_NUMNODES 的值为 1.    而对于 PC 这种**UMA 结构**的机器来说, 只使用了一个成为**contig_page_data**的静态 pg_data_t 结构.

- 各个节点又被划分为内存管理区域, 一个**管理区域**通过**struct zone_struct**描述, 其被定义为**zone_t**, 用以表示内存的某个范围,**低端范围的 16MB**被描述为**ZONE_DMA**,某些**工业标准体系结构中的(ISA)设备**需要用到它,然后是可**直接映射到内核**的**普通内存域 ZONE_NORMAL**,最后是超出了内核段的物理地址域 ZONE_HIGHMEM, 被称为高端内存. 是系统中预留的可用内存空间, 不能被内核直接映射.

- 最后**页帧(page frame**)代表了系统内存的最小单位, 堆内存中的每个页都会创建一个 struct page 的一个实例. 传统上, 把内存视为连续的字节, 即内存为字节数组, 内存单元的编号(地址)可作为字节数组的索引. 分页管理时, 将若干字节视为一页, 比如 4K byte. 此时, 内存变成了连续的页, 即内存为页数组, 每一页物理内存叫页帧, 以页为单位对内存进行编号, 该编号可作为页数组的索引, 又称为页帧号.