
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. time](#1-time)
  - [1.1. CPU 性能相关的选项](#11-cpu-性能相关的选项)
  - [1.2. 用法示例](#12-用法示例)
- [2. strace](#2-strace)
  - [2.1. CPU 性能相关的选项](#21-cpu-性能相关的选项)
  - [2.2. 用法示例](#22-用法示例)
- [3. ltrace](#3-ltrace)
  - [3.1. CPU 性能相关的选项](#31-cpu-性能相关的选项)
  - [3.2. 用法示例](#32-用法示例)
- [4. ps(进程状态)](#4-ps进程状态)
  - [4.1. CPU 性能相关的选项](#41-cpu-性能相关的选项)
  - [4.2. 用法示例](#42-用法示例)
- [5. ld.so(动态加载器)](#5-ldso动态加载器)
  - [5.1. CPU 性能相关的选项](#51-cpu-性能相关的选项)
  - [5.2. 用法示例](#52-用法示例)
- [6. gprof](#6-gprof)
  - [6.1. CPU 性能相关的选项](#61-cpu-性能相关的选项)
  - [6.2. 用法示例](#62-用法示例)
- [7. oprofile(II)](#7-oprofileii)
  - [7.1. CPU 性能相关的选项](#71-cpu-性能相关的选项)
  - [7.2. 用法示例](#72-用法示例)
- [8. 语言: 静态(C 和 C++)vs. 动态(Java 和 Mono)](#8-语言-静态c-和-cvs-动态java-和-mono)

<!-- /code_chunk_output -->

# 1. time

time 命令完成一项基本功能, 当需要测试一条命令的性能时, 通常会首先运行它. time 命令如同秒表一样, 可以测量命令执行的时间. 它测量的时间有三种类型: 第一种测量的是真正的或经过的时间, 即程序开始到结束执行之间的时间; 第二种测量的是用户时间, 即 CPU 代表该程序执行应用代码所花费的时间; 第三种测量的是系统时间, 即 CPU 代表该程序执行系统或内核代码所花费的时间.

## 1.1. CPU 性能相关的选项

time 命令(参见表 4-1)调用方式如下:

```
time [-V] application
```

对 application 程序计时, 在其完成后, 在标准输出上显示它的 CPU 使用情况.

表 4-1 time 命令行选项

![2019-12-08-16-17-31.png](./images/2019-12-08-16-17-31.png)

表 4-2 对 time 命令提供的有效输出统计信息进行了解释. 其他项不进行测量, 且总是显示为零.

表 4-2 与 CPU 相关的 time 输出

![2019-12-08-16-18-24.png](./images/2019-12-08-16-18-24.png)

这个命令是启动调查的良好开端. 它显示了应用程序执行了多长时间, 其中, 多少时间花费在 Linux 内核上, 多少时间花费在你的应用程序上.

## 1.2. 用法示例

包含在 Linux 中的 time 命令是跨平台 GNU 工具的一部分. 默认命令输出会打印命令运行的大量统计信息, 即使 Linux 不支持它们. 如果数据不可用, 那么 time 就只打印一个零. 下面的命令是对 time 的一个简单调用. 你可以在清单 4.1 中看到, 经过的时间(约 3 秒)远大于用户时间(0.9 秒)和系统时间(0.13 秒)的总和, 这是因为应用程序的大部分时间是用来等待输入的, 而少量的时间是用于处理器的.

清单 4.1

![2019-12-08-16-18-52.png](./images/2019-12-08-16-18-52.png)

清单 4.2 是 time 显示详细信息的例子. 如同你看到的, 这个输出比 time 的典型输出显示了更多的信息. 遗憾的是, 大部分统计数据都是零, 因为 Linux 不支持它们. 大多数情况下, 详细模式下提供的信息与标准模式下提供的信息是一样的, 但其统计信息的标签更具有描述性. 在这个例子中, 我们可以看到, 进程运行时使用了 15%的 CPU, 运行用户代码的时间为 1.15 秒, 运行内核代码的时间为 0.12 秒. 它累计有 2087 个主缺页故障, 或需要访问磁盘的内存故障; 有 371 个不需要访问磁盘的缺页故障. 大量的主缺页故障表明, 在应用程序试图使用内存时, 操作系统在不断的访问磁盘, 这极有可能意味着进行了大量的交换.

清单 4.2

![2019-12-08-16-19-04.png](./images/2019-12-08-16-19-04.png)

请注意, bash shell 有内置 time 命令, 因此, 如果你运行 bash 并在没有指定执行路径的情况下执行 time, 你将得到如下输出:

![2019-12-08-16-19-23.png](./images/2019-12-08-16-19-23.png)

bash 内置的 time 命令是很有用的, 但是它提供的是进程执行信息的子集.

# 2. strace

strace 是当程序执行时, 追踪其发起的系统调用的工具. 系统调用是由或代表一个应用程序进行的 Linux 内核函数调用. strace 可以展示准确的系统调用, 它在确定应用程序是如何使用 Linux 内核的方面是相当有用的. 在分析大型程序或你完全不懂的程序时, 跟踪系统调用的频率和长度是特别有价值的. 通过查看 strace 的输出, 你可以了解应用程序如何使用内核, 以及它依赖于什么类型的函数.

如果你完全理解了一个应用程序, 但是它有向系统库(如 libc 或 GTK)发起了调用, 那么此时, strace 也是很有用的. 在这种情况下, 即使你知道应用程序是如何进行每一个系统调用的, 库也可能会代表你的应用程序进行更多的系统调用. strace 可以迅速告诉你这些库都进行了哪些调用.

虽然 strace 主要用于跟踪进程与内核之间的交互, 显示应用程序的每个系统调用的参数和结果, 但是 strace 也可以提供不那么令人生畏的汇总信息. 应用程序运行之后, strace 会给出一个表格, 显示每个系统调用的频率和该类型调用所花费的总的时间. 这个表格可以作为理解你的程序与 Linux 内核之间交互的首个关键信息.

## 2.1. CPU 性能相关的选项

如下的 strace 调用对性能测试是最有用的:

```
strace [-c] [-p pid] [-o file] [--help] [command [arg ...]]
```

如果 strace 不带任何选项运行, 它将在标准错误输出上显示给定命令的所有的系统调用. 在试图发现为什么应用程序在内核中花费了大量时间时, 这是很有帮助的. 表 4-3 说明了一些 strace 选项, 它们在跟踪性能问题时也是有用的.

表 4-3 strace 命令行选项

![2019-12-08-16-21-20.png](./images/2019-12-08-16-21-20.png)

表 4-4 解释了 strace 汇总选项输出的统计信息. 每一行输出都说明了特定系统调用的一组统计数据.

尽管上述说明的选项是与性能调查最相关的, 但是 strace 也可以对其跟踪的系统调用进行类型过滤. strace 说明页和--help 选项详细解释了用于选择要跟踪哪些系统调用的选项. 对一般的性能优化, 通常没有必要使用它们; 不过如果需要的话, 它们也是存在可用的.

表 4-4 与 CPU 相关的 strace 输出

![2019-12-08-16-21-32.png](./images/2019-12-08-16-21-32.png)

## 2.2. 用法示例

清单 4.3 是用 strace 收集一个应用程序的系统调用统计信息的例子. 如你所见, strace 提供了对系统调用非常好的分析, 这些调用是代表应用程序执行的, 在这里, 这个应用程序就是 oowriter. 本例中, 我们查看 oowriter 是如何使用 read 系统调用的. 我们看到 read 占用了 20%的时间, 共消耗了 0.44 秒. 它被调用了 2427 次, 平均下来, 一次调用的时间为 184 微秒. 在这些调用中, 有 26 次返回了错误.

清单 4.3

![2019-12-08-16-22-07.png](./images/2019-12-08-16-22-07.png)

strace 善于跟踪进程, 但是它在一个应用程序上运行时会产生一些开销. 其结果就是, strace 报告的调用次数可能会比它报告的每个调用的时间要更加可靠一些. 应使用 strace 提供的次数作为调查的起点, 而不是每个调用所花费时间的高度精确的测量值.

# 3. ltrace

ltrace 与 strace 的概念相似, 但它跟踪的是应用程序对库的调用而不是对内核的调用. 虽然 ltrace 主要用于提供对库调用的参数和返回值的精确跟踪, 但是你也可以用它来汇总每个调用所花的时间. 这使得你既可以发现应用程序有哪些库调用, 又可以发现每个调用时间是多长.

使用 ltrace 要小心, 因为它会产生具有误导性的结果. 如果一个库函数调用了另一个函数, 则花费的时间要计算两次. 比如, 如果库函数 foo()调用了函数 bar(), 则函数 foo()的报告时间将是函数 foo()代码运行的全部时间再加上函数 bar()花费的时间.

记住了这个注意事项, ltrace 就还是揭示应用程序如何表现的有用的工具.

## 3.1. CPU 性能相关的选项

ltrace 提供与 strace 相似的功能, 其调用方法也和 strace 相近:

```
ltrace [-c] [-p pid] [-o filename] [-S] [--help] command
```

在上面的调用中, command 是你想要 ltrace 跟踪的命令. 如果 ltrace 不带选项, 它将在标准错误输出上显示所有的库调用. 表 4-5 解释了与性能调查最相关的 ltrace 选项.

表 4-5 ltrace 命令行选项:

![2019-12-08-16-22-45.png](./images/2019-12-08-16-22-45.png)

同样的, 汇总模式(summary mode)提供了应用程序执行期间的库调用的性能统计信息. 表 4-6 说明了这些统计数据的含义.

表 4-6 与 CPU 相关的 ltrace 输出

![2019-12-08-16-24-19.png](./images/2019-12-08-16-24-19.png)

就像 strace, ltrace 有大量的选项可以修改其跟踪的功能. ltrace 的- -help 命令描述了这些选项, 详细情况见于 ltrace 说明页.

## 3.2. 用法示例

清单 4.4 是 ltrace 运行于 xeyes 命令的简单例子. xeyes 是一个 XWindow 应用程序, 其功能是随着你的鼠标指针在屏幕上弹出一双眼睛.

清单 4.4

![2019-12-08-16-24-50.png](./images/2019-12-08-16-24-50.png)

在清单 4.4 中, 库函数 XSetWMProtocols、hypot、XQeuryPointer 分别占用了在库中所花总时间的 18.65%、17.19%和 12.06%. 消耗时间第二多的函数 hypot, 其调用次数为 702 次, 而消耗时间第一多的函数 XSetWMProtocols, 其调用次数仅为 1 次. 除非我们的应用程序能够完全删去对 XSetWMProtocols 的调用, 否则不管它需要多少时间, 我们都会被这个时间所制约. 我们最好将注意力转向 hypot. 这个函数的每次调用都是相对轻量级的, 因此, 如果我们能减少它的调用次数, 就有可能加快该应用程序的速度. 假如 xeyes 应用程序是一个性能问题, 那么 hypot 也许是第一个要被调查的函数. 起初, 我们想确定 hypot 是做什么的, 但是又不清楚它记录在什么地方. 那么是否有可能, 我们可以找出 hypot 属于哪个库, 然后阅读这个库的文档. 本例中, 我们不必先去找库, 因为 hypot 函数有说明页. 运行 man hypot 就可以告诉我们, hypot 函数计算两点之间的距离(斜边), 它是数学库 libm 的一部分. 但是, 库中函数有可能是没有说明页的, 因此, 我们需要确定这些没有说明页的函数是属于哪个库的. 遗憾的是, ltrace 不会明显地表示一个函数是来自于哪个库的. 要指出这一点, 我们必须使用 Linux 工具 ldd 和 objdump. 首先, ldd 用于显示一个动态链接的应用程序使用了哪些库. 其次, objdump 用于在每个库中查找给定的函数. 在清单 4.5 中, 我们用 ldd 来查看 xeyes 应用程序使用了哪些库.

清单 4.5

![2019-12-08-16-25-44.png](./images/2019-12-08-16-25-44.png)

现在 ldd 命令已经显示了 xeyes 使用的库, 我们可以用 objdump 命令来找出这些函数来自哪个库. 在清单 4.6 中, 我们在 xeyes 链接的每个库中查找 hypot 符号. objdump 的选项-T 列出了库依赖或提供的所有符号(主要是函数). 通过使用 fgrep 查看带有. text 的输出行, 我们可以发现是哪些库输出 hypot 函数. 本例中, libm 库是唯一含有 hypot 函数的库.

清单 4.6

![2019-12-08-16-25-54.png](./images/2019-12-08-16-25-54.png)

下一步应该浏览 xeyes 源代码找出 hypot 是在哪里被调用的, 如果可能的话, 减少其调用的次数. 或者还有一种方法, 查看 hypot 的源, 并尝试优化库的源代码.
通过调查哪个库调用需要很长的时间来完成, ltrace 使你能确定应用程序的每个库调用的成本.

# 4. ps(进程状态)

ps 是极好的跟踪运行进程的命令.

它给出正在运行进程的详细的静态和动态统计信息. ps 提供的静态信息包括命令名和 PID, 动态信息包括内存和 CPU 的当前使用情况.

## 4.1. CPU 性能相关的选项

ps 有许多不同的选项, 能检索正在运行中的应用程序的各种统计信息. 下面的调用给出了与 CPU 性能最相关的选项, 并将显示给定 PID 的信息:

```
ps [-o etime,time,pcpu,command] [-u user] [-U user] [PID]
```

ps 命令是出现最早的、功能丰富的用于提取性能信息的命令之一, 因此, 绝大多数人都会选择使用它. 若只看全部功能的一个子集, 它就更易于管理. 表 4-7 包含了与 CPU 性能最相关的选项.

表 4-7 ps 命令行选项

![2019-12-08-16-28-03.png](./images/2019-12-08-16-28-03.png)

除了 CPU 统计信息之外, ps 还提供了数量庞大的各种统计信息, 其中的一些, 比如进程的内存使用情况, 将在后续章节中讨论.

## 4.2. 用法示例

这个例子是一个测试程序, 它使用了 88%的 CPU, 运行了 6 秒, 但是消耗的 CPU 时间只有 5 秒:

![2019-12-08-16-28-15.png](./images/2019-12-08-16-28-15.png)

清单 4.7 中, 我们没有调查具体进程的 CPU 性能, 而是查看了特定用户运行的全部进程. 这可能会揭示特定用户消耗的资源量的信息. 本例中, 我们查看用户 netdump 运行的所有进程. 幸运的是, netdump 是一个很单调的用户, 它只运行了 bash 和 top, 其中, bash 不占用任何 CPU, 而 top 只占用了 0.5%的 CPU.

与 time 不同, ps 使我们能监控当前正在运行的进程的信息. 对于运行时间较长的工作, 你可以用 ps 定期检查进程的状态(而不是在程序已经执行完后, 用它来提供该程序执行的统计信息).

清单 4.7

![2019-12-08-16-28-39.png](./images/2019-12-08-16-28-39.png)

# 5. ld.so(动态加载器)

执行一个动态链接应用程序时, 首先运行的是 Linux 加载器 ld.so . ld.so 加载该应用程序所有的库, 并将它使用的符号与库提供的函数关联起来. 因为不同的库最初被链接到内存中的不同位置, 这些位置还可能是重叠的, 链接器需要对所有的符号进行排序, 以确保每个符号都位于内存中的不同位置. 一个符号从一个虚拟地址移动到另一个虚拟地址, 就被称为重定位(relocation). 加载器做这项工作是需要时间的, 如果它完全不用去做那就更好了. 预链接应用程序的目标就是通过重排整个系统的系统库来完成这项工作, 以保证它们不会相互重叠. 需要进行大量重定位的应用程序可能没有被预链接过.

Linux 加载器的运行不需要用户进行任何干预, 只需执行一个动态程序即可, 它是自动运行的. 虽然加载器的执行对用户来说是隐藏的, 但是它的执行仍然要花时间, 这就有可能会延长应用程序的启动时间. 当你要了解加载器的统计信息时, 加载器展示的是其工作量, 以便你能弄清楚它是否是瓶颈.

## 5.1. CPU 性能相关的选项

对使用共享库的每一个 Linux 应用程序来说, ld 命令的运行是不可见的. 通过设置合适的环境变量, 我们可以要求它显示其执行的信息. 下面的调用会影响 ld 的执行:

```
env LD_DEBUG=statistics,help LD_DEBUG_OUTPUT=filename <command>
```

加载器的调试能力完全用环境变量控制. 表 4-8 是对这些变量的说明.

表 4-8 ld 环境变量

![2019-12-08-16-31-10.png](./images/2019-12-08-16-31-10.png)

表 4-9 解释了一些 ld.so 可以提供的统计信息. 时间为时钟周期, 要将它转换为墙钟时间, 就必须除以处理器的时钟速度. (该信息见于 cat/proc/cpuinfo. )

ld 能提供的信息有助于确定应用程序开始执行之前, 设置动态库花费了多少时间.

表 4-9 与 CPU 相关的 ld.so 输出

![2019-12-08-16-31-23.png](./images/2019-12-08-16-31-23.png)

## 5.2. 用法示例

在清单 4.8 中, 我们运行一个应用程序, 并用 ld 调试定义的环境变量. 输出的统计信息保存在 lddebug 文件中. 请注意, 加载器显示了两组不同的统计数据. 第一个显示了启动时发生的全部重定位, 后一个则显示的是程序关闭后所有的统计信息. 如果应用程序使用了函数这些可以是不同的值, 比如使用函数 dlopen, 它允许共享库在程序开始执行后映射到该应用程序. 本例中, 我们看到加载器时间的 83%都用在定位上. 如果该应用程序已经预链接过, 那么这个时间会下降到接近于零.

清单 4.8

![2019-12-08-16-31-39.png](./images/2019-12-08-16-31-39.png)

如果 ld 被确定为延长启动时间的原因, 那么可以通过减少应用程序依赖的库的数量或者是在系统上运行 prelink 的方法来缩短启动时间.

# 6. gprof

剖析 Linux 应用程序的一种强有力的方法是使用 gprof 分析命令. gprof 可以展示应用程序的调用图, 并采样该应用程序的时间都花在了哪里. gprof 的工作方式是, 首先编译你的应用程序, 然后运行该应用程序生成一个采样文件. gprof 是非常强大的, 但是它需要应用源程序, 并且增加了编译开销. 尽管 gprof 可以确定函数被调用的精确次数, 以及函数所花的大致时间, 但是其编译将有可能改变应用程序的时间特性, 延缓程序的执行.

## 6.1. CPU 性能相关的选项

要用 gprof 剖析一个应用程序, 你必须访问应用程序源. 然后还需用如下所示的 gcc 命令编译该程序:

```
gcc -gp -g3 -o app app.c
```

首先, 你必须用 gcc 的-gp 选项来编译应用程序, 开启剖析功能. 须注意不要与可执行文件剥离, 如果用-g3 选项编译开启符号会更加有用. 符号信息对使用 gprof 的源注释特性是必须的. 当你运行被编译过的应用程序时, 会生成一个输出文件. 然后你可以用 gprof 命令来显示结果.

gprof 命令的调用如下:

```
gprog [-p -flat-profile -q --graph --brie -A -annotated-source] app
```

表 4-10 说明的选项指定了 gprof 显示的信息.

表 4-10 gprof 命令行选项

![2019-12-08-16-36-19.png](./images/2019-12-08-16-36-19.png)

对一个特定的剖析来说, 并不是所有的输出统计信息都是可以得到的. 哪个输出统计信息是可得的取决于应用程序是如何为了剖析而被编译的.

## 6.2. 用法示例

用 gprof 剖析一个应用程序时, 第一步是用剖析信息编译该程序. 编译器(gcc)将剖析信息插入到应用程序中, 该程序运行时, 会被保存到名为 gmon.out 的文件里. burn 测试程序相当简单. 它清除了大范围的内存, 然后调用了两个函数: a()和 b(), 这两个函数都要访问此内存区域. 函数 a()访问内存的频繁程度是函数 b()的 10 倍.

首先, 我们编译该应用程序:

```
gcc -pg -g3 -o burn_gprof burn.c
```

运行程序后, 我们可以分析输出, 如清单 4.9 所示.

清单 4.9

![2019-12-08-16-39-06.png](./images/2019-12-08-16-39-06.png)

在清单 4.9 中, 你可以看到 gprof 呈现的是我们已经知道的关于该应用程序的情况. 程序有两个函数 a()和 b(). 每个函数都调用了一次, a()完成的时间(91%)是 b()完成时间(8.99%)的 10 倍. 函数 a()花费的时间为 5.06 秒, 函数 b()花费的时间为 0.5 秒.

清单 4.10 给出了测试程序的调用图. 输出中列出的`<spontaneous>`注释的含义如下: 尽管 gprof 没有记录 main()的任何样本, 但它推断出 main()必然已经运行, 因为函数 a()和 b()都有采样, 而 main 是代码中唯一调用它们的函数. gprof 没有记录 main()的任何样本, 很可能是因为这个函数太短了.

清单 4.10

![2019-12-08-16-39-51.png](./images/2019-12-08-16-39-51.png)

最后, gprof 可以对源代码进行注释, 以展示每个函数调用的频率. 请注意, 清单 4.11 没有显示函数消耗的时间; 取而代之, 它显示的是函数被调用的次数. 在 gprof 前面的例子中, a()实际时长是 b()的 10 倍, 因此优化时需要多加小心. 不要认为被多次调用的函数实际上使用 CPU 的时间也多, 而被调用次数少的函数消耗的 CPU 时间必然也少.

清单 4.11

![2019-12-08-16-40-32.png](./images/2019-12-08-16-40-32.png)

gprof 提供了一个很好的总结, 可以显示应用程序中的函数以及源代码行运行的次数以及它们所花费的时间.

# 7. oprofile(II)

第 2 章中讨论过, 你可以使用 oprofile 跟踪系统或应用程序中不同事件的位置. 与 gprof 相比, oprofile 是一个低开销的工具. 与 gprof 不同, 它在使用前不需要对应用程序进行二次编译. oprofile 也可以测量 gprof 不支持的事件. 目前, oprofile 只支持那些 gprof 用内核补丁可以生成的调用图, 而 gprof 能够在所有的 Linux 内核上运行.

## 7.1. CPU 性能相关的选项

2.2.8 节讨论的 oprofile 涉及的是如何用 oprofile 开始进行剖析. 本小节介绍的则是 oprofile 用于分析进程级采样结果的部分.

oprofile 有一系列工具来显示已收集的样本. 第一个工具 opreport 显示的是样本在可执行文件和库的函数中分布情况. 其调用形式如下:

```
opreport [-d --details -f --long-filenames -l --symbols -l] application
```

表 4-11 解释了几个命令, 它们能够修改由 opreport 提供的信息的等级.

第二个你能用来提取性能样本信息的命令是 opannotate. opannotate 可以将样本对应到具体的源代码行或汇编指令. 其调用形式如下:

表 4-11 opreport 命令行选项

![2019-12-08-16-42-48.png](./images/2019-12-08-16-42-48.png)

表 4-12 说明了该调用的选项, 它们能让你指定 opannotate 提供的确切信息. 这里有一个忠告: 由于处理器硬件计数器在源代码行和指令级上的限制, 样本可能不会准确对应到引发它的那一行. 不过, 它们会很接近实际的事件.

表 4-12 opannotate 命令行选项

![2019-12-08-16-43-05.png](./images/2019-12-08-16-43-05.png)

使用 opannotate 和 opreport 时, 指明应用程序的完整路径名总是最好的做法. 如果不这样做, 你可能会接收到一条神秘的错误信息(如果 oprofile 无法发现应用程序的样本). 默认情况下, 在显示结果时, opreport 只显示可执行文件名, 这会与系统中多个有相同名称的可执行文件或库相混淆. 因此, 总是指定-f 选项就可以让 opreport 显示应用程序的完整路径.

oprofile 还可以提供一个命令 opgprof 用于输出由 oprofile 收集的样本, 其输出形式能被 gprof 理解. 该命令的调用方式如下:

```
opgprof application
```

该命令获取 application 的样本, 并生成与 gprof 兼容的文件. 之后, 你就可以用 gprof 命令来查看该文件了.

## 7.2. 用法示例

鉴于我们已经在 2.2.8 节中了解过 oprofile, 这里的例子向你展示的将是如何利用 oprofile 来跟踪源代码特定行的性能问题. 本小节假设你已经用 opcontrol 命令启动了剖析. 下一步就是运行有性能问题的程序. 本例中, 我们使用的是 burn 程序, 就是在 gprof 示例中用过的程序. 我们按如下方式启动测试程序:

```
# ./burn
```

程序完成后, 我们必须将 oprofile 的缓冲区转储到硬盘, 否则样本对 opreport 将是不可用的. 用如下命令完成这一步:

```
sudo opcontrol -d
```

接着, 在清单 4.12 中, 我们要求 opreport 告诉我们与测试程序/tmp/burn 相关的样本. 这能让我们对该应用程序消耗的周期数有个总体映像. 本例中, 我们看到应用程序有 9939 个样本. 如果我们深入 oprofile 工具, 我们将了解这些样本是如何在 burn 程序中分布的.

清单 4.12

![2019-12-08-16-46-25.png](./images/2019-12-08-16-46-25.png)

之后, 在清单 4.13 中, 我们想了解所有样本是属于 burn 程序中的哪些函数. 由于我们使用了`CPU_CLK_UNHANLTED`事件, 这大致对应于每个函数所花费的相对时间. 通过查看输出, 我们可以看到 91%的时间花在了函数 a()上, 9%的时间花在了函数 b()上.

清单 4.13

![2019-12-08-16-46-33.png](./images/2019-12-08-16-46-33.png)

在清单 4.14 中, 我们要求 opreport 展示哪些虚拟地址有对应的样本. 本例中, 看上去似乎位于地址 0x0804838a 的指令拥有 75%的样本. 但是, 现在还不清楚这条指令是做什么的, 或者为什么有这么多样本.

清单 4.14

![2019-12-08-16-46-54.png](./images/2019-12-08-16-46-54.png)

通常, 对我们更加有用的是知道使用所有 CPU 时间的源代码行, 而不是使用它的指令的虚拟地址. 找出一条特定指令与源代码行之间的对应关系并不总是容易的事儿. 因此, 在清单 4.15 中, 我们要求 opannotate 来做这项困难的工作, 向我们展示相对于原始源代码的样本(而并非指令的虚拟地址).

清单 4.15

![2019-12-08-16-47-10.png](./images/2019-12-08-16-47-10.png)

正如你能在清单 4.15 中看到的一样, opannotate 把大部分样本(86.59%)归因于函数 a()中的 for 循环. 可惜的是, for 循环中这部分的代价并不会很高. 对现代处理器来说, 整数加上固定数的执行速度是非常快的. 因此, oprofile 报告的样本可能被归于错误的源代码行. 而下面的代码行(`test[i]++;` )其代价则非常高, 因为它要访问内存子系统. 这一行才应该是这些样本所对应的.

有些超出 oprofile 控制的原因会导致它对样本的错误对应. 首先, 处理器并不总是精确中断于导致事件发生的那一行. 这可能会让样本被归于事件源头附近的指令, 而不是引发事件的那条指令. 其次, 当源代码被编译时, 编译器常常为了让执行更有效率而重排指令. 编译器完成优化后, 代码也许就不是按照其编写的顺序来执行. 不同的源代码行可能被重排和组合. 其结果就是, 特定的指令也许是多个源代码行的结果, 或者甚至于是编译器生成的中间代码段, 而这段中间代码在原始源代码中是不存在的. 因此, 当编译器优化代码, 生成机器指令时, 原始源代码行与生成的机器指令之间可能不再有一对一的映射关系. 这就使得让 oprofile(和调试器)指出每条机器指令究竟对应哪一行源代码变得困难重重, 甚至于不可能. 不过, oprofile 还是试图尽可能的准确, 因此, 通常你可以看看高样本计数代码行的上下几行, 就可以找出真正代价高的那行代码. 如果需要, 你可以用 opannotate 来显示确切的汇编指令, 以及正在接收所有样本的虚拟地址. 这有可能发现汇编指令在做什么, 从而手动将它映射回你的原始源代码. oprofile 的样本归属并不准确, 但它通常是足够接近的. 即使存在这些限制, oprofile 提供的文件显示了大致的源代码行以供调查, 一般说来, 这就足够找出应用程序的速度慢在了哪里.

# 8. 语言: 静态(C 和 C++)vs. 动态(Java 和 Mono)

大多数 Linux 性能工具都支持对静态语言(如 C 和 C++)的分析, 本章描述的所有工具都能运用于由这些语言编写的应用程序. 工具 ltrace, strace 和 time 可运用于由动态语言编写的应用程序, 比如 Java、Mono、Python 和 Perl. 但是剖析工具 gprof 和 oprofile 不能用于这些类型的应用程序. 幸运的是, 大多数动态语言提供了并不只针对 Linux 的剖析基础工具来生成相似类型的配置文件.

对 Java 应用程序而言, 如果运行 java 命令时带上了-Xrunhprof 命令行选项, 那么-Xrunhprof 将对应用程序进行剖析. 更多详细信息参见 http://antprof.sourceforge.net/hprof.html . 对 Mono 应用程序而言, 如果 mono 可执行文件被传递了--profile 标志, 那么它将剖析该应用程序. 更多详细信息参见 http://www.mono-project.com/docs/advanced/performance-tips/ . Perl 和 Python 也有相似的剖析功能, Perl 的 Devel::DProf 的说明见于网址 http://perl.com/pub/a/2004/06/25/profiling.html , 而 Python 的 profiler 的说明则见于新网址: https://docs.python.org/3/library/index.html .
