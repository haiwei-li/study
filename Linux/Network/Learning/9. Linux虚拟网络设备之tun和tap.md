
# 1. 虚拟设备和物理设备的区别

在\<Linux 网络数据包的接收过程\>和\<数据包的发送过程\>这两篇文章中, 介绍了数据包的收发流程, 知道了**Linux 内核**中有一个**网络设备管理层(管理所有网络设备！！！**), 处于**网络设备驱动(！！！**)和**协议栈(！！！**)之间, 负责**衔接**它们之间的**数据交互！！！**.

**驱动不需要了解协议栈**的细节, **协议栈也不需要了解设备驱动**的细节.

对于一个网络设备来说, 就像一个管道(pipe)一样, 有两端, 从其中任意一端收到的数据将从另一端发送出去.

比如一个**物理网卡 eth0**, 它的两端分别是**内核协议栈(通过内核网络设备管理模块间接的通信**)和**外面的物理网络**, 从**物理网络**收到的**数据**, 会转发给**内核协议栈**, 而**应用程序**从**协议栈**发过来的数据将会**通过物理网络发送**出去.

那么对于一个**虚拟网络设备**呢?首先它也**归内核的网络设备管理子系统管理**, 对于 Linux 内核网络设备管理模块来说, 虚拟设备和物理设备没有区别, 都是网络设备, 都能配置 IP, 从网络设备来的数据, 都会转发给协议栈, 协议栈过来的数据, 也会交由网络设备发送出去, 至于是**怎么发送出去**的, **发到哪里去**, 那是**设备驱动的事情！！！**, 跟 Linux 内核就没关系了, 所以说**虚拟网络设备的一端也是协议栈**, 而**另一端是什么取决于虚拟网络设备的驱动**实现.

# 2. 2 tun/tap 的另一端是什么?

先看图再说话:

```
+----------------------------------------------------------------+
|                                                                |
|  +--------------------+      +--------------------+            |
|  | User Application A |      | User Application B |<-----+     |
|  +--------------------+      +--------------------+      |     |
|               | 1                    | 5                 |     |
|...............|......................|...................|.....|
|               ↓                      ↓                   |     |
|         +----------+           +----------+              |     |
|         | socket A |           | socket B |              |     |
|         +----------+           +----------+              |     |
|                 | 2               | 6                    |     |
|.................|.................|......................|.....|
|                 ↓                 ↓                      |     |
|             +------------------------+                 4 |     |
|             | Newwork Protocol Stack |                   |     |
|             +------------------------+                   |     |
|                | 7                 | 3                   |     |
|................|...................|.....................|.....|
|                ↓                   ↓                     |     |
|        +----------------+    +----------------+          |     |
|        |      eth0      |    |      tun0      |          |     |
|        +----------------+    +----------------+          |     |
|    10.32.0.11  |                   |   192.168.3.11      |     |
|                | 8                 +---------------------+     |
|                |                                               |
+----------------|-----------------------------------------------+
                 ↓
         Physical Network
```

上图中有**两个应用程序 A 和 B**, 都在**用户层**, 而其它的**socket**、**协议栈(Newwork Protocol Stack**)和**网络设备(eth0 和 tun0**)部分都在**内核层**, 其实**socket 是协议栈的一部分！！！**, 这里分开来的目的是为了看的更直观.

**tun0**是一个**Tun/Tap 虚拟设备**, 从上图中可以看出它**和物理设备 eth0 的差别**, 它们的**一端虽然都连着协议栈**, 但另一端不一样, **eth0 的另一端是物理网络**, 这个物理网络可能就是一个交换机, 而**tun0 的另一端是一个用户层的程序！！！**, 协议栈发给 tun0 的数据包能被这个应用程序读取到, 并且**应用程序能直接向 tun0 写数据！！！**.

这里假设**eth0**配置的 IP 是**10.32.0.11**, 而**tun0**配置的 IP 是**192.168.3.11**.

这里列举的是一个典型的 tun/tap 设备的应用场景, 发到**192.168.3.0/24**网络的数据通过程序 B 这个隧道, 利用 10.32.0.11 发到远端网络的 10.33.0.1, 再由 10.33.0.1 转发给相应的设备, 从而实现 VPN.

下面来看看数据包的流程:

1. **应用程序 A**是一个**普通的程序**, 通过**socket A**发送了**一个数据包**, 假设这个数据包的**目的 IP 地址是 192.168.3.1**

2. **socket**将**这个数据包**丢给**协议栈**

3. **协议栈！！！**根据数据包的**目的 IP 地址**, 匹配**本地路由规则！！！**, 知道这个数据包应该**由 tun0 出去**, 于是**将数据包交给 tun0**

4. tun0 收到数据包之后, 发现**另一端被进程 B 打开**了, 于是将数据包丢给了**进程 B**

5. **进程 B 收到数据包**之后, 做一些跟业务相关的处理, 然后**构造一个新的数据包！！！**, 将原来的数据包嵌入在新的数据包中, 最后通过**socket B！！！**将数据包转发出去, 这时候**新数据包的源地址**变成了**eth0 的地址**, 而**目的 IP 地址**变成了一个**其它的地址**, 比如是 10.33.0.1.

6. **socket B**将数据包丢给**协议栈**

7. **协议栈**根据**本地路由！！！**, 发现**这个数据包**应该要通过**eth0**发送出去, 于是将数据包交给 eth0

8. eth0 通过物理网络将数据包发送出去

**10.33.0.1**收到数据包之后, 会**打开数据包**, 读取里面的**原始数据包**, 并**转发给本地的 192.168.3.1**, 然后**等收到 192.168.3.1 的应答**后, 再**构造新的应答包**, 并将**原始应答包**封装在里面, 再由**原路径返回给应用程序 B**, 应用程序 B 取出里面的**原始应答包**, 最后返回给应用程序 A

>这里不讨论 Tun/Tap 设备 tun0 是怎么和用户层的进程 B 进行通信的, 对于 Linux 内核来说, 有很多种办法来让内核空间和用户空间的进程交换数据.

从上面的流程中可以看出, **数据包选择走哪个网络设备完全由路由表控制！！！**, 所以如果我们想让某些网络流量走应用程序 B 的转发流程, 就需要**配置路由表让这部分数据走 tun0！！！**.

# 3. 3 tun/tap 设备有什么用?

从上面介绍过的流程可以看出来, **tun/tap 设备**的用处是将**协议栈中的部分数据包**转发给**用户空间的应用程序**, 给用户空间的程序一个处理数据包的机会. 于是比较常用的**数据压缩**, **加密等功能**就可以在**应用程序 B**里面做进去, tun/tap 设备**最常用的场景是 VPN！！！**, 包括 tunnel 以及应用层的 IPSec 等, 比较有名的项目是**VTun**, 有兴趣可以去了解一下.

# 4. 4 tun 和 tap 的区别

**用户层程序**通过**tun 设备只能读写 IP 数据包(只能网络层！！！**), 而通过**tap 设备**能**读写链路层数据包**, 类似于普通 socket 和 raw socket 的差别一样, 处理数据包的格式不一样.

# 5. 5 示例

## 5.1. 5.1 示例程序

这里写了一个程序, 它**收到 tun 设备的数据包**之后, **只打印出收到了多少字节的数据包**, 其它的什么都不做, 如何编程请参考后面的参考链接.


```c
#include <net/if.h>
#include <sys/ioctl.h>
#include <sys/stat.h>
#include <fcntl.h>
#include <string.h>
#include <sys/types.h>
#include <linux/if_tun.h>
#include<stdlib.h>
#include<stdio.h>

int tun_alloc(int flags)
{

    struct ifreq ifr;
    int fd, err;
    char *clonedev = "/dev/net/tun";

    if ((fd = open(clonedev, O_RDWR)) < 0) {
        return fd;
    }

    memset(&ifr, 0, sizeof(ifr));
    ifr.ifr_flags = flags;

    if ((err = ioctl(fd, TUNSETIFF, (void *) &ifr)) < 0) {
        close(fd);
        return err;
    }

    printf("Open tun/tap device: %s for reading...\n", ifr.ifr_name);

    return fd;
}

int main()
{

    int tun_fd, nread;
    char buffer[1500];

    /* Flags: IFF_TUN   - TUN device (no Ethernet headers)
     *        IFF_TAP   - TAP device
     *        IFF_NO_PI - Do not provide packet information
     */
    tun_fd = tun_alloc(IFF_TUN | IFF_NO_PI);

    if (tun_fd < 0) {
        perror("Allocating interface");
        exit(1);
    }

    while (1) {
        nread = read(tun_fd, buffer, sizeof(buffer));
        if (nread < 0) {
            perror("Reading from interface");
            close(tun_fd);
            exit(1);
        }

        printf("Read %d bytes from tun/tap device\n", nread);
    }
    return 0;
}
```

## 5.2. 5.2 演示

```
#--------------------------第一个 shell 窗口----------------------
#将上面的程序保存成 tun.c, 然后编译
dev@debian:~$ gcc tun.c -o tun

#启动 tun 程序, 程序会创建一个新的 tun 设备,
#程序会阻塞在这里, 等着数据包过来
dev@debian:~$ sudo ./tun
Open tun/tap device tun1 for reading...
Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device
Read 84 bytes from tun/tap device

#--------------------------第二个 shell 窗口----------------------
#启动抓包程序, 抓经过 tun1 的包
# tcpdump -i tun1
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on tun1, link-type RAW (Raw IP), capture size 262144 bytes
19:57:13.473101 IP 192.168.3.11 > 192.168.3.12: ICMP echo request, id 24028, seq 1, length 64
19:57:14.480362 IP 192.168.3.11 > 192.168.3.12: ICMP echo request, id 24028, seq 2, length 64
19:57:15.488246 IP 192.168.3.11 > 192.168.3.12: ICMP echo request, id 24028, seq 3, length 64
19:57:16.496241 IP 192.168.3.11 > 192.168.3.12: ICMP echo request, id 24028, seq 4, length 64

#--------------------------第三个 shell 窗口----------------------
#./tun 启动之后, 通过 ip link 命令就会发现系统多了一个 tun 设备,
#在我的测试环境中, 多出来的设备名称叫 tun1, 在你的环境中可能叫 tun0
#新的设备没有 ip, 我们先给 tun1 配上 IP 地址
dev@debian:~$ sudo ip addr add 192.168.3.11/24 dev tun1

#默认情况下, tun1 没有起来, 用下面的命令将 tun1 启动起来
dev@debian:~$ sudo ip link set tun1 up

#尝试 ping 一下 192.168.3.0/24 网段的 IP,
#根据默认路由, 该数据包会走 tun1 设备,
#由于我们的程序中收到数据包后, 啥都没干, 相当于把数据包丢弃了,
#所以这里的 ping 根本收不到返回包,
#但在前两个窗口中可以看到这里发出去的四个 icmp echo 请求包,
#说明数据包正确的发送到了应用程序里面, 只是应用程序没有处理该包
dev@debian:~$ ping -c 4 192.168.3.12
PING 192.168.3.12 (192.168.3.12) 56(84) bytes of data.

--- 192.168.3.12 ping statistics ---
4 packets transmitted, 0 received, 100% packet loss, time 3023ms
```

# 6. 6 参考

- [Universal TUN/TAP device driver](https://www.kernel.org/doc/Documentation/networking/tuntap.txt)
- [Tun/Tap interface tutorial](http://backreference.org/2010/03/26/tuntap-interface-tutorial/)