
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [前景回顾](#前景回顾)
  - [Linux 内存管理的层次结构](#linux-内存管理的层次结构)
  - [内存结点 pg_data_t](#内存结点-pg_data_t)
  - [物理内存区域](#物理内存区域)
  - [物理页帧](#物理页帧)
  - [今日内容(启动过程中的内存初始化)](#今日内容启动过程中的内存初始化)
- [第一阶段(启动过程中的内存管理)](#第一阶段启动过程中的内存管理)
  - [引导内存分配器 bootmem](#引导内存分配器-bootmem)
  - [memblock 内存分配器](#memblock-内存分配器)
  - [两者的区别与联系](#两者的区别与联系)
  - [memblock 的初始化(arm64 架构)](#memblock-的初始化arm64-架构)
- [第二阶段(初始化 buddy 内存管理)](#第二阶段初始化-buddy-内存管理)
  - [初始化流程](#初始化流程)
  - [3.2 paging\_init 初始化分页机制](#32-paging_init-初始化分页机制)
  - [3.3 虚拟地址空间(以 x86\_32 位系统为例)](#33-虚拟地址空间以-x86_32-位系统为例)
  - [3.4 bootmem\_init 初始化内存的基础数据结构(结点 pg\_data, 内存域 zone, 页面 page)](#34-bootmem_init-初始化内存的基础数据结构结点-pg_data-内存域-zone-页面-page)
  - [3.5 build\_all\_zonelists 初始化每个内存节点的 zonelists](#35-build_all_zonelists-初始化每个内存节点的-zonelists)
- [4 总结](#4-总结)
  - [4.1 start\_kernel 启动流程](#41-start_kernel-启动流程)
  - [4.2 体系结构相关的初始化工作 setup_arch](#42-体系结构相关的初始化工作-setup_arch)
  - [4.3 bootmem\_init 初始化内存的基础数据结构(结点 pg\_data, 内存域 zone, 页面 page)](#43-bootmem_init-初始化内存的基础数据结构结点-pg_data-内存域-zone-页面-page)
  - [4.4 build\_all\_zonelists 初始化每个内存节点的 zonelists](#44-build_all_zonelists-初始化每个内存节点的-zonelists)

<!-- /code_chunk_output -->

在内存管理的上下文中, 初始化(initialization)可以有多种含义.在许多 CPU 上,必须**显式设置**适用于 Linux 内核的**内存模型**.在 x86\_32 上需要切换到保护模式, 然后内核才能检测到可用内存和寄存器.

而我们今天要讲的 boot 阶段就是系统初始化阶段使用的内存分配器.

# 前景回顾

## Linux 内存管理的层次结构

Linux 把物理内存划分为三个层次来管理

| 层次 | 描述 |
|:----|:----|
| 存储节点(Node) |  CPU 被划分为多个节点(node), 内存则被分簇, 每个 CPU 对应一个本地物理内存, 即一个 CPU-node 对应一个内存簇 bank, 即每个内存簇被认为是一个节点 |
| 管理区(Zone)   | 每个物理内存节点 node 被划分为多个内存管理区域, 用于表示不同范围的内存, 内核可以使用不同的映射方式映射物理内存 |
| 页面(Page) 	   |	内存被细分为多个页面帧, 页面是最基本的页面分配的单位　｜

为了支持 NUMA 模型, 也即 CPU 对不同内存单元的访问时间可能不同, 此时系统的物理内存被划分为几个节点(node), 一个 node 对应一个内存簇 bank, 即每个内存簇被认为是一个节点

- 首先, 内存被划分为**结点**. 每个节点关联到系统中的一个处理器, 内核中表示为`pg_data_t`的实例. 系统中每个节点被链接到一个以 NULL 结尾的`pgdat_list`链表中<而其中的每个节点利用`pg_data_tnode_next`字段链接到下一节. 而对于 PC 这种 UMA 结构的机器来说, 只使用了一个成为 contig\_page\_data 的静态 pg\_data\_t 结构.

- 接着各个节点又被划分为内存管理区域, 一个**管理区域**通过 struct zone\_struct 描述, 其被定义为 zone\_t,用以表示内存的某个范围,低端范围的 16MB 被描述为 ZONE\_DMA,某些工业标准体系结构中的(ISA)设备需要用到它,然后是可直接映射到内核的普通内存域 ZONE\_NORMAL,最后是超出了内核段的物理地址域 ZONE\_HIGHMEM, 被称为高端内存.　是系统中预留的可用内存空间, 不能被内核直接映射.

- 最后**页帧(page frame**)代表了系统内存的最小单位, 堆内存中的每个页都会创建一个 struct page 的一个实例. 传统上, 把内存视为连续的字节, 即内存为字节数组, 内存单元的编号(地址)可作为字节数组的索引. 分页管理时, 将若干字节视为一页, 比如 4K byte. 此时, 内存变成了连续的页, 即内存为页数组, 每一页物理内存叫页帧, 以页为单位对内存进行编号, 该编号可作为页数组的索引, 又称为页帧号.

## 内存结点 pg_data_t

在 Linux 中引入一个数据结构`struct pglist_data` , 来描述一个 node, 定义在[`include/linux/mmzone.h`](http://lxr.free-electrons.com/source/include/linux/mmzone.h#L630) 文件中. (这个结构被 typedef pg\_data\_t).

- 对于 NUMA 系统来讲, 整个系统的内存由一个[**node\_data**](http://lxr.free-electrons.com/source/arch/s390/numa/numa.c?v=4.7#L23)的 pg\_data\_t**指针数组**来管理

- 对于 UMA 系统, 使用 struct pglist\_data contig\_page\_data , 作为系统唯一的 node 管理所有的内存区域. (UMA 系统中中只有一个 node)

可以使用 NODE\_DATA(node\_id)来查找系统中编号为 node\_id 的结点, 而 UMA 结构下由于只有一个结点, 因此该宏总是返回全局的 contig\_page\_data, 而与参数 node\_id 无关.

**NODE\_DATA(node\_id)查找编号 node\_id 的结点 pg\_data\_t 信息** 参见[NODE\_DATA 的定义](http://lxr.free-electrons.com/ident?v=4.7;i=NODE_DATA)

```cpp
extern struct pglist_data *node_data[];
#define NODE_DATA(nid)          (node_data[(nid)])
```

在 UMA 结构的机器中, 只有一个 node 结点即 contig\_page\_data,此时 NODE\_DATA 直接指向了全局的 contig\_page\_data,而与 node 的编号 nid 无关,参照[include/linux/mmzone.h?v=4.7, line 858](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L858)

```cpp
extern struct pglist_data contig_page_data;
#define NODE_DATA(nid)          (&contig_page_data)
```

## 物理内存区域

因为实际的计算机体系结构有硬件的诸多限制, 这限制了页框可以使用的方式. 尤其是, Linux 内核必须处理 80x86 体系结构的两种硬件约束.

- ISA 总线的直接内存存储 DMA 处理器有一个严格的限制 : 他们只能对 RAM 的前 16MB 进行寻址

- 在具有大容量 RAM 的现代 32 位计算机中, CPU 不能直接访问所有的物理地址, 因为线性地址空间太小, 内核不可能直接映射所有物理内存到线性地址空间, 我们会在后面典型架构(x86)上内存区域划分详细讲解 x86\_32 上的内存区域划分

因此 Linux 内核对不同区域的内存需要采用不同的管理方式和映射方式, 因此内核将物理地址或者成用 zone\_t 表示的不同地址区域

对于 x86\_32 的机器, 管理区(内存区域)类型如下分布

| 类型 | 区域 |
| :------- | :---- |
| ZONE_DMA | 0~15MB |
| ZONE_NORMAL | 16MB~895MB |
| ZONE_HIGHMEM | 896MB~物理内存结束 |

## 物理页帧

内核把物理页作为内存管理的基本单位.尽管处理器的最小可寻址单位通常是字,但是,内存管理单元 MMU 通常以页为单位进行处理.因此, 从虚拟内存的上来看, 页就是最小单位.

页帧代表了系统内存的最小单位, 对内存中的每个页都会创建 struct page 的一个实例. 内核必须要保证 page 结构体足够的小, 否则仅 struct page 就要占用大量的内存.

内核用[struct  page(include/linux/mm_types.h?v=4.7, line 45)](http://lxr.free-electrons.com/source/include/linux/mm_types.h?v4.7#L45)结构表示系统中的每个物理页.

出于节省内存的考虑, struct page 中使用了大量的联合体 union.

`mem_map`是一个 struct page 的数组, 管理着系统中所有的物理内存页面. 在系统启动的过程中, 创建和分配 mem\_map 的内存区域, mem\_map 定义在[mm/page\_alloc.c?v=4.7, line 6691](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L6691)

UMA 体系结构中, free\_area\_init 函数在系统唯一的 struct node 对象 contig\_page\_data 中 node\_mem\_map 成员赋值给全局的 mem\_map 变量

## 今日内容(启动过程中的内存初始化)

在初始化过程中, 还必须建立内存管理的数据结构,以及很多事务.因为内核在内存管理完全初始化之前就需要使用内存.在系统启动过程期间,使用了额外的简化的**内存管理模块**,然后在初始化完成后,将**旧的模块丢弃**掉.

因此我们可以把 linux 内核的**内存管理分三个阶段**.

| 阶段 | 起点 | 终点 | 描述 |
|:-----|:-----|:-----|:-----|
| 第一阶段 | 系统启动 | bootmem 或者 memblock 初始化完成 | 此阶段只能使用**memblock\_reserve 函数**分配内存, **早期内核**中使用 init\_bootmem\_done = 1 标识此阶段结束 |
| 第二阶段 | bootmem 或者 memblock 初始化完 | buddy 完成前 | **引导内存分配器 bootmem**或者**memblock**接受内存的管理工作, **早期内核**中使用 mem\_init\_done = 1 标记此阶段的结束 |
| 第三阶段 | buddy 初始化完成 | 系统停止运行 | 可以用**cache 和 buddy 分配**内存 |

**系统启动过程中的内存管理**

首先我们来看看 start\_kernel 是如何初始化系统的,start\_kerne 定义在[init/main.c?v=4.7, line 479](http://lxr.free-electrons.com/source/init/main.c?v=4.7#L479)

其代码很复杂, 我们只截取出其中与内存管理初始化相关的部分, 如下所示

```cpp
asmlinkage __visible void __init start_kernel(void)
{

    /*  设置特定架构的信息
     *	同时初始化 memblock  */
    setup_arch(&command_line);
    mm_init_cpumask(&init_mm);

    setup_per_cpu_areas();

	/*  初始化内存结点和内段区域  */
    build_all_zonelists(NULL, NULL);
    page_alloc_init();


    /*
     * These use large bootmem allocations and must precede
     * mem_init();
     * kmem_cache_init();
     */
    mm_init();

    kmem_cache_init_late();

	kmemleak_init();
    setup_per_cpu_pageset();

    rest_init();
}
```

| 函数  | 功能 |
|:----|:----|
| setup\_arch | 是一个特定于体系结构的设置函数, 其中一项任务是负责**初始化自举分配器** |
| mm\_init\_cpumask | 初始化**CPU 屏蔽字** |
| setup\_per\_cpu\_areas | 函数[(查看定义)](http://lxr.free-electrons.com/source/mm/percpu.c?v4.7#L2205])给每个 CPU 分配内存, 并拷贝.data.percpu 段的数据.为系统中的**每个 CPU 的 per\_cpu 变量申请空**间.<br>在 SMP 系统中,setup\_per\_cpu\_areas 初始化源代码中(使用[per_cpu 宏](http://lxr.free-electrons.com/source/include/linux/percpu-defs.h#L256))定义的静态 per-cpu 变量,这种变量对系统中每个 CPU 都有一个独立的副本. <br>此类变量保存在内核二进制影像的一个独立的段中,setup\_per\_cpu\_areas 的目的就是为系统中各个 CPU 分别创建一份这些数据的副本<br>在**非 SMP 系统**中这是一个**空操作** |
| build\_all\_zonelists | 建立并初始化**结点**和**内存域**的数据结构 |
| mm\_init | 建立了内核的**内存分配器**,<br>其中通过[**mem\_init**](http://lxr.free-electrons.com/ident?v=4.7&i=mem_init)**停用 bootmem**分配器并迁移到实际的内存管理器(比如伙伴系统)<br>然后调用**kmem\_cache\_init**函数初始化内核内部**用于小块内存区的分配器** |
| [kmem\_cache\_init\_late](http://lxr.free-electrons.com/source/mm/slab.c?v4.7#L1378) | 在**kmem\_cache\_init**之后,完善分配器的**缓存机制**,　当前 3 个可用的内核内存分配器[slab](http://lxr.free-electrons.com/source/mm/slab.c?v4.7#L1378), [slob](http://lxr.free-electrons.com/source/mm/slob.c?v4.7#L655), [slub](http://lxr.free-electrons.com/source/mm/slub.c?v=4.7#L3960)都会定义此函数　|
| [kmemleak\_init](http://lxr.free-electrons.com/source/mm/kmemleak.c?v=4.7#L1857) | Kmemleak 工作于内核态, Kmemleak 提供了一种**可选的内核泄漏检测**, 其方法类似于**跟踪内存收集器**. 当独立的对象没有被释放时, 其报告记录在 [/sys/kernel/debug/kmemleak](http://lxr.free-electrons.com/source/mm/kmemleak.c?v=4.7#L1467)中, Kmemcheck 能够帮助定位大多数内存错误的上下文 |
| [setup\_per\_cpu\_pageset](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L5392) | **初始化 CPU 高速缓存行**, 为 pagesets 的第一个数组元素分配内存, 换句话说, 其实就是第一个系统处理器分配<br>由于在分页情况下, **每次存储器访问都要存取多级页表**, 这就大大降低了访问速度. 所以, 为了提高速度, 在 CPU 中设置一个最近存取页面的**高速缓存硬件机制**, 当进行存储器访问时, 先检查要访问的页面是否在高速缓存中. |

# 第一阶段(启动过程中的内存管理)

内存管理是操作系统资源管理的重点,但是在**操作系统初始化的初期**,操作系统只是获取到了**内存的基本信息**,但是内存管理的**数据结构**都**没有建立**,而我们这些**数据结构创建的过程**本身就是一个**内存分配的过程**,那么就出现一个问题

我们还**没有**一个**内存管理器**去负责**分配和回收**内存,而我们又**不可能**将**所有的内存信息都静态创建并初始化**,那么我们怎么分配内存管理器所需要的内存呢? 现在我们进入了一个先有鸡还是先有蛋的怪圈,这种问题的**一般解决方法**是,我们先实现一个**满足要求**的但是**可能效率不高**的笨家伙(内存管理器),用它来负责系统**初始化初期**的内存管理,**最重要的**,用它来**初始化我们内存的数据结构**,直到我们真正的内存管理器被初始化完成并能投入使用,我们将旧的内存管理器丢掉

即因此在系统启动过程期间,内核使用了一个额外的简化形式的内存管理模块早期的**引导内存分配器(boot memory allocator--bootmem 分配器)**或者**memblock**, 用于在启动阶段早期分配内存, 而在**系统初始化完成**后, 该**分配器被内核抛弃**, 然后初始化了一套新的更加完善的内存分配器.

## 引导内存分配器 bootmem

在启动过程期间, 尽管内存管理尚未初始化,但是内核仍然需要分配内存以创建各种数据结构,早期的内核中负责初始化阶段的内存分配器称为**引导内存分配器(boot memory allocator--bootmem 分配器)**,在耳熟能详的伙伴系统建立前内存都是利用分配器来分配的, 伙伴系统框架建立起来后, bootmem 会过度到伙伴系统.显然,对该内存分配器的需求集中于**简单**性方面,而不是性能和通用性,它仅用于初始化阶段.因此内核开发者决定实现一个**最先适配(first-first)分配器**用于在启动阶段管理内存. 这是可能想到的最简单的方式.

**引导内存分配器(boot memory allocator--bootmem 分配器)**基于**最先适配(first-first)分配器**的原理(这儿是很多系统的内存分配所使用的原理),使用**一个位图来管理页**,以**位图**代替原来的**空闲链表结构**来表示**存储空间**,位图的比特位的数目与系统中物理内存页面数目相同. 若**位图中某一位是 1**,则标识**该页面**已经**被分配**(已用页),否则表示未被占有(未用页).

在需要分配内存时, 分配器逐位的**扫描位图**,直至找到一个能提供**足够连续页(空间连续！！！**)的位置,即所谓的**最先最佳(first-best)或最先适配**位置.该分配机制通过记录上一次分配的**页面帧号(PFN**)结束时的**偏移量**来实现分配**大小小于一页的空间**, 连续的小的**空闲空间**将被合并存储在**一页**上.

即使是初始化用的最先适配分配器也必须使用一些数据结构存,内核为系统中**每一个结点(每个 node！！！**)都提供了一个**struct bootmem\_data 结构的实例**,用于 bootmem 的内存管理. 它含有引导内存分配器给结点分配内存时所需的信息.当然,这时候内存管理还没有初始化, 因而该**结构所需的内存**是**无法动态分配**的,必须在**编译时分配给内核(！！！**).

在**UMA 系统**上该分配的实现**与 CPU 无关**,而 NUMA 系统内存结点与 CPU 相关联,因此采用了特定体系结构的解决方法.

bootmem\_data 的结构定义在[include/linux/bootmem.h?v=4.7, line 28](http://lxr.free-electrons.com/source/include/linux/bootmem.h?v=4.7#L28)

关于引导内存分配器的具体内容, 请参见另外一篇文章

## memblock 内存分配器

但是 bootmem 也有很多问题.最明显的就是**外碎片**的问题,因此内核维护了**memblock 内存分配器**,同时用 memblock 实现了一份**bootmem 相同的兼容 API**,即 nobootmem,Memblock 以前被定义为 Logical Memory Block(逻辑内存块), 但根据[Yinghai Lu 的补丁](https://lkml.org/lkml/2010/7/13/68), 它被重命名为 memblock. 并最终替代 bootmem 成为初始化阶段的内存管理器

关于引导内存分配器的具体内容, 请参见另外一篇文章

## 两者的区别与联系

bootmem 是通过**位图来管理**, 位图存在**低地址段**,而 memblock 是在**高地址管理内存**, 维护**两个链表**, 即**memory 和 reserved**

**memory 链表**维护系统的**内存信息**(在初始化阶段**通过 bios 获取**的),对于任何**内存分配**,先去**查找 memory 链表**,然后**在 reserve 链表上记录**(新增一个节点, 或者合并)

1. 两者都可以分配**小于一页的内存**;

2. 两者都是**就近查找可用的内存**,  bootmem 是从低到高找, memblock 是从高往低找;

在 boot 传递给 kernel memory bank 相关信息后, kernel 这边会以**memblcok 的方式保存**这些信息, 当 buddy system 没有起来之前, 在 kernel 中也是要有一套机制来管理 memory 的申请和释放.

Kernel 可以选择 nobootmem 或者 bootmem 来在 buddy system 起来之前管理 memory.这两种机制对**提供的 API 是一致的**, 因此对用户是透明的

参见[mm/**Makefile**](http://lxr.free-electrons.com/source/mm/Makefile#L44)

```cpp
ifdef CONFIG_NO_BOOTMEM
	obj-y           += nobootmem.o
else
	obj-y           += bootmem.o
endif
```

由于接口是一致的, 那么他们共同使用一份头文件

| 头文件 | bootmem 接口 | nobootmem 接口 |
|:-----:|:-----------:|:------------:|
| [include/linux/bootmem.h](http://lxr.free-electrons.com/source/include/linux/bootmem.h) | [mm/bootmem.c](http://lxr.free-electrons.com/source/mm/bootmem.c) | [mm/nobootmem.c](http://lxr.free-electrons.com/source/mm/nobootmem.c) |

## memblock 的初始化(arm64 架构)

前面我们的内核从**start\_kernel**开始,进入**setup\_arch**(),并完成了**早期内存分配器的初始化和设置**工作.

```cpp
void __init setup_arch(char **cmdline_p)
{
	/*  初始化 memblock  */
	arm64_memblock_init( );

	/*  分页机制初始化  */
	paging_init();

	bootmem_init();
}
```

| 流程 | 描述 |
|:---:|:----:|
| [arm64_memblock_init](http://lxr.free-electrons.com/source/arch/arm64/kernel/setup.c?v=4.7#L229) | 初始化 memblock 内存分配器 |
| [paging_init](http://lxr.free-electrons.com/source/arch/arm64/mm/mmu.c?v=4.7#L538) | 初始化分页机制 |
| [bootmem_init](http://lxr.free-electrons.com/source/arch/arm64/mm/init.c?v=4.7#L306) | 初始化内存管理 |

其中 arm64\_memblock\_init 就完成了**arm64 架构**下的 memblock 的初始化

# 第二阶段(初始化 buddy 内存管理)

## 初始化流程

下面我们就以**arm64 架构**来分析 bootmem 初始化内存**结点**和**内存域**的过程, 在讲解的过程中我们会兼顾的考虑 arm64 架构下的异同

- 首先内核从[**start\_kernel**](http://lxr.free-electrons.com/source/init/main.c?v=4.7#L505)开始启动

- 然后进入**体系结构相关**的设置部分[**setup\_arch**](http://lxr.free-electrons.com/source/arch/arm/kernel/setup.c?v=4.7#L1073),开始**获取并设置**指定**体系结构**的一些**物理信息**,而 arm64 架构下则对应着[arch/arm64/kernel/setup.c](http://lxr.free-electrons.com/source/arch/arm64/kernel/setup.c?v=4.7#L229)

- 在**setup\_arch**函数内, 通过**paging\_init**函数初始化了**分页机制**和**页表**的信息

- 接着**paging\_init**函数通过**调用**[**bootmem\_init**](http://lxr.free-electrons.com/source/arch/arm/mm/mmu.c#L1642)开始进行初始化工作

**arm64**在整个初始化的流程上并没有什么不同, 但是有细微的差别

- 由于**arm**是在**后期才开始加入了 MMU 内存管理单元**的,因此内核必须实现**mmu**和**nonmmu**两套**不同的代码**,这主要是体现在分页机制的不同上,因而 paging\_init 分别定义了[arch/arm/mm/nommu.c](http://lxr.free-electrons.com/source/arch/arm/mm/nommu.c?v=4.7#L311)和[arch/arm/mm/mmu.c](http://lxr.free-electrons.com/source/arch/arm/mm/mmu.c?v=4.7#L1623)两个版本,但是它们**均调用**了**bootmem_init**来完成初始化

- 也是因为上面的原因, arm 上**paging\_init**有**两份代码**([mmu](http://lxr.free-electrons.com/source/arch/arm/mm/mmu.c?v=4.7#L162)和[nonmmu](http://lxr.free-electrons.com/source/arch/arm/mm/nommu.c?v=4.7#L311)),为了降低**代码的耦合性**,arm 通过 setup\_arch 调用**paging\_init**函数,**paging\_init**进一步**调用了 bootmem\_init**来完成,而 arm64 上不存在这样的问题,则在[setup\_arch 中顺序的先用 paging\_init](http://lxr.free-electrons.com/source/arch/arm64/kernel/setup.c?v=4.7#L266)初始化了页表, 然后[**setup\_arch 又调用 bootmem\_init**](http://lxr.free-electrons.com/source/arch/arm64/kernel/setup.c?v4.7#L271)来完成了 bootmem 的初始化

## 3.2 paging\_init 初始化分页机制

paging\_init 负责建立**只能用于内核的页表**,**用户空间**是**无法访问**的.这对管理普通应用程序和内核访问内存的方式, 有深远的影响

因此在仔细考察其实现之前, 很重要的一点是解释该函数的目的.

在 x86\_32 系统上内核通常将总的 4GB 可用虚拟地址空间按 3:1 的比例划分给用户空间和内核空间, 虚拟地址空间的低端 3GB 用于用户状态应用程序,而高端的 1GB 则专用于内核.尽管在分配内核的虚拟地址空间时,当前系统上下文是不相干的,但每个进程都有自身特定的地址空间.

这些划分主要的动机如下所示

- 在用户**应用程序**的执行**切换到核心态**时(这总是会发生, 例如在使用系统调用或发生周期性的时钟中断时), **内核**必须装载在一个**可靠的环境**中. 因此有必要将地址空间的一部分分配给内核专用.

- **物理内存页**则映射到**内核地址空间的起始处**, 以便内核直接访问, 而无需复杂的页表操作.

如果所有物理内存页都映射到用户空间进程能访问的地址空间中,如果在系统上有**几个应用程序在运行**,将导致严重的**安全问题**.每个应用程序都能够读取和修改其他进程在物理内存中的内存区. 显然必须不惜任何代价防止这种情况出现.

虽然用于**用户层进程**的**虚拟地址部分**随进程切换而**改变**, 但是**内核部分总是相同的**

## 3.3 虚拟地址空间(以 x86\_32 位系统为例)

出于内存保护等一系列的考虑,内核将整个进程的虚拟运行空间划分为内核虚拟运行空间和内核虚拟运行空间

![虚拟地址空间](./images/vmarea_space.jpg)

按 3:1 的比例划分地址空间,只是约略反映了内核中的情况, **内核地址空间**作为内核的**常驻虚拟地址空间**, 自身又分为各个段

![内核空间](./images/kernel_space.jpg)

地址空间的**第一段**用于将系统的**所有物理内存页**映射到**内核的虚拟地址空间**中. 由于内核地址空间从偏移量 0xC0000000 开始, 即经常提到的 3 GB, 每个虚拟地址 x 都对应于物理地址(x \- 0xC0000000), 因此这是一个简单的线性平移.

**直接映射区域**从**0xC0000000 到 high\_memory**地址, high\_memory 准确的数值稍后讨论. 第 1 章提到过, 这种方案有一问题. 由于内核的虚拟地址空间只有 1GiB, 最多只能映射 1 GiB 物理内存. IA-32 系统(没有 PAE)最大的内存配置可以达到 4GiB, 引出的一个问题是, 如何处理剩下的内存?

这里有个坏消息. 如果**物理内存超过 896MiB**, 则**内核无法直接映射全部物理内存**. 该值甚至比此前提到的最大限制 1GiB 还小, 因为内核必须保留地址空间**最后的 128MiB 用于其他目的**, 我会稍后解释. 将这 128MiB 加上直接映射的 896MiB 内存, 则得到内核虚拟地址空间的总数为 1024MiB=1GiB. 内核使用两个经常使用的缩写 normal 和 highmem, 来区分是否可以直接映射的页帧.

内核地址空间的最后 128 MiB 用于何种用途呢?该部分有 3 个用途.

- **虚拟内存中连续**、但**物理内存中不连续**的内存区, 可以在**vmalloc 区域**分配. 该机制**通常用于用户过程**, 内核自身会试图尽力**避免非连续的物理地址**. 内核通常会成功, 因为大部分大的内存块都在启动时分配给内核, 那时内存的碎片尚不严重. 但在已经运行了很长时间的系统上, 在内核需要物理内存时, 就可能出现可用空间不连续的情况. 此类情况, 主要出现在**动态加载模块**时

- **持久映射**用于将高端内存域中的**非持久页(物理页！！！)映射到内核**中

- **固定映射**是与**物理地址**空间中的**固定页**关联的**虚拟地址空间项**, 但具体关联的**页帧(物理页**)可以自由选择. 它与通过固定公式与物理内存关联的**直接映射页**相反, **虚拟固定映射地址**与**物理内存**位置之间的**关联可以自行定义**, 关联建立后内核总是会注意到的

同样我们的[**用户空间**](http://www.360doc.com/content/14/1020/21/19947352_418512226.shtml), 也被划分为几个段, 包括从高地址到低地址分别为 :

![进程的虚拟地址空间](./images/user_space.jpg)

| 区域 | 存储内容 |
|:---:|:------:|
|  栈   | 局部变量, 函数参数, 返回地址等 |
|  堆   | 动态分配的内存 |
| BSS 段 | 未初始化或初值为 0 的全局变量和静态局部变量|
| 数据段 | 一初始化且初值非 0 的全局变量和静态局部变量|
| 代码段 | 可执行代码, 字符串面值, 只读变量 |

## 3.4 bootmem\_init 初始化内存的基础数据结构(结点 pg\_data, 内存域 zone, 页面 page)

在 paging\_init 之后,系统的页帧已经建立起来,然后通过 bootmem\_init 中,系统开始完成 bootmem 的初始化工作.

**不同的体系**结构 bootmem\_init 的实现, 没有很大的区别, 但是在**初始化**的过程中, 其中的很多函数, 依据系统是 NUMA 还是 UMA 结构则有不同的定义

bootmem\_init 函数的实现如下

| 函数实现 | arm | arm64 |
|:---:|:---:|:-----:|
| bootmem_init | [arch/arm/mm/init.c, line 282](http://lxr.free-electrons.com/source/arch/arm/mm/init.c?v=4.7#L282) | [arch/arm64/mm/init.c, line 306](http://lxr.free-electrons.com/source/arch/arm64/mm/init.c?v=4.7#L306) |

## 3.5 build\_all\_zonelists 初始化每个内存节点的 zonelists

内核 setup\_arch 的最后通过 bootmem\_init 中完成了**内存数据结构的初始化**(包括**内存结点 pg\_data\_t**,内存**管理域 zone**和**页面信息 page**),数据结构已经基本准备好了,在后面为内存管理做得一个准备工作就是将**所有节点的管理区(所有的节点 pg\_data\_t 的 zone！！！**)都链入到**zonelist**中, 便于后面内存分配工作的进行.

内存节点 pg\_data\_t 中将内存节点中的内存区域 zone 按照**某种组织层次**(可配置！！！)存储在一个 zonelist 中, 即 pglist\_data->node\_zonelists 成员信息

```cpp
//  http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L626
typedef struct pglist_data
{
	struct zone node_zones[MAX_NR_ZONES];
	struct zonelist node_zonelists[MAX_ZONELISTS];
}
```

内核定义了内存的一个层次结构关系, 首先试图分配廉价的内存, 如果失败, 则根据访问速度和容量, 逐渐尝试分配更昂贵的内存.

**高端内存最廉价**, 因为**内核**没有任何部分**依赖于从该内存域分配的内存**,如果高端内存用尽,对内核没有副作用, 所以优先分配高端内存

普通内存域的情况有所不同, 许多内核数据结构必须保存在该内存域, 而不能放置到高端内存域, 因此如果普通内存域用尽, 那么内核会面临内存紧张的情况

DMA 内存域最昂贵, 因为它用于外设和系统之间的数据传输.

举例来讲, 如果内核指定想要分配高端内存域. 它首先在当前结点的高端内存域寻找适当的空闲内存段, 如果失败, 则查看该结点的普通内存域, 如果还失败, 则试图在该结点的 DMA 内存域分配. 如果在 3 个本地内存域都无法找到空闲内存, 则查看其他结点. 这种情况下, 备选结点应该尽可能靠近主结点, 以最小化访问非本地内存引起的性能损失.

# 4 总结

## 4.1 start\_kernel 启动流程

```cpp
start_kernel()
    |---->page_address_init()
    |     考虑支持高端内存
    |     业务: 初始化 page_address_pool 链表;
    |          将 page_address_maps 数组元素按索引降序插入
    |          page_address_pool 链表;
    |          初始化 page_address_htable 数组.
    |
    |---->setup_arch(&command_line);
    |     初始化特定体系结构的内容
    	|---->arm64_memblock_init( );  [参见 memblock 和 bootmem]
        |     初始化引导阶段的内存分配器 memblock
        |
        |---->paging_init();  [参见分页机制初始化 paging_init]
        |     分页机制初始化
        |
        |---->bootmem_init();  [与 build_all_zonelist 共同完成内存数据结构的初始化]
        |       初始化内存数据结构包括内存节点和内存域
        |
    |---->setup_per_cpu_areas();
    |     为 per-CPU 变量分配空间
    |
    |---->build_all_zonelist();  [bootmem_init 初始化数据结构, 该函数初始化 zonelists]
    |     为系统中的 zone 建立后备 zone 的列表.
    |     所有 zone 的后备列表都在
    |     pglist_data->node_zonelists[0]中;
    |
    |     期间也对 per-CPU 变量 boot_pageset 做了初始化.
    |
    |---->page_alloc_init()
         |---->hotcpu_notifier(page_alloc_cpu_notifier, 0);
         |     不考虑热插拔 CPU
         |
    |---->pidhash_init()
    |     详见下文.
    |     根据低端内存页数和散列度, 分配 hash 空间, 并赋予 pid_hash
    |
    |---->vfs_caches_init_early()
          |---->dcache_init_early()
          |     dentry_hashtable 空间, d_hash_shift, h_hash_mask 赋值;
          |     同 pidhash_init();
          |     区别:
          |         散列度变化了(13 - PAGE_SHIFT);
          |         传入 alloc_large_system_hash 的最后参数值为 0;
          |
          |---->inode_init_early()
          |     inode_hashtable 空间, i_hash_shift, i_hash_mask 赋值;
          |     同 pidhash_init();
          |     区别:
          |         散列度变化了(14 - PAGE_SHIFT);
          |         传入 alloc_large_system_hash 的最后参数值为 0;
          |
```

## 4.2 体系结构相关的初始化工作 setup_arch

Linux 内核启动函数 start\_kernel(), 这里会调用 setup\_arch()完成与体系结构相关的一系列初始化工作, 其中就包括各种内存的初始化工作, 如内存图的建立、管理区的初始化等等.

ARM64 的 setup\_arch

```cpp
//arm64
setup_arch(char **cmdline_p)
    |---->arm64_memblock_init( );
    |     初始化引导阶段的内存分配器 memblock
	|
    |
    |---->paging_init();
    |     分页机制初始化
	|
    |
    |---->bootmem_init();
    |		初始化内存数据结构包括内存节点和内存域
}
```

x86 的 setup\_arch

```cpp
// arch/x86/kernel/setup.c

void __init setup_arch(char **cmdline_p)
{
    /* ...... */
    x86_init.oem.arch_setup();
    e820__memory_setup();
    parse_setup_data();

    /* ...... */

    /* update the e820_saved too */
    e820__reserve_setup_data();

    max_pfn = e820__end_of_ram_pfn();

#ifdef CONFIG_X86_32
    /* max_low_pfn 在这里更新 */
    find_low_pfn_range(); /* 找出低端内存的最大页帧号 */
#else
    check_x2apic();

    /* How many end-of-memory variables you have, grandma! */
    /* need this before calling reserve_initrd */
    if (max_pfn > (1UL<<(32 - PAGE_SHIFT)))
        max_low_pfn = e820__end_of_low_ram_pfn();
    else
        max_low_pfn = max_pfn;

    high_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;
#endif

    /*页表缓冲区申请*/
    early_alloc_pgt_buf();

    /* e820__memblock_setup()之前需要 */
    reserve_brk();

    memblock_set_current_limit(ISA_END_ADDRESS);

    /* memblock 建立 */
    e820__memblock_setup();

    /* 初始化低端内存和高端内存固定映射区的页表 */
    init_mem_mapping();

    /* 初始化内存分配器 */
    initmem_init();

    /* 建立高端内存永久映射区的页表并获取固定映射区的临时映射区页表 */
    x86_init.paging.pagetable_init();
}
```

几乎所有的内存初始化工作都是在 setup_arch()中完成的, 主要的工作包括:

(1)建立内存: e820\_\_memory\_setup(), 排序整理 e820 提供的内存, 对应原来的**setup\_memory\_map**, 可以参见教程 Linux-3.14.12 的《8. 系统启动阶段的 memblock 算法(一)》;

(2)调用 e820\_end\_of\_ram\_pfn()找出最大可用页帧号 max\_pfn, 调用 find\_low\_pfn\_range()找出低端内存区的最大可用页帧号 max\_low\_pfn.

(2)初始化低端内存和高端内存固定映射区的页表: init\_memory\_mapping();

(3)初始化内存分配器: initmem\_init();

(4)建立高端内存永久映射区的页表并获取固定映射区的临时映射区页表: x86\_init.paging.pagetable\_init().

**x86 的 setup\_arch 可以参见教程 Linux-3.14.12**

## 4.3 bootmem\_init 初始化内存的基础数据结构(结点 pg\_data, 内存域 zone, 页面 page)

```cpp
bootmem_init(void)
    |---->min = PFN_UP(memblock_start_of_DRAM());
    |---->max = PFN_DOWN(memblock_end_of_DRAM());
    |
    |
    |---->arm64_numa_init();
    |     支持 numa 架构
    |---->arm64_numa_init();
    |     支持 numa 架构
    |
    |
    |---->zone_sizes_init(min, max);
        来初始化节点和管理区的一些数据项
        |
        |---->free_area_init_node
        |   初始化内存节点
        |
        |
            |---->free_area_init_core 初始化 zone
                |
                |
                |---->memmap_init 初始化 page 页面
                |
                |
    |
    |---->memblock_dump_all();
    |   初始化完成, 显示 memblock 的保留的所有内存信息
```

## 4.4 build\_all\_zonelists 初始化每个内存节点的 zonelists

```cpp
void build_all_zonelists(void)
    |---->set_zonelist_order()
         |---->current_zonelist_order = ZONELIST_ORDER_ZONE;
    |
    |---->__build_all_zonelists(NULL);
    |    Memory 不支持热插拔, 为每个 zone 建立后备的 zone,
    |    每个 zone 及自己后备的 zone, 形成 zonelist
    	|
        |---->pg_data_t *pgdat = NULL;
        |     pgdat = &contig_page_data;(单 node)
        |
        |---->build_zonelists(pgdat);
        |     为每个 zone 建立后备 zone 的列表
            |
            |---->struct zonelist *zonelist = NULL;
            |     enum zone_type j;
            |     zonelist = &pgdat->node_zonelists[0];
            |
            |---->j = build_zonelists_node(pddat, zonelist, 0, MAX_NR_ZONES - 1);
            |     为 pgdat->node_zones[0]建立后备的 zone, node_zones[0]后备的 zone
            |     存储在 node_zonelist[0]内, 对于 node_zone[0]的后备 zone, 其后备的 zone
            |     链表如下(只考虑 UMA 体系, 而且不考虑 ZONE_DMA):
            |     node_zonelist[0]._zonerefs[0].zone = &node_zones[2];
            |     node_zonelist[0]._zonerefs[0].zone_idx = 2;
            |     node_zonelist[0]._zonerefs[1].zone = &node_zones[1];
            |     node_zonelist[0]._zonerefs[1].zone_idx = 1;
            |     node_zonelist[0]._zonerefs[2].zone = &node_zones[0];
            |     node_zonelist[0]._zonerefs[2].zone_idx = 0;
            |
            |     zonelist->_zonerefs[3].zone = NULL;
            |     zonelist->_zonerefs[3].zone_idx = 0;
        |
        |---->build_zonelist_cache(pgdat);
              |---->pdat->node_zonelists[0].zlcache_ptr = NULL;
              |     UMA 体系结构
              |
        |---->for_each_possible_cpu(cpu)
        |     setup_pageset(&per_cpu(boot_pageset, cpu), 0);
              |详见下文
    |---->vm_total_pages = nr_free_pagecache_pages();
    |    业务: 获得所有 zone 中的 present_pages 总和.
    |
    |---->page_group_by_mobility_disabled = 0;
    |     对于代码中的判断条件一般不会成立, 因为页数会最够多(内存较大)
```