
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [伙伴系统](#伙伴系统)
- [2 伙伴系统的结构](#2-伙伴系统的结构)
  - [2.1 伙伴系统数据结构](#21-伙伴系统数据结构)
  - [2.2 最大阶 MAX_ORDER 与 FORCE_MAX_ZONEORDER 配置选项](#22-最大阶-max_order-与-force_max_zoneorder-配置选项)
  - [2.3 内存区是如何连接的](#23-内存区是如何连接的)
  - [2.4 传统伙伴系统算法](#24-传统伙伴系统算法)
- [3	避免碎片](#3-避免碎片)
  - [3.1 内存碎片](#31-内存碎片)
  - [3.2 依据可移动性组织页](#32-依据可移动性组织页)
  - [3.3 避免碎片数据结构](#33-避免碎片数据结构)
    - [3.3.1 迁移类型](#331-迁移类型)
    - [3.3.2 迁移备用列表 fallbacks](#332-迁移备用列表-fallbacks)
    - [3.3.3 全局 pageblock_order 变量](#333-全局-pageblock_order-变量)
    - [3.3.4 gfpflags_to_migratetype 函数转换分配标识到迁移类型](#334-gfpflags_to_migratetype-函数转换分配标识到迁移类型)
    - [3.3.5 pageblock_flags 变量与其函数接口](#335-pageblock_flags-变量与其函数接口)
  - [3.4 初始化基于可移动性的分组](#34-初始化基于可移动性的分组)
- [4 分配器 API](#4-分配器-api)
  - [4.1 分配内存的接口](#41-分配内存的接口)
  - [4.2 释放函数](#42-释放函数)
  - [4.3 分配掩码(gfp_mask 标志)](#43-分配掩码gfp_mask-标志)
    - [4.3.1 分配掩码](#431-分配掩码)
    - [4.3.2 掩码分类](#432-掩码分类)
    - [4.3.3 内核中掩码的定义](#433-内核中掩码的定义)
    - [4.3.5 总结](#435-总结)
    - [4.3.6 掩码函数接口](#436-掩码函数接口)
  - [4.4 分配页](#44-分配页)
    - [4.4.1 内存分配统一到 alloc_pages 接口](#441-内存分配统一到-alloc_pages-接口)
    - [alloc_pages 函数分配页](#alloc_pages-函数分配页)
    - [4.4.3 伙伴系统的心脏__alloc_pages_nodemask](#443-伙伴系统的心脏__alloc_pages_nodemask)
  - [__free_pages](#__free_pages)

<!-- /code_chunk_output -->

# 伙伴系统

在内核初始化完成之后, 内存管理的责任就由伙伴系统来承担.伙伴系统基于一种相对简单然而令人吃惊的强大算法.

Linux 内核使用二进制伙伴算法来管理和分配物理内存页面,该算法由 Knowlton 设计,后来 Knuth 又进行了更深刻的描述.

伙伴系统是一个结合了**2 的方幂个分配器**和**空闲缓冲区合并技术**的内存分配方案, 其基本思想很简单. **内存**被分成**含有很多页面的大块**,**每一块**都是**2 的方幂个页面大小**.如果**找不到**想要的块,一个**大块会被分成两部分**,这两部分彼此就成为伙伴.其中**一半被用来分配**,而**另一半则空闲**.这些块在以后分配的过程中会继续被二分直至产生一个所需大小的块.当一个块被最终释放时,其伙伴将被检测出来,如果**伙伴也空闲则合并两者**.

- 内核如何记住哪些内存块是空闲的

- 分配空闲页面的方法

- 影响分配器行为的众多标识位

- 内存碎片的问题和分配器如何处理碎片

# 2 伙伴系统的结构

## 2.1 伙伴系统数据结构

系统内存中的**每个物理内存页(页帧**), 都对应于一个**struct page 实例**, **每个内存域**都关联了一个 struct zone 的实例, 其中保存了用于**管理伙伴数据的主要数组**

```cpp
//  http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L324
struct zone
{
	 /* free areas of different sizes */
	struct free_area        free_area[MAX_ORDER];
};
```

**struct free\_area**是一个伙伴系统的**辅助数据结构**, 它定义在[include/linux/mmzone.h?v=4.7, line 88](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L88)

```cpp
struct free_area {
	struct list_head        free_list[MIGRATE_TYPES];
    unsigned long           nr_free;
};
```

| 字段 | 描述 |
|:-----:|:-----|
| free\_list | 是用于连接**空闲页的链表**. 页链表包含**大小相同的连续内存区** |
| nr\_free | 指定了当前内存区中**空闲页块的数目**(对 0 阶内存区的块逐页计算, 对 1 阶内存区的块计算 2 页的数目, 对 2 阶内存区计算 4 页集合的数目, 依次类推 |

伙伴系统的分配器维护**空闲页面所组成的块(即内存区**), 这里**每一块都是 2 的方幂个页面**, 方幂的指数称为**阶**.

阶是伙伴系统中一个非常重要的术语.它描述了内存分配的数量单位.**内存块的长度是 2\^order**,其中**order**的范围从**0 到 MAX\_ORDER**

zone\-\>free\_area[MAX\_ORDER]数组中阶作为各个元素的索引,用于指定**对应链表**中的**连续内存区**包含多少个**页帧**.

- 数组中第 0 个元素的阶为 0, 它的 free\_list 链表域指向具有包含区为单页(2\^0=1)的内存页面链表

- 数组中第 1 个元素的 free\_list 域管理的内存区为两页(2^1=2)

- 第 2 个管理的内存区为 4 页, 依次类推.

- 直到**2\^{MAX_ORDER-1}个页面大小的块**

![空闲页快](./images/order_free_list.png)

## 2.2 最大阶 MAX_ORDER 与 FORCE_MAX_ZONEORDER 配置选项

一般来说 MAX\_ORDER 默认定义为 11, 这意味着**一次分配**可以请求的**页数最大是 2\^11=2048**个页面, 参见[include/linux/mmzone.h?v=4.7, line 22](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L22)

```cpp
/* Free memory management - zoned buddy allocator.  */
#ifndef CONFIG_FORCE_MAX_ZONEORDER
#define MAX_ORDER 11
#else
#define MAX_ORDER CONFIG_FORCE_MAX_ZONEORDER
#endif
#define MAX_ORDER_NR_PAGES (1 << (MAX_ORDER - 1))
```

但如果特定于体系结构的代码设置了**FORCE\_MAX\_ZONEORDER**配置选项, 该值也可以手工改变

例如, IA-64 系统上巨大的地址空间可以处理`MAX_ORDER=18`的情形, 而 ARM 或 v850 系统则使用更小的值(如 8 或 9). 但这不一定是由计算机支持的内存数量比较小引起的, 也可能是内存对齐方式的要求所导致

可以参考一些架构的**Kconfig 文件**如下

| arm | arm64 |
|:----:|:-----:|
| [arch/arm/Kconfig?v=4.7, line 1696](http://lxr.free-electrons.com/source/arch/arm/Kconfig?v=4.7#L1696) | [arch/arm64/Kconfig?v=4.7, line 679](http://lxr.free-electrons.com/source/arch/arm64/Kconfig?v=4.7#L679)

比如[arm64 体系结构的 Kconfig 配置文件的描述](http://lxr.free-electrons.com/source/arch/arm64/Kconfig?v=4.7#L679) |

```cpp
config FORCE_MAX_ZONEORDER
int
default "14" if (ARM64_64K_PAGES && TRANSPARENT_HUGEPAGE)
default "12" if (ARM64_16K_PAGES && TRANSPARENT_HUGEPAGE)
default "11"`
```

## 2.3 内存区是如何连接的

**每个内存区(每个块)**中**第 1 页内的链表元素**,可用于**将内存区维持在链表**中. 因此, 也**不必引入新的数据结构(！！！**)来管理**物理上连续的页**, 否则这些页不可能在同一内存区中. 如下图所示

![伙伴系统中相互连接的内存区](./images/buddy_node_connect.png)

伙伴不必是彼此连接的. 如果**一个内存区**在分配**其间分解为两半**,内核会**自动将未用的一半**加入到**对应的链表**中.

如果在未来的某个时刻,由于内存释放的缘故,**两个内存区都处于空闲状态**,可通过**其地址判断其是否为伙伴**.管理工作较少, 是伙伴系统的一个主要优点.

基于**伙伴系统**的内存管理**专注于某个结点的某个内存域(！！！某个节点的某个内存域！！！**),例如,DMA 或高端内存域.**但所有内存域和结点的伙伴系统**都通过**备用分配列表**连接起来.

伙伴系统和内存域／结点之间的关系:

![伙伴系统和内存域／结点之间的关系](./images/buddy_and_node_zone.png)

最后要注意, 有关伙伴系统和当前状态的信息可以在/proc/buddyinfo 中获取

![伙伴系统和当前状态的信息](./images/cat_proc_buddy.png)

上述输出给出了各个内存域中每个分配阶中空闲项的数目,**从左至右,阶依次升高**.上面给出的信息取自**4GiB 物理内存的 AMD64 系统**.

x86\_64 的 16GB 系统:

```
[root@tsinghua-pcm ~]# cat /proc/buddyinfo
Node 0, zone      DMA      0      0      0      0      2      1      1      0      1      1      3
Node 0, zone    DMA32      1      1      1      3      4      3      3      5      0      2    745
Node 0, zone   Normal    166    157    202    437    122    187     77     60     60      8   2003
```

## 2.4 传统伙伴系统算法

在**内核分配内存**时,必须记录**页帧的已分配或空闲状态**,以免**两个进程使用同样的内存区域**.由于内存分配和释放非常频繁, 内核还必须保证相关操作尽快完成.内核可以**只分配完整的页帧**.将内存划分为更小的部分的工作, 则委托给**用户空间中的标准库**.标准库将来源于内核的**页帧拆分为小的区域**,并为进程分配内存.

内核中很多时候**要求分配连续页**. 为快速检测内存中的连续区域, 内核采用了一种古老而历经检验的技术: **伙伴系统**

系统中的**空闲内存块(！！！空闲的块**)总是**两两分组**,每组中的**两个内存块称作伙伴**.伙伴的分配可以是彼此独立的. 但如果**两个伙伴都是空闲的**,内核会将其**合并为一个更大的内存块**,作为**下一层次上某个内存块的伙伴**.

下图示范了该系统, 图中给出了**一对伙伴**,**初始大小**均为**8 页**.即系统中**所有的页面都是 8 页**的.

![伙伴系统](./images/buddy_system.png)

内核对所有大小相同的伙伴(1、2、4、8、16 或其他数目的页),都放置到同一个列表中管理.各有 8 页的一对伙伴也在相应的列表中.

如果系统现在需要**8 个页帧**,则将**16 个页帧组成的块**拆分为**两个伙伴**.其中一块用于满足应用程序的请求, 而剩余的 8 个页帧则放置到对应 8 页大小内存块的列表中.

如果下一个请求**只需要 2 个连续页帧**,则由**8 页组成的块**会分裂成**2 个伙伴**,每个包含**4 个页帧**.其中**一块放置回伙伴列表**中, 而**另一个**再次分裂成**2 个伙伴**,每个包含**2 页**. 其中**一个回到伙伴系统**, 另一个则**传递给应用程序(分配时候会从伙伴系统去掉！！！**).

在应用程序**释放内存**时,内核可以**直接检查地址**,来判断**是否能够创建一组伙伴**,并合并为一个更大的内存块放回到伙伴列表中,这刚好是**内存块分裂的逆过程(释放内存可能会将内存块放回伙伴列表！！！**). 这提高了较大内存块可用的可能性.

在系统长期运行时, 服务器运行几个星期乃至几个月是很正常的, 许多桌面系统也趋向于长期开机运行, 那么会发生称为**碎片的内存管理问题**. **频繁的分配和释放页帧**可能导致一种情况: 系统中有**若干页帧是空闲**的, 但却**散布在物理地址空间的各处**. 换句话说, 系统中**缺乏连续页帧组成的较大的内存块**, 而从性能上考虑, 却又很需要使用较大的连续内存块. 通过伙伴系统可以在某种程度上减少这种效应, 但无法完全消除. 如果在大块的连续内存中间刚好有一个页帧分配出去, 很显然这两块空闲的内存是无法合并的.

在**内核版本 2.6.24**之后, 增加了一些有效措施来防止内存碎片.

# 3	避免碎片

在第 1 章给出的简化说明中, **一个双链表**即可满足伙伴系统的所有需求.在内核版本 2.6.23 之前,的确是这样. 但在内核 2.6.24 开发期间, 内核开发者对伙伴系统的争论持续了相当长时间.这是因为伙伴系统是内核最值得尊敬的一部分, 对它的改动不会被大家轻易接受

## 3.1 内存碎片

伙伴系统的基本原理已经在第 1 章中讨论过, 其方案在最近几年间确实工作得非常好. 但在 Linux 内存管理方面, 有一个长期存在的问题: 在系统启动并**长期运行后**, **物理内存(伙伴系统中存的都是空闲内存块！！！**)会产生很多**碎片**. 该情形如下图所示

![物理内存的碎片](./images/physical_memory_fragmentation.png)

假定内存由**60 页**组成, 这显然不是超级计算机, 但用于示例却足够了. **左侧的地址空间中散布着空闲页**. 尽管大约 25%的物理内存仍然未分配, 但**最大的连续空闲区只有一页**.这**对用户空间应用程序没有问题(！！！**): 其内存是**通过页表映射(！！！**)的, 无论空闲页在物理内存中的分布如何, **应用程序**看到的内存似乎**总是连续的**. 右图给出的情形中, 空闲页和使用页的数目与左图相同, 但所有空闲页都位于一个连续区中.

但对**内核**来说, 碎片是一个问题.由于(**大多数)物理内存一致映射到地址空间的内核部分**,那么在左图的场景中, 无法映射比一页更大的内存区.尽管许多时候内核都分配的是比较小的内存,但也有时候需要分配多于一页的内存. 显而易见, 在分配较大内存的情况下,右图中所有已分配页和空闲页都处于连续内存区的情形, 是更为可取的.

很有趣的一点是, 在**大部分内存仍然未分配**时, 就也**可能发生碎片问题**. 考虑下图.

**只分配了 4 页**, 但可分配的**最大连续区只有 8 页**, 因为伙伴系统所能工作的**分配范围只能是 2 的幂次**.

![物理内存的碎片](./images/some_memory_fragmentation.png)

我提到内存碎片只涉及内核, 这只是部分正确的. 大多数现代 CPU 都提供了使用**巨型页**的可能性, 比普通页大得多. 这对**内存使用密集的应用程序有好处**. 在使用更大的页时, 地址转换后缓冲器只需处理较少的项, 降低了 TLB 缓存失效的可能性. 但**分配巨型页需要连续的空闲物理内存**！

很长时间以来, 物理内存的碎片确实是 Linux 的弱点之一. 尽管已经提出了许多方法, 但没有哪个方法能够既满足 Linux 需要处理的各种类型工作负荷提出的苛刻需求, 同时又对其他事务影响不大.

## 3.2 依据可移动性组织页

在内核 2.6.24 开发期间, 防止碎片的方法最终加入内核. 在我讨论具体策略之前, 有一点需要澄清.

**文件系统也有碎片**, 该领域的碎片问题主要通过**碎片合并工具**解决. 它们分析文件系统, **重新排序已分配存储块**, 从而建立较大的连续存储区.理论上, 该方法对物理内存也是可能的, 但由于许多物理内存页不能移动到任意位置, 阻碍了该方法的实施. 因此, 内核的方法是**反碎片(anti-fragmentation**),即试图**从最初开始尽可能防止碎片**.

<font color=0x00ffff>
反碎片的工作原理如何?
</font>

为理解该方法, 我们必须知道内核将**已分配页**划分为下面 3 种不同类型.

| 页面类型 | 描述 | 举例 |
|:---------:|:-----|:-----|
| 不可移动页 | 在内存中有固定位置, **不能移动**到其他地方. | 核心**内核**分配的**大多数内存**属于该类别 |
| 可移动页 | **可以随意地移动**. | 属于**用户空间应用程序的页**属于该类别. 它们是通过页表映射的<br>如果它们复制到新位置, **页表项可以相应地更新**, 应用程序不会注意到任何事 |
| 可回收页 | **不能直接移动, 但可以删除, 其内容可以从某些源重新生成**. | 例如, **映射自文件的数据**属于该类别<br>**kswapd 守护进程**会根据可回收页访问的**频繁程度**, 周期性释放此类内存.页面回收本身就是一个复杂的过程.内核会在可回收页占据了太多内存时进行回收,在内存短缺(即分配失败)时也可以发起页面回收. |

页的可移动性, 依赖该页属于 3 种类别的哪一种.内核使用的**反碎片技术**,即基于将具有**相同可移动性的页**分组的思想.

<font color=0x00ffff>
为什么这种方法有助于减少碎片?
</font>

由于**页无法移动**,导致在原本几乎全空的内存区中无法进行**连续分配**.根据**页的可移动性**,将其分配到**不同的列表**中,即可防止这种情形.例如,不可移动的页不能位于可移动内存区的中间,否则就无法从该内存区分配较大的连续内存块.

想一下, 上图中大多数空闲页都属于可回收的类别,而分配的页则是不可移动的.如果这些页聚集到**两个不同的列表**中, 如下图所示. 在**不可移动页**中仍然**难以找到较大的连续空闲空间**,但对**可回收的页**,就**容易**多了.

减少内存碎片:

![减少内存碎片](./images/little_memory_fragmentation.png)

但要注意, 从**最初开始**,内存**并未划分**为可移动性不同的区.这些是在**运行时形成**的.内核的另一种方法确实将内存分区,分别用于可移动页和不可移动页的分配,我会下文讨论其工作原理.但这种划分对这里描述的方法是不必要的

## 3.3 避免碎片数据结构

### 3.3.1 迁移类型

尽管内核使用的反碎片技术卓有成效, 它**对伙伴分配器的代码和数据结构几乎没有影响(！！！**). 内核定义了一些**枚举常量(早期用宏来实现**)来表示**不同的迁移类型**, 参见[include/linux/mmzone.h?v=4.7, line 38](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L38)

```cpp
enum {
        MIGRATE_UNMOVABLE,
        MIGRATE_MOVABLE,
        MIGRATE_RECLAIMABLE,
        MIGRATE_PCPTYPES,       /* the number of types on the pcp lists */
        MIGRATE_HIGHATOMIC = MIGRATE_PCPTYPES,
#ifdef CONFIG_CMA
        /*
         * MIGRATE_CMA migration type is designed to mimic the way
         * ZONE_MOVABLE works.  Only movable pages can be allocated
         * from MIGRATE_CMA pageblocks and page allocator never
         * implicitly change migration type of MIGRATE_CMA pageblock.
         *
         * The way to use it is to change migratetype of a range of
         * pageblocks to MIGRATE_CMA which can be done by
         * __free_pageblock_cma() function.  What is important though
         * is that a range of pageblocks must be aligned to
         * MAX_ORDER_NR_PAGES should biggest page be bigger then
         * a single pageblock.
         */
        MIGRATE_CMA,
#endif
#ifdef CONFIG_MEMORY_ISOLATION
        MIGRATE_ISOLATE,        /* can't allocate from here */
#endif
        MIGRATE_TYPES
};
```

|  宏  | 类型 |
|:----:|:-----:|
| MIGRATE\_UNMOVABLE | 不可移动页 |
| MIGRATE\_MOVABLE | 可移动页 |
| MIGRATE\_RECLAIMABLE | 可回收页 |
| MIGRATE\_PCPTYPES | 是 per\_cpu\_pageset,即用来表示**每 CPU 页框高速缓存**的数据结构中的链表的迁移类型数目 |
| MIGRATE\_HIGHATOMIC |  =MIGRATE\_PCPTYPES,在罕见的情况下, 内核需要分配一个高阶的页面块而不能休眠.如果向具有特定可移动性的列表请求分配内存失败, 这种紧急情况下可从 MIGRATE\_HIGHATOMIC 中分配内存 |
| MIGRATE\_CMA | Linux 内核最新的**连续内存分配器**(CMA), 用于**避免预留大块内存** |
| MIGRATE\_ISOLATE | 是一个特殊的虚拟区域,用于**跨越 NUMA 结点移动物理内存页**.在大型系统上,它有益于将**物理内存页**移动到接近于**使用该页最频繁的 CPU**. |
| MIGRATE\_TYPES | 只是表示迁移类型的数目, 也不代表具体的区域 |

对于 MIGRATE\_CMA 类型, 其中在我们使用 ARM 等嵌入式 Linux 系统的时候,一个头疼的问题是 GPU,Camera,HDMI 等都需要**预留大量连续内存**, 这部分内存**平时不用**, 但是一般的做法又必须**先预留着**. 目前, Marek Szyprowski 和 Michal Nazarewicz 实现了一套全新的**Contiguous Memory Allocator**.通过这套机制,我们可以做到**不预留内存**, 这些内存**平时是可用的**, 只有当需要的时候才被分配给 Camera, HDMI 等设备.参照[宋宝华--Linux 内核最新的连续内存分配器(CMA)——避免预留大块内存](http://21cnbao.blog.51cto.com/109393/898846/),内核为此提供了函数 is\_migrate\_cma 来**检测当前类型**是否为 MIGRATE\_CMA,该函数定义在[include/linux/mmzone.h?v=4.7, line 69](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L69)

```cpp
/* In mm/page_alloc.c; keep in sync also with show_migration_types() there */
extern char * const migratetype_names[MIGRATE_TYPES];

#ifdef CONFIG_CMA
#  define is_migrate_cma(migratetype) unlikely((migratetype) == MIGRATE_CMA)
#else
#  define is_migrate_cma(migratetype) false
#endif
```

对伙伴系统数据结构的主要调整,是将**空闲列表**分解为**MIGRATE\_TYPE 个列表**,可以参见 free\_area 的定义[**include/linux/mmzone.h**?v=4.7, line 88](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L88)

```cpp
struct free_area
{
	struct list_head        free_list[MIGRATE_TYPES];
    unsigned long           nr_free;
};
```

- nr\_free 统计了**所有列表**上**空闲页的数目**, 而**每种迁移类型**都对应于**一个空闲列表(每种迁移类型对应一个空闲列表！！！**)

宏 for\_each\_migratetype\_order(order, type)可用于**迭代指定迁移类型的所有分配阶**

```cpp
#define for_each_migratetype_order(order, type) \
        for (order = 0; order < MAX_ORDER; order++) \
                for (type = 0; type < MIGRATE_TYPES; type++)
```
这样我们的伙伴系统的内存框架就如下所示

依据可移动性组织页:

![config](images/migrate_buddy.png)

### 3.3.2 迁移备用列表 fallbacks

<font color = 0x00ffff>
如果内核无法满足针对某一给定迁移类型的分配请求, 会怎么样?
</font>

此前已经出现过一个类似的问题,即**特定的 NUMA 内存域无法满足分配请求**时.我们需要从其他内存域中选择一个代价最低的内存域完成内存的分配,因此内核在内存的结点**pg\_data\_t**中提供了一个**备用内存域列表 zonelists**.

内核在**内存迁移的过程(！！！**)中处理这种情况下的做法是类似的.提供了一个备用列表**fallbacks**,规定了在指定列表中**无法满足分配请求**时.接下来应使用**哪一种迁移类型**, 定义在[**mm/page_alloc.c**?v=4.7, line 1799](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L1799)

```cpp
/*
 * This array describes the order lists are fallen back to when
 * the free lists for the desirable migrate type are depleted
 * 该数组描述了指定迁移类型的空闲列表耗尽时
 * 其他空闲列表在备用列表中的次序
 */
static int fallbacks[MIGRATE_TYPES][4] = {
	//  分配不可移动页失败的备用列表
    [MIGRATE_UNMOVABLE]   = { MIGRATE_RECLAIMABLE, MIGRATE_MOVABLE,   MIGRATE_TYPES },
    //  分配可回收页失败时的备用列表
    [MIGRATE_RECLAIMABLE] = { MIGRATE_UNMOVABLE,   MIGRATE_MOVABLE,   MIGRATE_TYPES },
    //  分配可移动页失败时的备用列表
    [MIGRATE_MOVABLE]     = { MIGRATE_RECLAIMABLE, MIGRATE_UNMOVABLE, MIGRATE_TYPES },
#ifdef CONFIG_CMA
    [MIGRATE_CMA]     = { MIGRATE_TYPES }, /* Never used */
#endif
#ifdef CONFIG_MEMORY_ISOLATION
    [MIGRATE_ISOLATE]     = { MIGRATE_TYPES }, /* Never used */
#endif
};
```

该数据结构大体上是自明的 :

每一行对应一个类型的备用搜索域的顺序,在内核想要**分配**不可移动页**MIGRATE\_UNMOVABLE**时,如果**对应链表为空**,则**遍历 fallbacks[MIGRATE\_UNMOVABLE]**,首先后退到**可回收页链表**`MIGRATE_RECLAIMABLE`,接下来到**可移动页链表**`MIGRATE_MOVABLE`,最后到**紧急分配链表**`MIGRATE_TYPES`.

### 3.3.3 全局 pageblock_order 变量

尽管**页可移动性分组特性**的**全局变量**和**辅助函数**总是**编译到内核**中, 但只有在系统中**有足够内存可以分配到多个迁移类型对应的链表(！！！**)时, 才是有意义的. 由于**每个迁移链表都应该有适当数量的内存(！！！迁移链表的内存**), 内核需要定义"适当"的概念.这是通过两个全局变量 pageblock\_order 和 pageblock\_nr\_pages 提供的.

第一个表示内核认为是"大"的**一个分配阶**,**pageblock\_nr\_pages**则表示**该分配阶对应的页数(！！！**). 如果体系结构提供了**巨型页机制**,则**pageblock\_order**通常定义为**巨型页对应的分配阶**.定义在[include/linux/pageblock-flags.h?v=4.7, line 44](http://lxr.free-electrons.com/source/include/linux/pageblock-flags.h?v=4.7#L42)

```cpp
#ifdef CONFIG_HUGETLB_PAGE

    #ifdef CONFIG_HUGETLB_PAGE_SIZE_VARIABLE

        /* Huge page sizes are variable */
        extern unsigned int pageblock_order;

    #else /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */

    /* Huge pages are a constant size */
        #define pageblock_order         HUGETLB_PAGE_ORDER

    #endif /* CONFIG_HUGETLB_PAGE_SIZE_VARIABLE */

#else /* CONFIG_HUGETLB_PAGE */

    /* If huge pages are not used, group by MAX_ORDER_NR_PAGES */
    #define pageblock_order         (MAX_ORDER-1)

#endif /* CONFIG_HUGETLB_PAGE */

#define pageblock_nr_pages      (1UL << pageblock_order)
```

在 IA-32 体系结构上, **巨型页长度是 4MB(Linux 使用 32-bit 的 PSE 了??**),因此**每个巨型页由 1024 个普通页组成**,而**HUGETLB\_PAGE\_ORDER**则定义为 10.相比之下,IA-64 体系结构允许设置**可变的普通和巨型页长度**,因此 HUGETLB\_PAGE\_ORDER 的值**取决于内核配置**.

如果体系结构**不支持巨型页**, 则将其定义为**第二高的分配阶**, 即`MAX_ORDER - 1`

```cpp
/* If huge pages are not used, group by MAX_ORDER_NR_PAGES */
#define pageblock_order         (MAX_ORDER-1)
```

如果**各迁移类型的链表**中没有一块较大的连续内存,那么**页面迁移不会提供任何好处**,因此在**可用内存太少时内核会关闭该特性**.这是在**build\_all\_zonelists**函数中检查的,该函数用于初始化内存域列表.如果没有足够的内存可用, 则**全局变量**[**page\_group\_by\_mobility\_disabled**](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L79)设置为 0, 否则设置为 1.

内核如何知道**给定的分配内存**属于**何种迁移类型**?

我们将在以后讲解, 有关**各个内存分配的细节**都通过**分配掩码指定**.

内核提供了两个标志, 分别用于表示分配的内存是**可移动**的(**\_\_GFP\_MOVABLE**)或**可回收**的(**\_\_GFP\_RECLAIMABLE**).

### 3.3.4 gfpflags_to_migratetype 函数转换分配标识到迁移类型

如果这些标志**都没有设置**,则**分配的内存假定为不可移动的**.辅助函数 gfpflags\_to\_migratetype 可用于**转换分配标志及对应的迁移类型**, 该函数定义在[include/linux/gfp.h?v=4.7, line 266](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L266)

```cpp
static inline int gfpflags_to_migratetype(const gfp_t gfp_flags)
{
    VM_WARN_ON((gfp_flags & GFP_MOVABLE_MASK) == GFP_MOVABLE_MASK);
    BUILD_BUG_ON((1UL << GFP_MOVABLE_SHIFT) != ___GFP_MOVABLE);
    BUILD_BUG_ON((___GFP_MOVABLE >> GFP_MOVABLE_SHIFT) != MIGRATE_MOVABLE);

    if (unlikely(page_group_by_mobility_disabled))
        return MIGRATE_UNMOVABLE;

    /* Group based on mobility */
    return (gfp_flags & GFP_MOVABLE_MASK) >> GFP_MOVABLE_SHIFT;
}
```

>linux-2.6.x 的内核中转换分配标志及对应的迁移类型的辅助函数为 allocflags\_to\_migratetype,这个名字会有歧义的, 让我们误以为参数的标识中有 alloc flags,但是其实并不然,因此后来的内核中将该函数更名为 gfpflags\_to\_migratetype, 参见[Rename it to gfpflags_to_migratetype()](https://patchwork.kernel.org/patch/4291831)

在 2.6.25 中为如下接口

```cpp
/* Convert GFP flags to their corresponding migrate type */
static inline int allocflags_to_migratetype(gfp_t gfp_flags)
{
    WARN_ON((gfp_flags & GFP_MOVABLE_MASK) == GFP_MOVABLE_MASK);

    if (unlikely(page_group_by_mobility_disabled))
        return MIGRATE_UNMOVABLE;

    /* Group based on mobility */
    return (((gfp_flags & __GFP_MOVABLE) != 0) << 1) |
        ((gfp_flags & __GFP_RECLAIMABLE) != 0);
}
```

如果**停用了页面迁移**特性,则**所有的页都是不可移动**的.否则.该函数的**返回值**可以直接用作 free\_area.free\_list 的**数组索引**.

### 3.3.5 pageblock_flags 变量与其函数接口

最后要注意, 每个内存域都提供了一个特殊的字段,可以**跟踪包含 pageblock\_nr\_pages 个页的内存区的属性**.即 zone->pageblock\_flags 字段,当前只有**与页可移动性相关的代码使用**,参见[include/linux/mmzone.h?v=4.7, line 367](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L367)

```cpp
struct zone
{
#ifndef CONFIG_SPARSEMEM
    /*
     * Flags for a pageblock_nr_pages block. See pageblock-flags.h.
     * In SPARSEMEM, this map is stored in struct mem_section
     */
    unsigned long       *pageblock_flags;
#endif /* CONFIG_SPARSEMEM */
};
```

在**初始化期间**, 内核自动确保对内存域中的**每个不同的迁移类型分组**,在 pageblock\_flags 中都分配了足够存储 NR\_PAGEBLOCK\_BITS 个比特位的空间. 当前, 表示**一个连续内存区的迁移类型需要 3 个比特位**,参见[include/linux/pageblock-flags.h?v=4.7, line 28](http://lxr.free-electrons.com/source/include/linux/pageblock-flags.h?v=4.7#L28)

```cpp
/* Bit indices that affect a whole block of pages */
enum pageblock_bits {
    PB_migrate,
    PB_migrate_end = PB_migrate + 3 - 1,
            /* 3 bits required for migrate types */
    PB_migrate_skip,/* If set the block is skipped by compaction */

    /*
     * Assume the bits will always align on a word. If this assumption
     * changes then get/set pageblock needs updating.
     */
    NR_PAGEBLOCK_BITS
};
```

内核提供**set\_pageblock\_migratetype**负责设置**以 page 为首的一个内存区的迁移类型**,该函数定义在[mm/page_alloc.c?v=4.7, line 458](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L458), 如下所示

```cpp
void set_pageblock_migratetype(struct page *page, int migratetype)
{
    if (unlikely(page_group_by_mobility_disabled &&
             migratetype < MIGRATE_PCPTYPES))
        migratetype = MIGRATE_UNMOVABLE;

    set_pageblock_flags_group(page, (unsigned long)migratetype,
                    PB_migrate, PB_migrate_end);
}
```

`migratetype`参数可以通过上文介绍的`gfpflags_to_migratetype`辅助函数构建. 请注意很重要的一点, **页的迁移类型**是**预先分配**好的,对应的比特位总是可用,与**页是否由伙伴系统管理无关**.在**释放内存**时, 页必须返回到**正确的迁移链表**. 这之所以可行, 是因为能够从**get\_pageblock\_migratetype**获得所需的信息. 参见[include/linux/mmzone.h?v=4.7, line 84](http://lxr.free-electrons.com/source/include/linux/mmzone.h?v=4.7#L84)

```cpp
#define get_pageblock_migratetype(page)                                 \
        get_pfnblock_flags_mask(page, page_to_pfn(page),                \
                        PB_migrate_end, MIGRATETYPE_MASK)
```
最后请注意, 在各个**迁移链表**之间, **当前的页面分配状态**可以从`/proc/pagetypeinfo`获得.

![proc/pagetypeinfo](./images/pagetypeinfo.png)

## 3.4 初始化基于可移动性的分组

在内存子系统初始化期间, **memmap\_init\_zone**负责处理**内存域的 page 实例**.该函数定义在[mm/page_alloc.c?v=4.7, line 5139](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L5139), 该函数完成了一些不怎么有趣的标准初始化工作, 但其中有一件是实质性的, 即**所有的页最初都标记为可移动的**. 参见[mm/page_alloc.c?v=4.7, line 5224](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L5224)

```cpp
/*
 * Initially all pages are reserved - free ones are freed
 * up by free_all_bootmem() once the early boot process is
 * done. Non-atomic initialization, single-pass.
 */
void __meminit memmap_init_zone(unsigned long size, int nid, unsigned long zone,
        unsigned long start_pfn, enum memmap_context context)
{
    /*  ......  */

    for (pfn = start_pfn; pfn < end_pfn; pfn++) {
        /*  ......  */
not_early:
        if (!(pfn & (pageblock_nr_pages - 1))) {
            struct page *page = pfn_to_page(pfn);

            __init_single_page(page, pfn, zone, nid);
            set_pageblock_migratetype(page, MIGRATE_MOVABLE);
        } else {
            __init_single_pfn(pfn, zone, nid);
        }
    }
}
```

在**分配内存**时, 如果必须"盗取"**不同于预定迁移类型的内存区**,内核在策略上**倾向于"盗取"更大的内存区**.由于所有页最初都是可移动的,那么在内核分配不可移动的内存区时,则必须"盗取".

实际上, 在**启动期间**分配**可移动内存区的情况较少**,那么分配器有很高的几率分配长度最大的内存区,并将其**从可移动列表转换到不可移动列表(回收后???**).由于分配的内存区长度是最大的,因此不会向可移动内存中引入碎片.

总而言之, 这种做法**避免**了**启动期间内核分配的内存**(经常在系统的**整个运行时间都不释放**)散布到物理内存各处, 从而**使其他类型的内存分配免受碎片的干扰**, 这也是页可移动性分组框架的最重要的目标之一.

# 4 分配器 API

## 4.1 分配内存的接口

就伙伴系统的接口而言,NUMA 或 UMA 体系结构是没有差别的,二者的调用语法都是相同的.

所有函数的一个共同点是 : **只能分配 2 的整数幂个页(！！！**).

因此, 接口中不像 C 标准库的 malloc 函数或 bootmem 和 memblock 分配器那样指定了所需**内存大小**作为参数.相反,必须指定的是**分配阶**,伙伴系统将在内存中**分配 2\^order 页**.内核中细粒度的分配只能借助于**slab 分配器(或者 slub、slob 分配器**),后者基于伙伴系统

| 内存分配函数 | 功能 | 定义 |
|:-----:|:-----|:----|
| alloc\_pages(mask, order) | 分配**2\^order 页**并返回一个 struct page 的实例, 表示分配的**内存块的起始页** | [NUMA-include/linux/gfp.h, line 466](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L466)<br>[UMA-include/linux/gfp.h?v=4.7, line 476](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L476) |
| alloc\_page(mask) | 是前者在 order = 0 情况下的简化形式, **只分配一页** |  [include/linux/gfp.h?v=4.7, line 483](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L483) |
| get\_zeroed\_page(mask) | **分配一页**并**返回一个 page 实例**, 页对应的**内存填充 0**(**所有其他函数, 分配之后页的内容是未定义的！！！**) | [mm/page_alloc.c?v=4.7, line 3900](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3900)| |
| [\_\_get\_free\_pages(mask,order)](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3883)<br>[\_\_get\_free\_page(mask)](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L500) | 工作方式与上述函数相同, 但返回分配**内存块的虚拟地址**, 而**不是 page 实例** |
| get\_dma\_pages(gfp_mask, order) | 用来获得适用于 DMA 的页. | [include/linux/gfp.h?v=4.7, line 503](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L503) |

在空闲内存**无法满足**请求以至于**分配失败**的情况下, 所有上述函数都返回**空指针**(比如 alloc\_pages 和 alloc\_page)或者**0**(比如 get\_zeroed\_page、\_\_get\_free\_pages 和\_\_get\_free\_page).

因此内核在各次分配之后都必须检查返回的结果.这种惯例与设计得很好的用户层应用程序没什么不同,但在内核中忽略检查会导致严重得多的故障

内核除了**伙伴系统函数**之外,还提供了其他内存管理函数.它们**以伙伴系统为基础**,但并**不属于伙伴分配器自身**.这些函数包括**vmalloc**和**vmalloc\_32**,使用**页表**将**不连续的内存映射**到**内核地址空间**中,使之看上去是**连续的**.

还有一组**kmalloc 类型的函数**,用于分配**小于一整页的内存区**.其实现将在本章后续的几节分别讨论.

## 4.2 释放函数

有 4 个函数用于释放不再使用的页, 与所述函数稍有不同

| 内存释放函数 | 描述 |
|:--------------:|:-----|
| [free\_page(struct page *)](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L520)<br>[free\_pages(struct page *, order)](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3918) | 用于将**一个**或**2\^order 页**返回给内存管理子系统. 内存区的**起始地址**由指向该内存区的第一个 page 实例的指针表示 |
| [\_\_free\_page(addr)](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L519)<br>[\_\_free\_pages(addr, order)](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3906) | 类似于前两个函数, 但在表示需要释放的内存区时, 使用了**虚拟内存地址**而不是 page 实例 |

## 4.3 分配掩码(gfp_mask 标志)

### 4.3.1 分配掩码

前述所有函数中强制使用的 mask 参数, 到底是什么语义?

我们知道 Linux 将内存划分为内存域.内核提供了所谓的**内存域修饰符(zone modifier**)(在**掩码的最低 4 个比特位定义**),来指定从**哪个内存域分配所需的页**.

内核使用宏的方式定义了这些掩码,一个掩码的定义被划分为 3 个部分进行定义,我们会逐步展开来讲解,参见[include/linux/gfp.h?v=4.7, line 12~374](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L12), 共计 26 个掩码信息, 因此后面\_\_GFP\_BITS\_SHIFT =  26.

### 4.3.2 掩码分类

Linux 中这些**掩码标志 gfp\_mask**分为 3 种类型 :

| 类型 | 描述 |
|:-----:|:-----|
| 区描述符 | 内核把物理内存分为多个区,每个区用于不同的目的,区描述符指明到底从这些区中的哪一区进行分配 |
| 行为修饰符 | 表示内核应该如何分配所需的内存.在某些特定情况下,只能使用某些特定的方法分配内存 |
| 类型标志 | 组合了行为修饰符和区描述符,将这些可能用到的组合归纳为不同类型 |

### 4.3.3 内核中掩码的定义

**内核中的定义方式**

```cpp
//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7

/*  line 12 ~ line 44  第一部分
 *  定义可掩码所在位的信息, 每个掩码对应一位为 1
 *  定义形式为  #define	___GFP_XXX		0x01u
 */
/* Plain integer GFP bitmasks. Do not use this directly. */
#define ___GFP_DMA              0x01u
#define ___GFP_HIGHMEM          0x02u
#define ___GFP_DMA32            0x04u
#define ___GFP_MOVABLE          0x08u
/*  ......  */

/*  line 46 ~ line 192  第二部分
 *  定义掩码和 MASK 信息, 第二部分的某些宏可能是第一部分一个或者几个的组合
 *  定义形式为  #define	__GFP_XXX		 ((__force gfp_t)___GFP_XXX)
 */
#define __GFP_DMA       ((__force gfp_t)___GFP_DMA)
#define __GFP_HIGHMEM   ((__force gfp_t)___GFP_HIGHMEM)
#define __GFP_DMA32     ((__force gfp_t)___GFP_DMA32)
#define __GFP_MOVABLE   ((__force gfp_t)___GFP_MOVABLE)  /* ZONE_MOVABLE allowed */
#define GFP_ZONEMASK    (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE)

/*  line 194 ~ line 260  第三部分
 *  定义掩码
 *  定义形式为  #define	GFP_XXX		 __GFP_XXX
 */
#define GFP_DMA         __GFP_DMA
#define GFP_DMA32       __GFP_DMA32
```

其中 GFP 缩写的意思为获取空闲页(get free page), \_\_GFP\_MOVABLE 不表示物理内存域, 但通知内核应在特殊的虚拟内存域 ZONE\_MOVABLE 进行相应的分配.

**定义掩码位**

我们首先来看**第一部分**, 内核源代码中定义在[include/linux/gfp.h?v=4.7, line 18 ~ line 44](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L17), 共计 26 个掩码信息.

```cpp
/* Plain integer GFP bitmasks. Do not use this directly. */
//  区域修饰符
#define ___GFP_DMA              0x01u
#define ___GFP_HIGHMEM          0x02u
#define ___GFP_DMA32            0x04u

//  行为修饰符
#define ___GFP_MOVABLE          0x08u	    /* 页是可移动的 */
#define ___GFP_RECLAIMABLE      0x10u	    /* 页是可回收的 */
#define ___GFP_HIGH             0x20u		/* 应该访问紧急分配池? */
#define ___GFP_IO               0x40u		/* 可以启动物理 IO? */
#define ___GFP_FS               0x80u		/* 可以调用底层文件系统? */
#define ___GFP_COLD             0x100u	   /* 需要非缓存的冷页 */
#define ___GFP_NOWARN           0x200u	   /* 禁止分配失败警告 */
#define ___GFP_REPEAT           0x400u	   /* 重试分配, 可能失败 */
#define ___GFP_NOFAIL           0x800u	   /* 一直重试, 不会失败 */
#define ___GFP_NORETRY          0x1000u	  /* 不重试, 可能失败 */
#define ___GFP_MEMALLOC         0x2000u  	/* 使用紧急分配链表 */
#define ___GFP_COMP             0x4000u	  /* 增加复合页元数据 */
#define ___GFP_ZERO             0x8000u	  /* 成功则返回填充字节 0 的页 */
//  类型修饰符
#define ___GFP_NOMEMALLOC       0x10000u	 /* 不使用紧急分配链表 */
#define ___GFP_HARDWALL         0x20000u	 /* 只允许在进程允许运行的 CPU 所关联的结点分配内存 */
#define ___GFP_THISNODE         0x40000u	 /* 没有备用结点, 没有策略 */
#define ___GFP_ATOMIC           0x80000u 	/* 用于原子分配, 在任何情况下都不能中断  */
#define ___GFP_ACCOUNT          0x100000u
#define ___GFP_NOTRACK          0x200000u
#define ___GFP_DIRECT_RECLAIM   0x400000u
#define ___GFP_OTHER_NODE       0x800000u
#define ___GFP_WRITE            0x1000000u
#define ___GFP_KSWAPD_RECLAIM   0x2000000u
```

**定义掩码**

然后**第二部分**, 相对而言每一个宏又被重新定义如下, 参见[include/linux/gfp.h?v=4.7, line 46 ~ line 192](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L46)

```cpp
/*
* Physical address zone modifiers (see linux/mmzone.h - low four bits)
*
* Do not put any conditional on these. If necessary modify the definitions
* without the underscores and use them consistently. The definitions here may
* be used in bit comparisons.
* 定义区描述符
*/
#define __GFP_DMA       ((__force gfp_t)___GFP_DMA)
#define __GFP_HIGHMEM   ((__force gfp_t)___GFP_HIGHMEM)
#define __GFP_DMA32     ((__force gfp_t)___GFP_DMA32)
#define __GFP_MOVABLE   ((__force gfp_t)___GFP_MOVABLE)  /* ZONE_MOVABLE allowed */
#define GFP_ZONEMASK    (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE)

/*
* Page mobility and placement hints
*
* These flags provide hints about how mobile the page is. Pages with similar
* mobility are placed within the same pageblocks to minimise problems due
* to external fragmentation.
*
* __GFP_MOVABLE (also a zone modifier) indicates that the page can be
*   moved by page migration during memory compaction or can be reclaimed.
*
* __GFP_RECLAIMABLE is used for slab allocations that specify
*   SLAB_RECLAIM_ACCOUNT and whose pages can be freed via shrinkers.
*
* __GFP_WRITE indicates the caller intends to dirty the page. Where possible,
*   these pages will be spread between local zones to avoid all the dirty
*   pages being in one zone (fair zone allocation policy).
*
* __GFP_HARDWALL enforces the cpuset memory allocation policy.
*
* __GFP_THISNODE forces the allocation to be satisified from the requested
*   node with no fallbacks or placement policy enforcements.
*
* __GFP_ACCOUNT causes the allocation to be accounted to kmemcg (only relevant
*   to kmem allocations).
*/
#define __GFP_RECLAIMABLE ((__force gfp_t)___GFP_RECLAIMABLE)
#define __GFP_WRITE     ((__force gfp_t)___GFP_WRITE)
#define __GFP_HARDWALL   ((__force gfp_t)___GFP_HARDWALL)
#define __GFP_THISNODE  ((__force gfp_t)___GFP_THISNODE)
#define __GFP_ACCOUNT   ((__force gfp_t)___GFP_ACCOUNT)

/*
* Watermark modifiers -- controls access to emergency reserves
*
* __GFP_HIGH indicates that the caller is high-priority and that granting
*   the request is necessary before the system can make forward progress.
*   For example, creating an IO context to clean pages.
*
* __GFP_ATOMIC indicates that the caller cannot reclaim or sleep and is
*   high priority. Users are typically interrupt handlers. This may be
*   used in conjunction with __GFP_HIGH
 *
 * __GFP_MEMALLOC allows access to all memory. This should only be used when
 *   the caller guarantees the allocation will allow more memory to be freed
 *   very shortly e.g. process exiting or swapping. Users either should
 *   be the MM or co-ordinating closely with the VM (e.g. swap over NFS).
 *
 * __GFP_NOMEMALLOC is used to explicitly forbid access to emergency reserves.
 *   This takes precedence over the __GFP_MEMALLOC flag if both are set.
 */
#define __GFP_ATOMIC    ((__force gfp_t)___GFP_ATOMIC)
#define __GFP_HIGH      ((__force gfp_t)___GFP_HIGH)
#define __GFP_MEMALLOC  ((__force gfp_t)___GFP_MEMALLOC)
#define __GFP_NOMEMALLOC ((__force gfp_t)___GFP_NOMEMALLOC)

/*
 * Reclaim modifiers
 *
 * __GFP_IO can start physical IO.
 *
 * __GFP_FS can call down to the low-level FS. Clearing the flag avoids the
 *   allocator recursing into the filesystem which might already be holding
 *   locks.
 *
 * __GFP_DIRECT_RECLAIM indicates that the caller may enter direct reclaim.
 *   This flag can be cleared to avoid unnecessary delays when a fallback
 *   option is available.
 *
 * __GFP_KSWAPD_RECLAIM indicates that the caller wants to wake kswapd when
 *   the low watermark is reached and have it reclaim pages until the high
 *   watermark is reached. A caller may wish to clear this flag when fallback
 *   options are available and the reclaim is likely to disrupt the system. The
 *   canonical example is THP allocation where a fallback is cheap but
 *   reclaim/compaction may cause indirect stalls.
 *
 * __GFP_RECLAIM is shorthand to allow/forbid both direct and kswapd reclaim.
 *
 * __GFP_REPEAT: Try hard to allocate the memory, but the allocation attempt
 *   _might_ fail.  This depends upon the particular VM implementation.
 *
 * __GFP_NOFAIL: The VM implementation _must_ retry infinitely: the caller
 *   cannot handle allocation failures. New users should be evaluated carefully
 *   (and the flag should be used only when there is no reasonable failure
 *   policy) but it is definitely preferable to use the flag rather than
 *   opencode endless loop around allocator.
 *
 * __GFP_NORETRY: The VM implementation must not retry indefinitely and will
 *   return NULL when direct reclaim and memory compaction have failed to allow
 *   the allocation to succeed.  The OOM killer is not called with the current
 *   implementation.
 */
#define __GFP_IO        ((__force gfp_t)___GFP_IO)
#define __GFP_FS        ((__force gfp_t)___GFP_FS)
#define __GFP_DIRECT_RECLAIM    ((__force gfp_t)___GFP_DIRECT_RECLAIM) /* Caller can reclaim */
#define __GFP_KSWAPD_RECLAIM    ((__force gfp_t)___GFP_KSWAPD_RECLAIM) /* kswapd can wake */
#define __GFP_RECLAIM ((__force gfp_t)(___GFP_DIRECT_RECLAIM|___GFP_KSWAPD_RECLAIM))
#define __GFP_REPEAT    ((__force gfp_t)___GFP_REPEAT)
#define __GFP_NOFAIL    ((__force gfp_t)___GFP_NOFAIL)
#define __GFP_NORETRY   ((__force gfp_t)___GFP_NORETRY)

/*
 * Action modifiers
 *
 * __GFP_COLD indicates that the caller does not expect to be used in the near
 *   future. Where possible, a cache-cold page will be returned.
 *
 * __GFP_NOWARN suppresses allocation failure reports.
 *
 * __GFP_COMP address compound page metadata.
 *
 * __GFP_ZERO returns a zeroed page on success.
 *
 * __GFP_NOTRACK avoids tracking with kmemcheck.
 *
 * __GFP_NOTRACK_FALSE_POSITIVE is an alias of __GFP_NOTRACK. It's a means of
 *   distinguishing in the source between false positives and allocations that
 *   cannot be supported (e.g. page tables).
 *
 * __GFP_OTHER_NODE is for allocations that are on a remote node but that
 *   should not be accounted for as a remote allocation in vmstat. A
 *   typical user would be khugepaged collapsing a huge page on a remote
 *   node.
 */
#define __GFP_COLD      ((__force gfp_t)___GFP_COLD)
#define __GFP_NOWARN    ((__force gfp_t)___GFP_NOWARN)
#define __GFP_COMP      ((__force gfp_t)___GFP_COMP)
#define __GFP_ZERO      ((__force gfp_t)___GFP_ZERO)
#define __GFP_NOTRACK   ((__force gfp_t)___GFP_NOTRACK)
#define __GFP_NOTRACK_FALSE_POSITIVE (__GFP_NOTRACK)
#define __GFP_OTHER_NODE ((__force gfp_t)___GFP_OTHER_NODE)

/* Room for N __GFP_FOO bits */
#define __GFP_BITS_SHIFT 26
#define __GFP_BITS_MASK ((__force gfp_t)((1 << __GFP_BITS_SHIFT) - 1))
```

给出的常数, 其中一些很少使用, 因此我不会讨论. 其中最重要的一些常数语义如下所示

其中在开始的位置定义了对应的**区修饰符**,定义在[include/linux/gfp.h?v=4.7, line 46 ~ line 57](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L46)

| 区修饰符标志 | 描述 |
|:--------------:|:-----|
| \_\_GFP\_DMA | 从 ZONE\_DMA 中分配内存 |
| \_\_GFP\_HIGHMEM | 从 ZONE\_HIGHMEM 或 ZONE\_NORMAL 中分配内存 |
| \_\_GFP\_DMA32 | 从 ZONE\_DMA32 中分配内存 |
| \_\_GFP\_MOVABLE | 从\_\_GFP\_MOVABLE 中分配内存 |

其次还定义了我们程序和函数中所需要的掩码 MASK 的信息,由于其中\_\_GFP\_DMA,\_\_GFP\_DMA32,\_\_GFP\_HIGHMEM,\_\_GFP\_MOVABLE 是在内存中分别有对应的内存域信息,因此我们定义了内存域的掩码 GFP\_ZONEMASK,参见[include/linux/gfp.h?v=4.7, line 57](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L57)

```cpp
#define GFP_ZONEMASK    (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE)
```

接着内核定义了**行为修饰符**

\_\_GFP\_WAIT 表示分配内存的请求可以中断. 也就是说, 调度器在该请求期间可随意选择另一个过程执行, 或者该请求可以被另一个更重要的事件中断. 分配器还可以在返回内存之前, 在队列上等待一个事件(相关进程会进入睡眠状态).

>虽然名字相似, 但\_\_GFP\_HIGH 与\_\_GFP\_HIGHMEM 毫无关系, 请不要弄混这两者

| 行为修饰符 | 描述 |
|:---:|:----:|
| \_\_GFP\_RECLAIMABLE<br>\_\_GFP\_MOVABLE | 是页迁移机制所需的标志.顾名思义, 它们分别将分配的内存标记为可回收的或可移动的. 这影响从空闲列表的哪个子表获取内存 |
| \_\_GFP\_WRITE | |
| \_\_GFP\_HARDWALL | 只在 NUMA 系统上有意义. 它限制只在分配到当前进程的各个 CPU 所关联的结点分配内存. 如果进程允许在所有 CPU 上运行(默认情况), 该标志是无意义的. 只有进程可以运行的 CPU 受限时, 该标志才有效果 |
| \_\_GFP\_THISNODE | 也只在 NUMA 系统上有意义. 如果设置该比特位, 则内存分配失败的情况下不允许使用其他结点作为备用, 需要保证在当前结点或者明确指定的结点上成功分配内存 |
| \_\_GFP\_ACCOUNT | |
|--------|--------|
| \_\_GFP\_ATOMIC | |
| \_\_GFP\_HIGH | 如果请求非常重要, 则设置\_\_GFP\_HIGH, 即内核急切地需要内存时. 在分配内存失败可能给内核带来严重后果时(比如威胁到系统稳定性或系统崩溃), 总是会使用该标志 |
| \_\_GFP\_MEMALLOC | |
| \_\_GFP\_NOMEMALLOC | |
|--------|--------|
| \_\_GFP\_IO |说明在查找空闲内存期间内核可以进行 I/O 操作. 实际上, 这意味着如果内核在内存分配期间换出页, 那么仅当设置该标志时, 才能将选择的页写入硬盘 |
| \_\_GFP\_FS |允许内核执行 VFS 操作. 在与 VFS 层有联系的内核子系统中必须禁用, 因为这可能引起循环递归调用. |
| \_\_GFP\_DIRECT\_RECLAIM | |
| \_\_GFP\_KSWAPD\_RECLAIM | |
| \_\_GFP\_RECLAIM | |
| \_\_GFP\_REPEAT | 在分配失败后自动重试, 但在尝试若干次之后会停止 |
| \_\_GFP\_NOFAIL | 在分配失败后一直重试, 直至成功 |
| \_\_GFP\_NORETRY |  在分配失败后不重试, 因此可能分配失败 |
|--------|--------|
| \_\_GFP\_COLD | 如果需要分配不在 CPU 高速缓存中的"冷"页时, 则设置\__GFP_COLD |
| \_\_GFP\_NOWARN | 在分配失败时禁止内核故障警告. 在极少数场合该标志有用 |
| \_\_GFP\_COMP | 添加混合页元素, 在 hugetlb 的代码内部使用 |
| \_\_GFP\_ZERO | 在分配成功时, 将返回填充字节 0 的页 |
| \_\_GFP\_NOTRACK | |
| \_\_GFP\_NOTRACK\_FALSE\_POSITIVE<BR>\_\_GFP\_NOTRACK | |
| \_\_GFP\_OTHER\_NODE | |

那自然还有\_\_GFP\_BITS\_SHIFT 来表示我们所有的掩码位, 由于我们共计 26 个掩码位

```cpp
/* Room for N __GFP_FOO bits */
#define __GFP_BITS_SHIFT 26
#define __GFP_BITS_MASK ((__force gfp_t)((1 << __GFP_BITS_SHIFT) - 1))
```

可以同时指定这些分配标志, 例如

```cpp
ptr = kmalloc(size, __GFP_IO | __GFP_FS);
```

说明**页分配器**(最终会调用 alloc_page)在分配时**可以执行 I/O**,在必要时还可以**执行文件系统操作**.这就让**内核有很大的自由度**,以便它尽可能找到空闲的内存来满足分配请求.大多数分配器都会执行这些修饰符,但一般不是这样直接指定, 而是将这些行为描述符标志进行分组, 即**类型标志**

**掩码分组**

最后来看**第三部分**, 由于这些标志几乎总是组合使用, 内核作了一些分组, 包含了用于各种标准情形的适当的标志. 称之为**类型标志**, 定义在[include/linux/gfp.h?v=4.7, lien 194 ~ line 258](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L245)

类型标志指定所需的行为和区描述符以安城特殊类型的处理, 正因为这一点, 内核总是趋于使用正确的类型标志, 而不是一味地指定它可能用到的多种描述符. 这么做既简单又不容易出错误.

如果有可能的话, 在内存管理子系统之外, 总是把下列分组之一用于内存分配. 在内核源代码中, 双下划线通常用于内部数据和定义. 而这些预定义的分组名没有双下划线前缀, 点从侧面验证了上述说法.

```cpp
#define GFP_ATOMIC      (__GFP_HIGH|__GFP_ATOMIC|__GFP_KSWAPD_RECLAIM)
#define GFP_KERNEL      (__GFP_RECLAIM | __GFP_IO | __GFP_FS)
#define GFP_KERNEL_ACCOUNT (GFP_KERNEL | __GFP_ACCOUNT)
#define GFP_NOWAIT      (__GFP_KSWAPD_RECLAIM)
#define GFP_NOIO        (__GFP_RECLAIM)
#define GFP_NOFS        (__GFP_RECLAIM | __GFP_IO)
#define GFP_TEMPORARY   (__GFP_RECLAIM | __GFP_IO | __GFP_FS | \
                         __GFP_RECLAIMABLE)
#define GFP_USER        (__GFP_RECLAIM | __GFP_IO | __GFP_FS | __GFP_HARDWALL)
#define GFP_DMA         __GFP_DMA
#define GFP_DMA32       __GFP_DMA32
#define GFP_HIGHUSER    (GFP_USER | __GFP_HIGHMEM)
#define GFP_HIGHUSER_MOVABLE    (GFP_HIGHUSER | __GFP_MOVABLE)
#define GFP_TRANSHUGE   ((GFP_HIGHUSER_MOVABLE | __GFP_COMP | \
                         __GFP_NOMEMALLOC | __GFP_NORETRY | __GFP_NOWARN) & \
                         ~__GFP_RECLAIM)

/* Convert GFP flags to their corresponding migrate type */
#define GFP_MOVABLE_MASK (__GFP_RECLAIMABLE|__GFP_MOVABLE)
#define GFP_MOVABLE_SHIFT 3
```

| 掩码组 | 描述 |
|:-------:|:-----:|
| GFP\_ATOMIC | 用于原子分配, 在任何情况下都不能中断, 可能使用紧急分配链表中的内存, 这个标志用在中断处理程序, 下半部, 持有自旋锁以及其他不能睡眠的地方 |
| GFP\_KERNEL | 这是一种常规的分配方式, 可能会阻塞. 这个标志在睡眠安全时用在进程的长下文代码中. 为了获取调用者所需的内存, 内核会尽力而为. 这个标志应该是首选标志 |
| GFP\_KERNEL\_ACCOUNT | |
| GFP\_NOWAIT | 与 GFP\_ATOMIC 类似, 不同之处在于, 调用不会退给紧急内存池, 这就增加了内存分配失败的可能性 |
| GFP\_NOIO | 这种分配可以阻塞, 但不会启动磁盘 I/O, 这个标志在不能引发更多的磁盘 I/O 时阻塞 I/O 代码, 这可能导致令人不愉快的递归 |
| GFP\_NOFS | 这种分配在必要时可以阻塞, 但是也可能启动磁盘, 但是不会启动文件系统操作, 这个标志在你不鞥在启动另一个文件系统操作时, 用在文件系统部分的代码中 |
| GFP\_TEMPORARY | |
| GFP\_USER | 这是一种常规的分配方式, 可能会阻塞. 这个标志用于为用户空间进程分配内存时使用 |
| GFP\_DMA<br>GFP\_DMA32 | 用于分配适用于 DMA 的内存, 当前是\_\_GFP\_DMA 的同义词, GFP\_DMA32 也是\_\_GFP\_GMA32 的同义词 |
| GFP\_HIGHUSER | 是 GFP\_USER 的一个扩展, 也用于用户空间. 它允许分配无法直接映射的高端内存. 使用高端内存页是没有坏处的, 因为用户过程的地址空间总是通过非线性页表组织的 |
| GFP\_HIGHUSER\_MOVABLE |用途类似于 GFP\_HIGHUSER, 但分配将从虚拟内存域 ZONE\_MOVABLE 进行 |
| GFP\_TRANSHUGE | |

- 其中 GFP\_NOIO 和 GFP\_NOFS, 分别明确禁止 I/O 操作和访问 VFS 层, 但同时设置了\_\_GFP\_RECLAIM, 因此可以被回收

- 而 GFP\_KERNEL 和 GFP\_USER. 分别是内核和用户分配的默认设置. 二者的失败不会立即威胁系统稳定性,GFP\_KERNEL 绝对是内核源代码中最常使用的标志 |

最后内核设置了碎片管理的可移动依据组织页的 MASK 信息 GFP\_MOVABLE\_MASK, 参见[include/linux/gfp.h?v=4.7, line 262](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L262)

```cpp
/* Convert GFP flags to their corresponding migrate type */
#define GFP_MOVABLE_MASK (__GFP_RECLAIMABLE|__GFP_MOVABLE)
#define GFP_MOVABLE_SHIFT 3
```

在你编写的绝大多数代码中, 用么用到的是 GFP\_KERNEL, 要么是 GFP\_ATOMIC, 当然各个类型标志也均有其应用场景

| 情形 | 相应标志 |
|:-----:|:----------|
| 进程上下文, 可以睡眠 | 使用 GFP_KERNEL |
| 进程上下文, 不可以睡眠 | 使用 GFP\_KERNEL, 在你睡眠之前或之后以 GFP_KERNEL 执行内存分配 |
| 中断处理程序 | 使用 GFP\_ATMOIC |
| 软中断 | 使用 GFP\_ATMOIC |
| tasklet | 使用 GFP\_ATMOIC |
| 需要用于 DMA 的内存, 可以睡眠 | 使用(GFP\_DMA GFP\_KERNEL) |
| 需要用于 DMA 的内存, 不可以睡眠 | 使用(GFP\_DMA GFP\_ATOMIC), 或在你睡眠之前执行内存分配 |

### 4.3.5 总结

我们从注释中找到这样的信息, 可以作为参考[]()

```cpp
bit       result
=================
0x0    => NORMAL
0x1    => DMA or NORMAL
0x2    => HIGHMEM or NORMAL
0x3    => BAD (DMA+HIGHMEM)
0x4    => DMA32 or DMA or NORMAL
0x5    => BAD (DMA+DMA32)
0x6    => BAD (HIGHMEM+DMA32)
0x7    => BAD (HIGHMEM+DMA32+DMA)
0x8    => NORMAL (MOVABLE+0)
0x9    => DMA or NORMAL (MOVABLE+DMA)
0xa    => MOVABLE (Movable is valid only if HIGHMEM is set too)
0xb    => BAD (MOVABLE+HIGHMEM+DMA)
0xc    => DMA32 (MOVABLE+DMA32)
0xd    => BAD (MOVABLE+DMA32+DMA)
0xe    => BAD (MOVABLE+DMA32+HIGHMEM)
0xf    => BAD (MOVABLE+DMA32+HIGHMEM+DMA)

GFP_ZONES_SHIFT must be <= 2 on 32 bit platforms.
```

### 4.3.6 掩码函数接口

很有趣的一点是, 没有\_\_GFP\_NORMAL 常数, 而内存分配的主要负担却落到 ZONE\_NORMAL 内存域

内核考虑到这一点, 提供了一个函数 gfp_zone 来计算与给定分配标志兼容的最高内存域.那么内存分配可以从该内存域或更低的内存域进行, 该函数定义在[include/linux/gfp.h?v=4.7, line 394](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L394)

```cpp
static inline enum zone_type gfp_zone(gfp_t flags)
{
    enum zone_type z;
    int bit = (__force int) (flags & GFP_ZONEMASK);

    z = (GFP_ZONE_TABLE >> (bit * GFP_ZONES_SHIFT)) &
                     ((1 << GFP_ZONES_SHIFT) - 1);
    VM_BUG_ON((GFP_ZONE_BAD >> bit) & 1);
    return z;
}
```

其中 GFP\_ZONES\_SHIFT 的定义如下, 在[include/linux/gfp.h?v=4.7, line 337](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L337)


```cpp
#if defined(CONFIG_ZONE_DEVICE) && (MAX_NR_ZONES-1) <= 4
/* ZONE_DEVICE is not a valid GFP zone specifier */
#define GFP_ZONES_SHIFT 2
#else
#define GFP_ZONES_SHIFT ZONES_SHIFT
#endif

#if 16 * GFP_ZONES_SHIFT > BITS_PER_LONG
#error GFP_ZONES_SHIFT too large to create GFP_ZONE_TABLE integer
#endif
```

由于内存域修饰符的解释方式不是那么直观, 表 3-7 给出了该函数结果的一个例子, 其中 DMA 和 DMA32 内存域相同. 假定在下文中没有设置\_\_GFP\_MOVABLE 修饰符.

| 修饰符 | 扫描的内存域 |
|:-------:|:--------------:|
| 无 | ZONE\_NORMAL、ZONE\_DMA |
| \_\_GFP\_DMA | ZONE\_DMA |
| \_\_GFP\_DMA & \_\_GFP\_HIGHMEM | ZONE\_DMA |
| \_\_GFP\_HIGHMEM | ZONE\_HIGHMEM、ZONE\_NORMAL、ZONE\_DMA |

- 如果\_\_GFP\_DMA 和\_\_GFP\_HIGHMEM 都没有设置, 则首先扫描 ZONE\_NORMAL, 后面是 ZONE\_DMA

- 如果设置了\_\_GFP\_HIGHMEM 没有设置\_\_GFP\_DMA, 则结果是从 ZONE\_HIGHMEM 开始扫描所有 3 个内存域. =

- 如果设置了\_\_GFP\_DMA, 那么\_\_GFP\_HIGHMEM 设置与否没有关系. 只有 ZONE\_DMA 用于 3 种情形. 这是合理的, 因为同时使用\_\_GFP\_HIGHMEM 和\_\_GFP\_DMA 没有意义. 高端内存从来都不适用于 DMA

设置\__GFP_MOVABLE 不会影响内核的决策, 除非它与\_\_GFP\_HIGHMEM 同时指定. 在这种情况下, 会使用特殊的虚拟内存域 ZONE_MOVABLE 满足内存分配请求. 对前文描述的内核的反碎片策略而言, 这种行为是必要的.

除了内存域修饰符之外, 掩码中还可以设置一些标志.

下图中给出了掩码的布局, 以及与各个比特位置关联的常数. \_\_GFP\_DMA32 出现了几次, 因为它可能位于不同的地方.

![GFP 掩码的布局](./images/gfp_flag_mask.png)

与内存域修饰符相反, 这些额外的标志并不限制从哪个物理内存段分配内存, 但确实可以改变分配器的行为. 例如, 它们可以修改查找空闲内存时的积极程度.

## 4.4 分配页

### 4.4.1 内存分配统一到 alloc_pages 接口

通过使用标志、内存域修饰符和各个分配函数, 内核提供了一种非常灵活的内存分配体系.尽管如此,所有接口函数都可以追溯到一个简单的基本函数(alloc\_pages\_node)

分配单页的函数[`alloc_page`](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L483)和[`__get_free_page`](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L500), 还有[`__get_dma_pages`](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L503)是借助于宏定义的.

```cpp
//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L483
#define alloc_page(gfp_mask) alloc_pages(gfp_mask, 0)

//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L500
#define __get_free_page(gfp_mask) \
	__get_free_pages((gfp_mask), 0)`

//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L503
#define __get_dma_pages(gfp_mask, order) \
	__get_free_pages((gfp_mask) | GFP_DMA, (order))
```

[`get_zeroed_page`](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3900)的实现也没什么困难, 对`__get_free_pages`使用`__GFP_ZERO`标志, 即可分配**填充字节 0 的页**. 再返回与页关联的内存区地址即可.

```cpp
//  http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3900
unsigned long get_zeroed_page(gfp_t gfp_mask)
{
        return __get_free_pages(gfp_mask | __GFP_ZERO, 0);
}
EXPORT_SYMBOL(get_zeroed_page);
```

[`__get_free_pages`](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3883)调用`alloc_pages`完成内存分配,而**alloc\_pages**又借助于**alloc\_pages\_node**

[`__get_free_pages`](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3883)函数的定义在[mm/page_alloc.c?v=4.7, line 3883](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3883)

```cpp
//  http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3883
unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order)
{
    struct page *page;

    /*
     * __get_free_pages() returns a 32-bit address, which cannot represent
     * a highmem page
     */
    VM_BUG_ON((gfp_mask & __GFP_HIGHMEM) != 0);

    page = alloc_pages(gfp_mask, order);
    if (!page)
        return 0;
    return (unsigned long) page_address(page);
}
EXPORT_SYMBOL(__get_free_pages);
```

在这种情况下,  使用了一个普通函数而不是宏,因为`alloc_pages`返回的`page`实例需要使用辅助

函数**page\_address**转换为内存地址.在这里, 只要知道该函数可根据`page`实例计算**相关页的线性内存地址(！！！线性地址！！！**)即可. **对高端内存页这是有问题的(！！！**)

这样, 就完成了所有分配内存的 API 函数到公共的基础函数 alloc\_pages 的统一

伙伴系统中各个分配函数之间的关系:

![伙伴系统中各个分配函数之间的关系](./images/alloc_pages.png)

所有体系结构都必须实现的标准**函数 clear\_page**,可帮助 alloc\_pages 对页**填充字节 0**, 实现如下表所示

| x86 | arm |
|:----:|:-----:|
| [arch/x86/include/asm/page_32.h?v=4.7, line 24](http://lxr.free-electrons.com/source/arch/x86/include/asm/page_32.h?v=4.7#L24) | [arch/arm/include/asm/page.h?v=4.7#L14](http://lxr.free-electrons.com/source/arch/arm/include/asm/page.h?v=4.7#L142)<br>[arch/arm/include/asm/page-nommu.h](http://lxr.free-electrons.com/source/arch/arm/include/asm/page-nommu.h?v=4.7#L20) |

### alloc_pages 函数分配页

既然**所有的内存分配 API 函数**都可以**追溯到 alloc\_pages**函数,从某种意义上说, 该函数是伙伴系统主要实现的"发射台".

`alloc_pages`函数的定义是**依赖于 NUMA 或者 UMA 架构**的, 定义如下


```cpp
#ifdef CONFIG_NUMA

//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L465
static inline struct page *
alloc_pages(gfp_t gfp_mask, unsigned int order)
{
        return alloc_pages_current(gfp_mask, order);
}

#else

//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L476
#define alloc_pages(gfp_mask, order) \
                alloc_pages_node(numa_node_id(), gfp_mask, order)
#endif
```

**UMA 结构**下的**alloc\_pages**是通过**alloc\_pages\_node 函数**实现的,下面我们看看`alloc_pages_node`函数的定义, 在[include/linux/gfp.h?v=4.7, line 448](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L448)

```cpp
//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L448
/*
 * Allocate pages, preferring the node given as nid. When nid == NUMA_NO_NODE,
 * prefer the current CPU's closest node. Otherwise node must be valid and
 * online.
 */
static inline struct page *alloc_pages_node(int nid, gfp_t gfp_mask,
                        unsigned int order)
{
    if (nid == NUMA_NO_NODE)
        nid = numa_mem_id();

    return __alloc_pages_node(nid, gfp_mask, order);
}
````

它只是执行了一个简单的检查, 如果**指定负的结点 ID**(不存在, 即[NUMA\_NO\_NODE = -1](http://lxr.free-electrons.com/source/include/linux/numa.h?v=4.7#L13)), 内核自动地使用**当前执行 CPU 对应的结点 nid** = [numa_mem_id();](http://lxr.free-electrons.com/source/include/linux/topology.h?v=4.7#L137), 然后调用`__alloc_pages_node`函数进行了内存分配

`__alloc_pages_node`函数定义在[include/linux/gfp.h?v=4.7, line 435)](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L435), 如下所示

```cpp
// http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L435
/*
 * Allocate pages, preferring the node given as nid. The node must be valid and
 * online. For more general interface, see alloc_pages_node().
 */
static inline struct page *
__alloc_pages_node(int nid, gfp_t gfp_mask, unsigned int order)
{
    VM_BUG_ON(nid < 0 || nid >= MAX_NUMNODES);
    VM_WARN_ON(!node_online(nid));

    return __alloc_pages(gfp_mask, order, node_zonelist(nid, gfp_mask));
}
```

内核假定传递给该 alloc\_pages\_node 函数的**结点 nid 是被激活**,即**online**的.但是为了安全它还是**检查并警告内存结点不存在**的情况.接下来的工作委托给\_\_alloc\_pages,只需传递一组适当的参数,其中包括**节点 nid**的**备用内存域列表 zonelist**.

现在`__alloc_pages`函数没什么特别的, 它直接将自己的所有信息传递给`__alloc_pages_nodemask`来完成内存的分配

```cpp
//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L428
static inline struct page *
__alloc_pages(gfp_t gfp_mask, unsigned int order,
        struct zonelist *zonelist)
{
    return __alloc_pages_nodemask(gfp_mask, order, zonelist, NULL);
}
```

### 4.4.3 伙伴系统的心脏__alloc_pages_nodemask

内核源代码将**\_\_alloc\_pages**称之为"**伙伴系统的心脏**"(`the 'heart' of the zoned buddy allocator``), 因为它处理的是**实质性的内存分配**.

由于"心脏"的重要性, 我将在下文详细介绍该函数.

`__alloc_pages`函数定义在[include/linux/gfp.h?v=4.7#L428](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L428)

```cpp
//  http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3779
/*
 * This is the 'heart' of the zoned buddy allocator.
 */
struct page *
__alloc_pages_nodemask(gfp_t gfp_mask, unsigned int order,
            struct zonelist *zonelist, nodemask_t *nodemask)
{
    struct page *page;
    unsigned int cpuset_mems_cookie;
    unsigned int alloc_flags = ALLOC_WMARK_LOW|ALLOC_FAIR;
    gfp_t alloc_mask = gfp_mask; /* The gfp_t that was actually used for allocation */
    struct alloc_context ac = {
        .high_zoneidx = gfp_zone(gfp_mask),
        .zonelist = zonelist,
        .nodemask = nodemask,
        .migratetype = gfpflags_to_migratetype(gfp_mask),
    };

    if (cpusets_enabled()) {
        alloc_mask |= __GFP_HARDWALL;
        alloc_flags |= ALLOC_CPUSET;
        if (!ac.nodemask)
            ac.nodemask = &cpuset_current_mems_allowed;
    }

    gfp_mask &= gfp_allowed_mask;

    lockdep_trace_alloc(gfp_mask);

    might_sleep_if(gfp_mask & __GFP_DIRECT_RECLAIM);

    if (should_fail_alloc_page(gfp_mask, order))
        return NULL;

    /*
     * Check the zones suitable for the gfp_mask contain at least one
     * valid zone. It's possible to have an empty zonelist as a result
     * of __GFP_THISNODE and a memoryless node
     */
    if (unlikely(!zonelist->_zonerefs->zone))
        return NULL;

    if (IS_ENABLED(CONFIG_CMA) && ac.migratetype == MIGRATE_MOVABLE)
        alloc_flags |= ALLOC_CMA;

retry_cpuset:
    cpuset_mems_cookie = read_mems_allowed_begin();

    /* Dirty zone balancing only done in the fast path */
    ac.spread_dirty_pages = (gfp_mask & __GFP_WRITE);

    /*
     * The preferred zone is used for statistics but crucially it is
     * also used as the starting point for the zonelist iterator. It
     * may get reset for allocations that ignore memory policies.
     */
    ac.preferred_zoneref = first_zones_zonelist(ac.zonelist,
                    ac.high_zoneidx, ac.nodemask);
    if (!ac.preferred_zoneref) {
        page = NULL;
        goto no_zone;
    }

    /* First allocation attempt */
    page = get_page_from_freelist(alloc_mask, order, alloc_flags, &ac);
    if (likely(page))
        goto out;

    /*
     * Runtime PM, block IO and its error handling path can deadlock
     * because I/O on the device might not complete.
     */
    alloc_mask = memalloc_noio_flags(gfp_mask);
    ac.spread_dirty_pages = false;

    /*
     * Restore the original nodemask if it was potentially replaced with
     * &cpuset_current_mems_allowed to optimize the fast-path attempt.
     */
    if (cpusets_enabled())
        ac.nodemask = nodemask;
    page = __alloc_pages_slowpath(alloc_mask, order, &ac);

no_zone:
    /*
     * When updating a task's mems_allowed, it is possible to race with
     * parallel threads in such a way that an allocation can fail while
     * the mask is being updated. If a page allocation is about to fail,
     * check if the cpuset changed during allocation and if so, retry.
     */
    if (unlikely(!page && read_mems_allowed_retry(cpuset_mems_cookie))) {
        alloc_mask = gfp_mask;
        goto retry_cpuset;
    }

out:
    if (kmemcheck_enabled && page)
        kmemcheck_pagealloc_alloc(page, order, gfp_mask);

    trace_mm_page_alloc(page, order, alloc_mask, ac.migratetype);

    return page;
}
EXPORT_SYMBOL(__alloc_pages_nodemask);
```

## __free_pages

类似地, 内存释放函数也可以归约到一个主要的函数(**\_\_free\_pages**),只是用不同的参数调用而已

前面我们讲过内核释放的两个主要函数有\_\_free\_page 和 free\_page,它们的定义在[include/linux/gfp.h?v=4.7#L519](http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L519)

```cpp
//  http://lxr.free-electrons.com/source/include/linux/gfp.h?v=4.7#L519
#define __free_page(page) __free_pages((page), 0)
#define free_page(addr) free_pages((addr), 0)
```

而 free\_pages 是通过**\_\_free\_pages**来完成内存释放的,参见[mm/page_alloc.c?v=4.7#L3918](http://lxr.free-electrons.com/source/mm/page_alloc.c?v=4.7#L3918)

```cpp
void free_pages(unsigned long addr, unsigned int order)
{
    if (addr != 0) {
        VM_BUG_ON(!virt_addr_valid((void *)addr));
        __free_pages(virt_to_page((void *)addr), order);
    }
}
```

`free_pages`和`__free_pages`之间的关系通过函数而不是宏建立, 因为首先必须将**虚拟地址**转换为指向**struct page 的指针**

**virt\_to\_page**将**虚拟内存地址**转换为**指向 page 实例的指针**. 基本上, 这是讲解**内存分配函数**时介绍的**page\_address**辅助函数的**逆过程**.

下图以图形化方式综述了各个内存释放函数之间的关系

![伙伴系统各个内存释放函数之间的关系](./images/__free_pages.png)