
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1 前言](#1-前言)
- [2 用户将一个 work 挂入 workqueue](#2-用户将一个-work-挂入-workqueue)
  - [2.1 queue\_work\_on 函数](#21-queue_work_on-函数)
  - [2.2 \_\_WQ\_DRAINING 的解释](#22-__wq_draining-的解释)
  - [2.3 选择 pool workqueue](#23-选择-pool-workqueue)
  - [2.4 选择 worker thread pool](#24-选择-worker-thread-pool)
  - [2.5 选择 work 挂入的队列](#25-选择-work-挂入的队列)
  - [2.6 唤醒 idle 的 worker 来处理该 work](#26-唤醒-idle-的-worker-来处理该-work)
- [3 线程池如何创建 worker 线程?](#3-线程池如何创建-worker-线程)
  - [3.1 per cpu worker pool 什么时候创建 worker 线程?](#31-per-cpu-worker-pool-什么时候创建-worker-线程)
  - [3.2 unbound thread pool 什么时候创建 worker 线程?](#32-unbound-thread-pool-什么时候创建-worker-线程)
  - [3.3 如何创建 worker](#33-如何创建-worker)
- [4 work 的处理](#4-work-的处理)
  - [4.1 PF\_WQ\_WORKER 标记](#41-pf_wq_worker-标记)
  - [4.2 管理线程池中的线程](#42-管理线程池中的线程)
  - [4.3 worker 线程开始处理 work](#43-worker-线程开始处理-work)

<!-- /code_chunk_output -->

# 1 前言

本文主要讲述下面两部分的内容:

1, 将 work 挂入 workqueue 的处理过程

2, 如何处理挂入 workqueue 的 work

# 2 用户将一个 work 挂入 workqueue

## 2.1 queue\_work\_on 函数

使用 workqueue 机制的模块可以调用 queue\_work\_on(有其他变种的接口, 这里略过, 其实思路是一致的)将一个定义好的 work 挂入 workqueue, 具体代码如下:

```c
bool queue_work_on(int cpu, struct workqueue_struct *wq, struct work_struct *work)
{
    ......

    if (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {
        __queue_work(cpu, wq, work);－－－挂入 work list 并通知 worker thread pool 来处理
        ret = true;
    }

    ......
}
```

work\_struct 的 data member 中的 WORK\_STRUCT\_PENDING\_BIT 这个 bit 标识了该 work 是处于 pending 状态还是正在处理中, pending 状态的 work 只会挂入一次. 大部分的逻辑都是在 \_\_queue\_work 函数中, 下面的小节都是描述该函数的执行过程.

## 2.2 \_\_WQ\_DRAINING 的解释

\_\_queue\_work 函数一开始会校验 \_\_WQ\_DRAINING 这个 flag, 如下:

```c
if (unlikely(wq->flags & __WQ_DRAINING) && WARN_ON_ONCE(!is_chained_work(wq)))
        return;
```

\_\_WQ\_DRAINING 这个 flag 表示该 workqueue 正在进行 draining 的操作, 这多半是发送在销毁 workqueue 的时候, 既然要销毁, 那么挂入该 workqueue 的所有的 work 都要处理完毕, 才允许它消亡. 当想要将一个 workqueue 中所有的 work 都清空的时候, 如果还有 work 挂入怎么办? 一般而言, 这时候当然是不允许新的 work 挂入了, 毕竟现在的目标是清空 workqueue 中的 work. 但是有一种特例 (通过 is\_chained\_work 判定), 也就是正在清空的 work(隶属于该 workqueue) 又触发了一个 queue work 的操作(也就是所谓 chained work), 这时候该 work 允许挂入.

## 2.3 选择 pool workqueue

```c
if (req_cpu == WORK_CPU_UNBOUND)
        cpu = raw_smp_processor_id();

if (!(wq->flags & WQ_UNBOUND))
        pwq = per_cpu_ptr(wq->cpu_pwqs, cpu);
    else
        pwq = unbound_pwq_by_node(wq, cpu_to_node(cpu));
```

WORK\_CPU\_UNBOUND 表示并不指定 cpu, 这时候, 选择当前代码运行的那个 cpu 了. 一旦确定了 cpu 了, 对于非 unbound 的 workqueue, 当然使用 per cpu 的 pool workqueue. 如果是 unbound 的 workqueue, 那么要根据 numa node id 来选择. cpu\_to\_node 可以从 cpu id 获取 node id. 需要注意的是: 这里选择的 pool wq 只是备选的, 可能用也可能不用, 它有可能会被替换掉, 具体参考下一节描述.

## 2.4 选择 worker thread pool

与其说挂入 workqueue, 不如说挂入 worker thread pool, 因为毕竟是线程池来处理具体的 work. pool\_workqueue 有一个相关联的 worker thread pool(struct pool\_workqueue 的 pool 成员), 因此看起来选择了 pool wq 也就选定了 worker pool 了, 但是, 不是当前选定的那个 pool wq 对应的 worker pool 就适合该 work, 因为有时候该 work 可能正在其他的 worker thread 上执行中, 在这种情况下, 为了确保 work 的 callback function 不会重入, 该 work 最好还是挂在那个 worker thread pool 上, 具体代码如下:

```c
last_pool = get_work_pool(work);
    if (last_pool && last_pool != pwq->pool) {
        struct worker *worker;

        spin_lock(&last_pool->lock);

        worker = find_worker_executing_work(last_pool, work);

        if (worker && worker->current_pwq->wq == wq) {
            pwq = worker->current_pwq;
        } else {
            /* meh... not running there, queue here */
            spin_unlock(&last_pool->lock);
            spin_lock(&pwq->pool->lock);
        }
    } else {
        spin_lock(&pwq->pool->lock);
    }
```

last\_pool 记录了上一次该 work 是被哪一个 worker pool 处理的, 如果 last\_pool 就是 pool wq 对应的 worker pool, 那么皆大欢喜, 否则只能使用 last pool 了. 使用 last pool 的例子比较复杂一些, 因为这时候需要根据 last worker pool 找到对应的 pool workqueue. find\_worker\_executing\_work 函数可以找到具体哪一个 worker 线程正在处理该 work, 如果没有找到, 那么还是使用第 3 节中选定的 pool wq 吧, 否则, 选择该 worker 线程当前的那个 pool workqueue(其实也就是选定了线程池).

## 2.5 选择 work 挂入的队列

队列有两个, 一个是被推迟执行的队列(pwq->delayed_works), 一个是线程池要处理的队列(pwq->pool->worklist), 如果挂入线程池要处理的队列, 也就意味着该 work 进入 active 状态, 线程池会立刻启动处理流程, 如果挂入推迟执行的队列, 那么该 work 还是 pending 状态:

```c
    pwq->nr_in_flight[pwq->work_color]++;
    work_flags = work_color_to_flags(pwq->work_color);

    if (likely(pwq->nr_active < pwq->max_active)) {
        pwq->nr_active++;
        worklist = &pwq->pool->worklist;
    } else {
        work_flags |= WORK_STRUCT_DELAYED;
        worklist = &pwq->delayed_works;
    }

    insert_work(pwq, work, worklist, work_flags);
```

具体的挂入队列的动作是在 insert_work 函数中完成的.

## 2.6 唤醒 idle 的 worker 来处理该 work

在 insert\_work 函数中有下面的代码:

```c
if (__need_more_worker(pool))
        wake_up_worker(pool);
```

当线程池中正在运行状态的 worker 线程数目等于 0 的时候, 说明需要 wakeup 线程池中处于 idle 状态的的 worker 线程来处理 work.

# 3 线程池如何创建 worker 线程?

## 3.1 per cpu worker pool 什么时候创建 worker 线程?

对于 per\-CPU workqueue, 每个 cpu 有两个线程池, 一个是 normal, 一个是 high priority 的. 在初始化函数 init\_workqueues 中有对这两个线程池的初始化:

```c
for_each_online_cpu(cpu) {
    struct worker_pool *pool;

    for_each_cpu_worker_pool(pool, cpu) {
        pool->flags &= ~POOL_DISASSOCIATED;
        BUG_ON(!create_worker(pool));
    }
}
```

因此, 在系统初始化的时候, per cpu workqueue 共享的那些线程池 (2 x cpu nr) 就会通过 create_worker 创建一个 initial worker.

一旦 initial worker 启动, 该线程会执行 worker_thread 函数来处理 work, 在处理过程中, 如果有需要,  worker 会创建新的线程.

## 3.2 unbound thread pool 什么时候创建 worker 线程?

我们先看看 unbound thread pool 的建立, 和 per-CPU 不同的是 unbound thread pool 是全局共享的, 因此, 每当创建不同属性的 unbound workqueue 的时候, 都需要创建 pool\_workqueue 及其对应的 worker pool, 这时候就会调用 get\_unbound\_pool 函数在当前系统中现存的线程池中找是否有匹配的 worker pool, 如果没有就需要创建新的线程池. 在创建新的线程池之后, 会立刻调用 create\_worker 创建一个 initial worker. 和 per cpu worker pool 一样, 一旦 initial worker 启动, 随着 work 不断的挂入以及 worker 处理 work 的具体情况, 线程池会动态创建 worker.

## 3.3 如何创建 worker

代码如下:

```c
static struct worker *create_worker(struct worker_pool *pool)
{
    struct worker *worker = NULL;
    int id = -1;
    char id_buf[16];

    id = ida_simple_get(&pool->worker_ida, 0, 0, GFP_KERNEL);－－－－分配 ID

    worker = alloc_worker(pool->node);－－－－－分配 worker struct 的内存

    worker->pool = pool;
    worker->id = id;

    if (pool->cpu >= 0)－－－－－－－－－worker 的名字
        snprintf(id_buf, sizeof(id_buf), "%d:%d%s", pool->cpu, id,  pool->attrs->nice < 0  ? "H" : "");
    else
        snprintf(id_buf, sizeof(id_buf), "u%d:%d", pool->id, id);

worker->task = kthread_create_on_node(worker_thread, worker, pool->node,   "kworker/%s", id_buf);

    set_user_nice(worker->task, pool->attrs->nice); －－－创建 task 并设定 nice value
    worker->task->flags |= PF_NO_SETAFFINITY;
    worker_attach_to_pool(worker, pool); －－－－－建立 worker 和线程池的关系

    spin_lock_irq(&pool->lock);
    worker->pool->nr_workers++;
    worker_enter_idle(worker);
    wake_up_process(worker->task);－－－－－－让 worker 运行起来
    spin_unlock_irq(&pool->lock);

    return worker;
}
```

代码不复杂, 通过线程池 (struct worker\_pool) 绑定的 cpu 信息 (struct worker\_pool 的 cpu 成员) 可以知道该 pool 是 per-CPU 还是 unbound, 对于 per\-CPU 线程池, pool\->cpu 是大于等于 0 的. 对于对于 per-CPU 线程池, 其 worker 线程的名字是 kworker/cpu: worker id, 如果是 high priority 的, 后面还跟着一个 H 字符. 对于 unbound 线程池, 其 worker 线程的名字是 kworker/u pool id: worker id.

# 4 work 的处理

本章主要描述 worker\_thread 函数的执行流程, 部分代码有删节, 保留主干部分.

## 4.1 PF\_WQ\_WORKER 标记

worker 线程函数一开始就会通过 PF\_WQ\_WORKER 来标注自己:

```c
worker->task->flags |= PF_WQ_WORKER;
```

有了这样一个 flag, 调度器在调度当前进程 sleep 的时候可以检查这个准备 sleep 的进程是否是一个 worker 线程, 如果是的话, 那么调度器不能鲁莽的调度到其他的进程, 这时候, 还需要找到该 worker 对应的线程池, 唤醒一个 idle 的 worker 线程. 通过 workqueue 模块和调度器模块的交互, 当 work A 被阻塞后(处理该 work 的 worker 线程进入 sleep), 调度器会唤醒其他的 worker 线程来处理其他的 work B, work C......

## 4.2 管理线程池中的线程

```c
recheck:
    if (!need_more_worker(pool))
        goto sleep;

    if (unlikely(!may_start_working(pool)) && manage_workers(worker))
        goto recheck;
```

如何判断是否需要创建更多的 worker 线程呢? 原则如下:

(1) 有事情做: 挂在 worker pool 中的 work list 不能是空的, 如果是空的, 那么当然 sleep 就好了

(2) 比较忙: worker pool 的 nr\_running 成员表示线程池中当前正在干活 (running 状态) 的 worker 线程有多少个, 当 nr\_running 等于 0 表示所有的 worker 线程在处理 work 的时候阻塞了, 这时候, 必须要启动新的 worker 线程来处理 worker pool 上处于 active 状态的 work 链表上的 work 们.

## 4.3 worker 线程开始处理 work

```c
worker_clr_flags(worker, WORKER_PREP | WORKER_REBOUND);

do {
    struct work_struct *work =   list_first_entry(&pool->worklist,  struct work_struct, entry);

    if (likely(!(*work_data_bits(work) & WORK_STRUCT_LINKED))) {
        process_one_work(worker, work);
        if (unlikely(!list_empty(&worker->scheduled)))
            process_scheduled_works(worker);
    } else {
        move_linked_works(work, &worker->scheduled, NULL);
        process_scheduled_works(worker);
    }
} while (keep_working(pool));

worker_set_flags(worker, WORKER_PREP);
```

按理说 worker 线程处理 work 应该比较简单, 从线程池的 worklist 中取一个 work, 然后调用 process\_one\_work 处理之就 OK 了, 不过现实稍微复杂一些, work 和 work 之间并不是独立的, 也就是说, work A 和 work B 可能是 linked work, 这些 linked work 应该被一个 worker 来处理. WORK\_STRUCT\_LINKED 标记了 work 是属于 linked work, 如果是 linked work, worker 并不直接处理, 而是将其挂入 scheduled work list, 然后调用 process\_scheduled\_works 来处理. 毫无疑问, process\_scheduled\_works 也是调用 process\_one_work 来处理一个一个 scheduled work list 上的 work.

scheduled work list 并非仅仅应用在 linked work, 在 worker 处理 work 的时候, 有一个原则要保证: 同一个 work 不能被同一个 cpu 上的多个 worker 同时执行. 这时候, 如果 worker 发现自己要处理的 work 正在被另外一个 worker 线程处理, 那么本 worker 线程将不处理该 work, 只需要挂入正在执行该 work 的 worker 线程的 scheduled work list 即可.