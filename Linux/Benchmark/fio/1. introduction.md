
FIO 是测试 IOPS 的非常好的工具, 用来对硬件进行压力测试和验证, 支持 13 种不同的 I/O 引擎, 包括: sync, mmap, libaio, posixaio, SG v3, splice, null, network, syslet, guasi, solarisaio 等等.

# 源码

URL: https://git.kernel.dk/cgit/fio/

git://git.kernel.dk/fio.git

https://git.kernel.dk/fio.git

# 编译安装

```
$ ./configure
$ make
$ make install
```

注意, GNU make 是必需的. 在 BSD 上, 它可以从 ports 目录中的 devel/gmake 获得; 在 Solaris 上, 它位于 SUNWgmake 包中. 在默认不是 GNU make 的平台上, 键入 `gmake` 而不是 `make`.

Configure 将打印已启用的选项. 注意, 在基于 Linux 的平台上, 必须安装 libaio 开发包才能使用 libaio 引擎. 根据发行版的不同, 它通常被称为 libaio-devel 或 libaio-dev.

对于 gfio, 需要安装 gtk 2.18(或更高版本)、关联的 glib 线程和 cairo. GFIO 不是自动构建的, 可以使用 "--enable-GFIO" 选项进行 configure.

交叉编译:

```
$ make clean
$ make CROSS_COMPILE=/path/to/toolchain/prefix
```

配置将尝试自动确定目标平台.

也可以为 ESX 构建 fio, 使用 `--esx` 开关进行配置.

# 文档

Fio 使用 Sphinx_ 从 reStructuredText_ 文件生成文档.  要构建 HTML 格式的文档, 请运行 "`make -C doc html`" 并将浏览器定向到: file: `./doc/output/html/index.html`.  要构建手册页, 请运行 "`make -C doc man`", 然后运行 "`man doc/output/man/fio.1`".  要查看支持哪些其他输出格式, 请运行 "`make -C doc help`".

```
.._reStructuredText: https://www.sphinx-doc.org/rest.html
.._Sphinx: https://www.sphinx-doc.org
```

# 平台

Fio(至少)在 Linux, Solaris, AIX, HP-UX, OSX, NetBSD, OpenBSD, Windows, FreeBSD 和 DragonFly 上工作. 某些功能和/或选项可能仅在某些平台上可用, 通常是因为这些功能仅适用于该平台(如 solarisaio 引擎或 Linux 上的 splice 引擎).

Fio 使用 pthread mutexes(互斥锁)进行 signaling 和 locking, 某些平台不支持 process 进程共享 pthread mutexes. 因此, 在这种平台上仅支持 threads. 这可以通过 sysv ipc locking 或其他 locking 替代方案来解决.

# 命令选项

```
$ fio [options] [jobfile] ...
```

有 2 种执行方式: 命令行执行和配置文件执行.

```
# cat write.fio
[global]
direct=1
iodepth=16
numjobs=4
rw=write
ioengine=libaio
bs=4K
size=20G
runtime=600
group_reporting
name=file

[job1]
filename=/perf/test1
```

它会按照 jobfile 内容运行. 可以有多个 jobfile, fio 将**串行化运行**.

命令行参数与作业参数相同, 只是有一些额外的参数用于控制全局参数. 例如, 对于作业文档参数: `iodepth=2`, 镜像命令行选项为: `--iodepth 2` 或 `--iodepth=2`.

可以使用**命令行**提供**多个作业条目**. 对于每个 `--name <name>` 选项, fio 将使用该名称启动一个新作业. `--name <name>` **后面的命令行**条目将**应用于该作业**, 直到**没有更多命令行条目**或看到**新的** `--name <name>` 条目. 这类似于文件选项, 其中每个选项都适用于当前作业, 直到看到新的 `[]` job 条目.


```
fio -filename=/dev/nvme0n1 -direct=1 -iodepth  32 -iodepth_batch 1 -iodepth_batch_complete 16 -rw=randread -ioengine=libaio -bs=16k -size=400G -numjobs=1 -runtime=600 -group_reporting -time_based -ramp_time=60 -name=nvme0
```

## filename

filename: 这里可以是一个文件名, 也可以是分区或者块设备, 这里是 ssd 块设备

## direct

Linux 读写的时候, 内核维护了缓存, 数据先写到缓存, 然后再后台写到 SSD. 读的时候也优先读缓存里的数据. 这样速度可以加快. 所以有一种模式叫作 DirectIO, 跳过缓存, 直接读写 SSD, 测试结果会更真实

打开文件时带不带 `O_DIRECT` 标记

```
# strace -f ./fio --name=seqwrite     \
                  --rw=write          \
                  --bs=4k             \
                  --size=2048G        \
                  --runtime=30        \
                  --ioengine=libaio   \
                  --direct=1          \
                  --iodepth=1         \
                  --numjobs=1         \
                  --filename=/dev/sdd \
                  --group_reporting > strace.log  2>&1

# cat strace.log
...
[pid 31496] open("/dev/sdd", O_RDWR|O_DIRECT|O_NOATIME) = 3
[pid 31496] ioctl(3, BLKFLSBUF, 0x750080) = 0
[pid 31496] fadvise64(3, 0, 2199023255552, POSIX_FADV_SEQUENTIAL) = 0
[pid 31496] io_submit(140395703390208, 1, {{pwrite, filedes:3, str:"5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., nbytes:4096, offset:0}}) = 1
[pid 31496] io_getevents(140395703390208, 1, 1, {{(nil), 0x7d37e8, 4096, 0}}, NULL) = 1
[pid 31496] io_submit(140395703390208, 1, {{pwrite, filedes:3, str:"\0\20\0\0\0\0\0\0\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., nbytes:4096, offset:4096}}) = 1
[pid 31496] io_getevents(140395703390208, 1, 1, {{(nil), 0x7d37e8, 4096, 0}}, NULL) = 1
```

值得注意的是, ioengine=libaio 时, 一定要 direct=1 . 因为目前, libaio 只支持 direct I/O: libaio 只在 O_DIRECT 的情况下是异步的, 在没有 O_DIRECT 的情况下可能会 blocking;

## sync

和 direct 选项类似, 它决定的是: 打开文件时带不带 `O_SYNC` 标记;

```
# strace -f ./fio --name=seqwrite      \
                  --rw=write           \
                  --bs=4k              \
                  --size=2048G         \
                  --runtime=30         \
                  --ioengine=sync      \
                  --sync=1             \
                  --iodepth=1          \
                  --numjobs=1          \
                  --filename=/dev/sdd  \
                  --group_reporting > strace.log 2>&1

# cat strace.log
...
[pid 31618] open("/dev/sdd", O_RDWR|O_SYNC|O_NOATIME) = 3
[pid 31618] ioctl(3, BLKFLSBUF, 0x747020) = 0
[pid 31618] fadvise64(3, 0, 2199023255552, POSIX_FADV_SEQUENTIAL) = 0
[pid 31618] write(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096 <unfinished ...>
[pid 31582] <... nanosleep resumed> NULL) = 0
[pid 31582] wait4(31618, 0x7ffcf5649400, WNOHANG, NULL) = 0
[pid 31582] stat("/tmp/fio-dump-status", 0x7ffcf56483c0) = -1 ENOENT (No such file or directory)
[pid 31582] nanosleep({0, 10000000},  <unfinished ...>
[pid 31618] <... write resumed> )       = 4096
[pid 31618] write(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096) = 4096
[pid 31618] write(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096) = 4096
[pid 31618] write(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096) = 4096
```

## fsync 和 fdatasync 选项

如上所说, ioengine=sync 或 psync, 有点误导, 因为它不会调用 fsync 或 fdatasync 操作. 要想在 write 后调用 fsync 或者 fdatasync, 需要加水–fsync=N 或者–fdatasync=N. 这里的 N 表示每 N 个 write 之后调用 fsync 或者 fdatasync 一次.

```
# strace -f ./fio --name=seqwrite     \
                  --rw=write          \
                  --bs=4k             \
                  --size=2048G        \
                  --runtime=30        \
                  --ioengine=psync    \
                  --fdatasync=3       \
                  --iodepth=1         \
                  --numjobs=1         \
                  --filename=/dev/sdd \
                  --group_reporting > strace.log  2>&1

# cat strace.log
...
[pid 31670] open("/dev/sdd", O_RDWR|O_NOATIME) = 3
[pid 31670] ioctl(3, BLKFLSBUF, 0x746f40) = 0
[pid 31670] fadvise64(3, 0, 2199023255552, POSIX_FADV_SEQUENTIAL) = 0
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 0) = 4096
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 4096) = 4096
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 8192) = 4096
[pid 31670] fdatasync(3 <unfinished ...>
[pid 31636] <... nanosleep resumed> NULL) = 0
[pid 31636] wait4(31670, 0x7ffe86a9c280, WNOHANG, NULL) = 0
[pid 31636] stat("/tmp/fio-dump-status", 0x7ffe86a9b240) = -1 ENOENT (No such file or directory)
[pid 31636] nanosleep({0, 10000000},  <unfinished ...>
[pid 31670] <... fdatasync resumed> )   = 0
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 12288) = 4096
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 16384) = 4096
[pid 31670] pwrite(3, "5\340(\3148\240\231\26\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., 4096, 20480) = 4096
[pid 31670] fdatasync(3 <unfinished ...>
[pid 31636] <... nanosleep resumed> NULL) = 0
[pid 31636] wait4(31670, 0x7ffe86a9c280, WNOHANG, NULL) = 0
[pid 31636] stat("/tmp/fio-dump-status", 0x7ffe86a9b240) = -1 ENOENT (No such file or directory)
[pid 31636] nanosleep({0, 10000000},  <unfinished ...>
[pid 31670] <... fdatasync resumed> )   = 0
```

关于 fsync/fdatasync 需要注意: fsync/fdatasync 的耗时不包含在 write latency 之内. 新版本的 fio(例如 fio-3.13 和 fio-3.14)单独显示 fsync/fdatasync 的耗时, 而老版本不显示 fsync/fdatasync 的耗时(这有点使人迷惑: write latency 很小——因为不包含 fsync/fdatasync 耗时——但 IOPS 又不高, 你会疑惑时间花在哪里了).

## iodepth

> 一次提交要提交多少个 1/O 请求, 仅对异步 1/0 引擎有用, 因为同步 I/O 总是会等待提交的 I/O 请求返回了再提交下一个 I/O 请求(即串行), 所以 iodepth 总是 1.
>
> 对于 I/O depth,并不是越大越好, 需要选择一个合适的值, 其原因如下:
>
> 随着 iodepth 的增大在一定范围内, 带宽、io 延时会增加, 超过一定范围后带宽增加缓慢, 延时继续会增加. 延时增加的原因是因为随着 iodepth 增加都需花更多的时间等待请求 io 数量达到 iodepth 数值后, 才会真正把 io 请求发送给存储, 所以平均每一个 io 的延时都会增大了
>
> 带宽之所以会提高可能主要与网络延时有关, 如果每次只发一个 io 请求, 那么完成这一次 io 请求的时间＝收发延时＋io 请求执行时间, 如果没有延时则每秒客户端可以完成 1000 次请求, 但是加上收发延时后, 每秒的请求次数必然减少. 但是如果将每次 io 请求数量增加, 比如一次发 10 个请求, 那么这 10 次请求时间花费＝等待 10 个 io 请求＋1 次收发延时＋10 次 io 请求执行时间, 而 10 次单个的 io 请求时间＝10 次收发延时＋10 次 io 请求执行时间. 如果等待 10 个 io 请求时间低于 9 次收发延时, 那么每秒能够完成的 io 请求时间就会增加, 也就会增加带宽

队列深度, 应用层面的. 简单来说, 就是一个 job 实例在一个文件上的 inflight 的 I/O 的数.

考虑:

* `–ioengine=libaio`: 一次性丢给系统处理的 io 请求数量. libaio 引擎会用这个 iodepth 值来调用 `io_setup` 准备个可以**一次提交** iodepth 个 **IO 的上下文**, 同时申请一个 io 请求队列用于保持 IO; 再把 I/O 请求通过 `io_submit` 发出去; 然后通过 `io_getevents` 获取结果. 这样**一个 job 实例**就可以保持有**多个 inflight I/O**.

* `–ioengine=sync` 或者 `psync`: 一个 job 实例只能顺序地调用 `read/write(pread/pwrite)`, 也就是**只能**保持**一个 I/O inflight**, 所以对于 `–ioengine=sync` 或者 `–ioengine=psync` 设置 iodepth 为大于 1 的值**不起作用**.

对比一下:

### libaio

```
终端 A:
# ./fio --name=seqwrite     \
        --rw=write          \
        --bs=4k             \
        --size=2048G        \
        --runtime=30        \
        --ioengine=libaio   \
        --direct=1          \
        --iodepth=2         \
        --numjobs=3         \
        --filename=/dev/sdd \
        --group_reporting

seqwrite: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=2
...
fio-3.14
Starting 3 processes
Jobs: 3 (f=3): [W(3)][100.0%][w=26.5MiB/s][w=6784 IOPS][eta 00m:00s]
seqwrite: (groupid=0, jobs=3): err= 0: pid=31333: Thu Jun 20 20:10:28 2019
  write: IOPS=7158, BW=27.0MiB/s (29.3MB/s)(839MiB/30001msec)
    slat (nsec): min=2934, max=37646, avg=6739.80, stdev=2421.02
    clat (usec): min=125, max=148817, avg=830.45, stdev=1904.14
     lat (usec): min=130, max=148823, avg=837.30, stdev=1904.16
    clat percentiles (usec):
     |  1.00th=[  141],  5.00th=[  347], 10.00th=[  627], 20.00th=[  635],
     | 30.00th=[  635], 40.00th=[  644], 50.00th=[  660], 60.00th=[  791],
     | 70.00th=[  799], 80.00th=[  865], 90.00th=[  996], 95.00th=[ 1369],
     | 99.00th=[ 1516], 99.50th=[ 2573], 99.90th=[12256], 99.95th=[34341],
     | 99.99th=[96994]
   bw (  KiB/s): min=14528, max=49712, per=100.00%, avg=28649.71, stdev=2786.85, samples=179
   iops        : min= 3632, max=12428, avg=7162.42, stdev=696.71, samples=179
  lat (usec)   : 250=4.55%, 500=0.51%, 750=51.07%, 1000=34.20%
  lat (msec)   : 2=8.99%, 4=0.21%, 10=0.05%, 20=0.34%, 50=0.03%
  lat (msec)   : 100=0.03%, 250=0.01%
  cpu          : usr=0.70%, sys=2.53%, ctx=185415, majf=0, minf=98
  IO depths    : 1=0.1%, 2=100.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=0,214751,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=2

Run status group 0 (all jobs):
  WRITE: bw=27.0MiB/s (29.3MB/s), 27.0MiB/s-27.0MiB/s (29.3MB/s-29.3MB/s), io=839MiB (880MB), run=30001-30001msec

Disk stats (read/write):
  sdd: ios=122/213903, merge=0/0, ticks=24/176947, in_queue=176925, util=99.77%


终端 B:
# iostat -mxd 1 /dev/sdd
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.09    0.00    0.22    0.00    0.00   99.69

Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sdd               0.00     0.00    0.00 8540.00     0.00    33.36     8.00     5.91    0.69    0.00    0.69   0.12 100.00

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.06    0.00    0.22    0.03    0.00   99.69

Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sdd               0.00     0.00    0.00 8434.00     0.00    32.95     8.00     5.90    0.70    0.00    0.70   0.12 100.00
```

`IO depths: 1=0.1%, 2=100.0%` 表明 iodepth 为 2. iostat 显示 avgqu-sz 接近 6. 我们有 3 个 job 实例, 故每个 job 实例的 iodepth 接近 2;

### sync

```
终端 A:
# ./fio --name=seqwrite     \
        --rw=write          \
        --bs=4k             \
        --size=2048G        \
        --runtime=30        \
        --ioengine=sync     \
        --direct=1          \
        --iodepth=2         \
        --numjobs=3         \
        --filename=/dev/sdd \
        --group_reporting

seqwrite: (g=0): rw=write, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=sync, iodepth=2
...
fio-3.14
Starting 3 processes
Jobs: 3 (f=3): [W(3)][100.0%][w=33.0MiB/s][w=8457 IOPS][eta 00m:00s]
seqwrite: (groupid=0, jobs=3): err= 0: pid=31445: Thu Jun 20 20:14:31 2019
  write: IOPS=5405, BW=21.1MiB/s (22.1MB/s)(634MiB/30001msec)
    clat (usec): min=107, max=97490, avg=553.96, stdev=1255.04
     lat (usec): min=107, max=97490, avg=554.08, stdev=1255.04
    clat percentiles (usec):
     |  1.00th=[  269],  5.00th=[  310], 10.00th=[  314], 20.00th=[  314],
     | 30.00th=[  318], 40.00th=[  469], 50.00th=[  490], 60.00th=[  578],
     | 70.00th=[  668], 80.00th=[  693], 90.00th=[  734], 95.00th=[  750],
     | 99.00th=[  766], 99.50th=[  783], 99.90th=[14615], 99.95th=[26870],
     | 99.99th=[62653]
   bw (  KiB/s): min=12400, max=34776, per=99.06%, avg=21419.20, stdev=2159.32, samples=177
   iops        : min= 3100, max= 8694, avg=5354.80, stdev=539.83, samples=177
  lat (usec)   : 250=0.64%, 500=53.22%, 750=41.44%, 1000=4.47%
  lat (msec)   : 2=0.02%, 4=0.01%, 10=0.02%, 20=0.12%, 50=0.04%
  lat (msec)   : 100=0.02%
  cpu          : usr=0.42%, sys=1.85%, ctx=162178, majf=0, minf=102
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=0,162177,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=2

Run status group 0 (all jobs):
  WRITE: bw=21.1MiB/s (22.1MB/s), 21.1MiB/s-21.1MiB/s (22.1MB/s-22.1MB/s), io=634MiB (664MB), run=30001-30001msec

Disk stats (read/write):
  sdd: ios=120/161214, merge=0/0, ticks=28/87940, in_queue=87943, util=99.78%


终端 B:
# iostat -mxd 1 /dev/sdd
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.03    0.00    0.16    8.20    0.00   91.61

Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sdd               0.00     0.00    0.00 4209.00     0.00    16.44     8.00     2.94    0.70    0.00    0.70   0.24 100.00

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.03    0.00    0.09    9.08    0.00   90.80

Device:         rrqm/s   wrqm/s     r/s     w/s    rMB/s    wMB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sdd               0.00     0.00    0.00 4155.00     0.00    16.23     8.00     2.96    0.71    0.00    0.71   0.24 100.10
```

`IO depths: 1=100.0%, 2=0.0%` 表明 iodepth 为 1; iostat 显示 avgqu-sz 接近 3. 我们有 3 个 job 实例, 故每个 job 实例的 iodepth 接近 1;

## iodepth_batch

io 队列请求丢过来后, 攒积到这些请求后, 立即提交, 默认是 iodepth 的值;

## iodepth_batch_complete

io 请求过来后, 能 retrieve 获得的最多请求数;

## ipdepth_low

io 请求达到这个水平线后, 开始尝试去补充和获取请求, 默认是 iodepth 的值;

```
-iodepth 32 -iodepth_batch 1 -iodepth_batch_complete 16
```

一次模拟生成 32 个 io 请求, 一次处理能接受 16 个请求, 异步模式下, 1 个请求来了直接提交;

libaio 引擎会用 iodepth 值来调用 `io_setup` 准备个可以一次提交 iodepth 个 IO 的上下文, 同时申请个 io 请求队列用于保持 IO.  在压测进行的时候, 系统会生成特定的 IO 请求, 往 io 请求队列里面扔, 当队列里面的 IO 个数达到 `iodepth_batch` 值的时候, 就调用 `io_submit` 批次提交请求, 然后开始调用 `io_getevents` 开始收割已经完成的 IO. 每次收割多少呢? 由于收割的时候, 超时时间设置为 0, 所以有多少已完成就算多少, 最多可以收割 `iodepth_batch_complete` 值个. 随着收割, IO 队列里面的 IO 数就少了, 那么需要补充新的 IO.  什么时候补充呢? 当 IO 数目降到 `iodepth_low` 值的时候, 就重新填充, 保证 OS 可以看到至少 `iodepth_low` 数目的 io 在电梯口排队着.

## rw

设置读写模式

* write: 顺序写;
* read: 顺序读;
* randwrite: 随机写;
* randread: 随机读;
* rw: 顺序混合读写;
* randrw: 随机混合读写;

混合读写可以指定 rwmixread 或者 rwmixwrite 来指定比例, 默认 50

## ioengine

### libaio

异步模式, 即 linux native asynchronous I/O, 也就是使用 `io_submit` 提交 I/O 请求, 然后再异步地使用 `io_getevents` 获取结果. 可以通过 strace 来看**实际的系统调用**.

```
终端 A:
# ./fio --name=seqwrite       \
        --rw=write            \
        --bs=4k               \
        --size=2048G          \
        --runtime=30          \
        --ioengine=libaio     \
        --direct=1            \
        --iodepth=1           \
        --numjobs=1           \
        --filename=/dev/sdd

终端 B:
# ps -ef|grep fio
root      31136 141809 26 20:00 pts/1    00:00:00 ./fio --name=seqwrite --rw=write --bs=4k --size=2048G --runtime=30 --ioengine=libaio --direct=1 --iodepth=1 --numjobs=1 --filename=/dev/sdd
root      31170  31136 19 20:00 ?        00:00:00 ./fio --name=seqwrite --rw=write --bs=4k --size=2048G --runtime=30 --ioengine=libaio --direct=1 --iodepth=1 --numjobs=1 --filename=/dev/sdd

# strace -p 31170
Process 31170 attached
......
io_submit(140009640251392, 1, {{pwrite, filedes:3, str:"\0\200|:\0\0\0\0\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., nbytes:4096, offset:981250048}}) = 1
io_getevents(140009640251392, 1, 1, {{(nil), 0x1cb57e8, 4096, 0}}, NULL) = 1
io_submit(140009640251392, 1, {{pwrite, filedes:3, str:"\0\200|:\0\0\0\0\6\234j\251\362\315\351\n\200S*\7\t\345\r\25pJ%\367\v9\235\30"..., nbytes:4096, offset:981254144}}) = 1
io_getevents(140009640251392, 1, 1, {{(nil), 0x1cb57e8, 4096, 0}}, NULL) = 1
......
```

> 为了提高并行性, 大部分情况下 SSD 读写采用的是异步模式. 就是用几微秒发送命令, 发完后继续发后面的命令. 如果前面的命令执行完了, SSD 通知会通过中断或者轮询等方式告诉 CPU, 由 CPU 来调用该命令的回调函数来处理结果. SSD 里面几十上百个并行单元都能分到活干, 效率暴增. libaio 指的是异步模式, 如果是同步就要用 sync.

### sync

它虽然叫做 sync, 但并不意味着**文件**以 `O_SYNC` 的方式打开, 也不意味着每个 write 之后会调用 `fsync/fdatasync` 操作. 实际上, 这个 sync 和 libaio 是相对的概念, 不是先提交 I/O 请求(`io_submit`)再异步获取结果(`io_getevents`), 而是使用 read/write 这样的系统调用来完成 I/O. 到底 write 之后会不会调用 fsync, 要看 `–fsync` 或者 `–fdatasync` 的设置;

### psync

和 sync 类似, 不同之处在于使用 pread 和 pwrite 来进行 I/O.

## size

每个线程/进程操作的数据量.

它的值有两种形式:

* 绝对大小, 例如 10M,20G;

* 百分比, 例如 20%; 需要文件事先存在;

无论哪种形式都是指定一个 job 实例读写的空间(多个 job 实例的情况下每个 job 实例都读写这么大的空间); fio 运行时间取决于 `–runtime` 指定的时间和读写这么多空间所需时间二者中的**最小者**.

## bs

每一个 BIO 命令包含的数据大小是 4KB

## numjobs

同时并行运行的工作 jobs 数, 相当于一个 job 克隆, 具有相同 workload(负载)

每个 job 是 1 个进程/线程, 后面每个用 `-name` 指定的任务就开几个线程测试. 所以最终 `真正 job 数 = 任务数 × numjobs`.

## runtime

如果**不设置** `time_based`, runtime 设置的就算很大, 那么 io 大小到 size 后就会立即停止, 而不是到 runtime 设置的时间;

## time_based

如果设置这个值, 即使 io 大小到达 size 后还未结束的情况, 仍然会继续模拟相同的负载, 直至这个时间 runtime 结束;

## ramp_time

ramp 本意是坡度, 相当于预热, 意思是跑每个 job 之前会跑多久的预热, 预热时间不算进 runtime;

## group_reporting

当设置这个值的时候, 会把所有的 jobs 一起统计汇总平均值等信息, 否则会按照每个 jobs 分别统计;

## thread

fio 默认会使用 fork() 创建 job, 如果这个选项设置的话, fio 将使用 pthread_create 来创建线程;

> 进程的开销比线程要大, 一般都采用 thread 测试

## cpu_allowed

cpu_allowed: 允许执行的 cpu

## name

一个 name 代表一个 task

## 有关 sync 的选项

从前几节可以看到, 和 sync 相关的选项有:

* –direct,
* –sync,
* –fsync(fdatasync);

而常用的 ioengine 有两种:

* libaio
* sync(psync)

如何组合使用呢?

* ioengine=libaio: –direct=1 是必须的(见 3.6 节), 所以, –fsync(fdatasync) 就不需要了; 而 –sync 可以和 –direct 组合使用, 但一般测试裸盘性能直接用 –direct 就可以了.

* ioengine=sync(psync): 可以选择 –direct 或者 –fsync(fdatasync), 选择 –direct 时可以和 –sync 组合使用.

所以共有下面几种组合:

* –ioengine=libaio –direct=1

* –ioengine=sync(psync) –direct=1

* –ioengine=sync(psync) –direct=1 –sync=1

* –ioengine=sync(psync) –fsync=1

# 输出

> fio -filename=/dev/nvme0n1 -direct=1 -iodepth=32 -rw=read -ioengine=libaio -size=2G -bs=4k -numjobs=4 -cpus_allowed=0-3 -cpus_allowed_policy=split -runtime=300 -name=read

```
read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=32
...
fio-3.33
Starting 4 processes
Jobs: 4 (f=4): [R(4)][100.0%][r=1735MiB/s][r=444k IOPS][eta 00m:00s]
read: (groupid=0, jobs=1): err= 0: pid=621076: Tue Mar  7 23:17:45 2023
  read: IOPS=105k, BW=411MiB/s (431MB/s)(2048MiB/4982msec)
    slat (nsec): min=724, max=53917, avg=1249.32, stdev=614.43
    clat (usec): min=110, max=8555, avg=302.48, stdev=123.77
     lat (usec): min=114, max=8565, avg=303.73, stdev=123.83
    clat percentiles (usec):
     |  1.00th=[  262],  5.00th=[  269], 10.00th=[  273], 20.00th=[  277],
     | 30.00th=[  281], 40.00th=[  285], 50.00th=[  285], 60.00th=[  289],
     | 70.00th=[  297], 80.00th=[  306], 90.00th=[  314], 95.00th=[  326],
     | 99.00th=[  717], 99.50th=[  783], 99.90th=[ 1713], 99.95th=[ 1713],
     | 99.99th=[ 2008]
   bw (  KiB/s): min=253840, max=455968, per=24.93%, avg=419759.11, stdev=63047.49, samples=9
   iops        : min=63460, max=113992, avg=104939.78, stdev=15761.87, samples=9
  lat (usec)   : 250=0.11%, 500=98.06%, 750=1.30%, 1000=0.04%
  lat (msec)   : 2=0.48%, 4=0.01%, 10=0.01%
  cpu          : usr=7.67%, sys=18.29%, ctx=247079, majf=0, minf=41
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
read: (groupid=0, jobs=1): err= 0: pid=621077: Tue Mar  7 23:17:45 2023
  read: IOPS=105k, BW=411MiB/s (431MB/s)(2048MiB/4982msec)
    slat (nsec): min=723, max=42775, avg=1247.82, stdev=623.20
    clat (usec): min=163, max=8520, avg=302.47, stdev=126.90
     lat (usec): min=164, max=8530, avg=303.72, stdev=126.95
    clat percentiles (usec):
     |  1.00th=[  260],  5.00th=[  269], 10.00th=[  273], 20.00th=[  277],
     | 30.00th=[  281], 40.00th=[  285], 50.00th=[  289], 60.00th=[  289],
     | 70.00th=[  297], 80.00th=[  302], 90.00th=[  314], 95.00th=[  326],
     | 99.00th=[  709], 99.50th=[  783], 99.90th=[ 1795], 99.95th=[ 1795],
     | 99.99th=[ 2040]
   bw (  KiB/s): min=253824, max=455968, per=24.93%, avg=419780.44, stdev=63063.67, samples=9
   iops        : min=63456, max=113992, avg=104945.11, stdev=15765.92, samples=9
  lat (usec)   : 250=0.24%, 500=97.93%, 750=1.30%, 1000=0.05%
  lat (msec)   : 2=0.47%, 4=0.01%, 10=0.01%
  cpu          : usr=7.79%, sys=17.45%, ctx=222940, majf=0, minf=43
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
read: (groupid=0, jobs=1): err= 0: pid=621078: Tue Mar  7 23:17:45 2023
  read: IOPS=105k, BW=411MiB/s (431MB/s)(2048MiB/4982msec)
    slat (nsec): min=719, max=45590, avg=1198.27, stdev=620.81
    clat (usec): min=147, max=8610, avg=302.56, stdev=123.84
     lat (usec): min=148, max=8620, avg=303.76, stdev=123.90
    clat percentiles (usec):
     |  1.00th=[  260],  5.00th=[  269], 10.00th=[  273], 20.00th=[  277],
     | 30.00th=[  281], 40.00th=[  285], 50.00th=[  285], 60.00th=[  289],
     | 70.00th=[  297], 80.00th=[  306], 90.00th=[  314], 95.00th=[  326],
     | 99.00th=[  717], 99.50th=[  783], 99.90th=[ 1713], 99.95th=[ 1713],
     | 99.99th=[ 1991]
   bw (  KiB/s): min=253816, max=455968, per=24.93%, avg=419767.11, stdev=63060.10, samples=9
   iops        : min=63454, max=113992, avg=104941.78, stdev=15765.03, samples=9
  lat (usec)   : 250=0.28%, 500=97.89%, 750=1.33%, 1000=0.02%
  lat (msec)   : 2=0.48%, 4=0.01%, 10=0.01%
  cpu          : usr=6.46%, sys=16.78%, ctx=184260, majf=0, minf=43
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
read: (groupid=0, jobs=1): err= 0: pid=621079: Tue Mar  7 23:17:45 2023
  read: IOPS=105k, BW=411MiB/s (431MB/s)(2048MiB/4982msec)
    slat (nsec): min=718, max=43424, avg=1243.55, stdev=584.41
    clat (usec): min=127, max=8825, avg=302.46, stdev=127.73
     lat (usec): min=129, max=8835, avg=303.71, stdev=127.77
    clat percentiles (usec):
     |  1.00th=[  260],  5.00th=[  265], 10.00th=[  269], 20.00th=[  277],
     | 30.00th=[  281], 40.00th=[  285], 50.00th=[  289], 60.00th=[  293],
     | 70.00th=[  297], 80.00th=[  306], 90.00th=[  318], 95.00th=[  326],
     | 99.00th=[  693], 99.50th=[  750], 99.90th=[ 1795], 99.95th=[ 1795],
     | 99.99th=[ 2089]
   bw (  KiB/s): min=253792, max=455968, per=24.93%, avg=419787.56, stdev=63080.74, samples=9
   iops        : min=63448, max=113992, avg=104946.89, stdev=15770.18, samples=9
  lat (usec)   : 250=0.21%, 500=97.96%, 750=1.33%, 1000=0.02%
  lat (msec)   : 2=0.47%, 4=0.01%, 10=0.01%
  cpu          : usr=7.75%, sys=20.86%, ctx=358079, majf=0, minf=42
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32

Run status group 0 (all jobs):
   READ: bw=1644MiB/s (1724MB/s), 411MiB/s-411MiB/s (431MB/s-431MB/s), io=8192MiB (8590MB), run=4982-4982msec

Disk stats (read/write):
  nvme0n1: ios=2060661/0, merge=0/0, ticks=620092/0, in_queue=620091, util=98.12%
```

值得一提的是, 上面一共有 5 个 fio 进程; 因为其中一个是主进程, 其他 4 个才是 job 实例进程

```
Jobs: 4 (f=4): [R(4)][100.0%][r=1735MiB/s][r=444k IOPS][eta 00m:00s]
```

显示已创建作业的状态.

当前运行和执行 I/O 的线程数为 4, 当前打开的文件数(f=)为 4

第一组括号中的字符表示每个线程的当前状态:

* w: running, doing random writes
* W: running, doing sequential writes
* r: running, doing random reads
* R: running, doing sequential reads
* m: running, doing mixed random reads/writes
* M: running, doing mixed sequential reads/writes
* C: thread created
* f: thread finishing

第二组括号显示当前估计完成百分比, 因为已经命令已经执行完, 所以是 100%.

第三组括号分别显示读取 I/O 速率.

第四组括号以 IOPS 表示第三组括号的内容. `(444k * 4)/1024 = 1735MiB/s`

最后, 将显示预估的作业剩余运行时间.

当 fio 完成时(或被 `Ctrl-C` 中断), 它将按顺序显示每个线程、每组线程和每个磁盘的数据.

```
read: (groupid=0, jobs=1): err= 0: pid=621076: Tue Mar  7 23:17:45 2023
```

job 头, 显示了所属 group, pid, 运行时间等

```
  read: IOPS=105k, BW=411MiB/s (431MB/s)(2048MiB/4982msec)
```

IOPS: 每秒的**输入输出量**(或**读写次数**), 是衡量磁盘性能的主要指标之一;

> 这里的是数据量

Bw: 平均带宽速率.

(2048MiB/4982msec) 是该 job 的总和数据量以及花费时间

> KiB/s 是按 1K=1024 计算的, kB/s 是按 1K=1000 计算的

```
    slat (nsec): min=724, max=53917, avg=1249.32, stdev=614.43
    clat (usec): min=110, max=8555, avg=302.48, stdev=123.77
     lat (usec): min=114, max=8565, avg=303.73, stdev=123.83
```

>usec: 微秒; msec: 毫秒; 1ms=1000us;

* min, max, avg 分别代表最小、最大和平均值;

* stdev 表示标准差(standard deviation), 越大代表波动越大

I/O 延迟包括三种: slat, clat, lat:

* slat 表示 fio submit 某个 I/O 的延迟. slat 只在 `–ioengine=libaio` 的时候才会出现, 因为对于 –ioengine=sync/psync 没有所谓的提交延迟

* clat 表示 fio complete 某个 I/O 的延迟. 对于 `–ioengine=libaio`, clat 表示从提交到完成的延迟. 对于 `–ioengine=sync/psync`, fio 文档中说 clat 等于或非常接近于 0(因为提交就相当于完成). 但从实验上看, 不是这样的: 对于 `–ioengine=sync/psync`, 不显示 slat, clat 接近总延迟.

* lat 即从 I/O 被创建到完成的延迟(从 fio 将请求提交给内核, 再到内核完成这个 I/O 为止所需要的时间)

大致是这样(对吗?):

* 对于 `–ioengine=libaio`: lat = latency(创建到提交) + slat + clat
* 对于 `–ioengine=sync/psync`: lat = latency(创建到开始) + clat

```
    clat percentiles (usec):
     |  1.00th=[  262],  5.00th=[  269], 10.00th=[  273], 20.00th=[  277],
     | 30.00th=[  281], 40.00th=[  285], 50.00th=[  285], 60.00th=[  289],
     | 70.00th=[  297], 80.00th=[  306], 90.00th=[  314], 95.00th=[  326],
     | 99.00th=[  717], 99.50th=[  783], 99.90th=[ 1713], 99.95th=[ 1713],
     | 99.99th=[ 2008]
```

clat 的百分位数. 1% 在 262us 内; 5% 在 269us 内; 10% 在 273us 内, 以此类推

```
   bw (  KiB/s): min=253840, max=455968, per=24.93%, avg=419759.11, stdev=63047.49, samples=9
```

基于采样得到的带宽统计(可以看见, 与前面的 BW=411MiB/s 接近).

* min, max, avg 分别表示最小、最大和平均值

* per 表示当前 job 实例(`g0-j0`)的带宽在组里所占的百分比, 即 g0-j0 在 groupid=0 的组里(4 个 pid, 即 4 个 jobs), 读带宽占总读带宽的 24.93%(差不多刚好 1/4)

* stdev 表示标准差

* samples 表示采样数

```
   iops        : min=63460, max=113992, avg=104939.78, stdev=15761.87, samples=9
```

基于采样得到的 iops 统计(与前面的 IOPS=105k 接近)

```
  lat (usec)   : 250=0.11%, 500=98.06%, 750=1.30%, 1000=0.04%
  lat (msec)   : 2=0.48%, 4=0.01%, 10=0.01%
```

所有 I/O 的总体延迟分布. 这是从 I/O 离开 fio 到完成的时间

* 有 0.11% 的 request 延迟 < 250us;

* 有 98.06% 的 250us =< request lat < 500us;

* 有 1.30% 的 500us =< request lat < 750us, 以此类推;

```
  cpu          : usr=7.67%, sys=18.29%, ctx=247079, majf=0, minf=41
```

cpu 使用情况.

* usr 是用户态占比;

* sys 是内核态占比;

* ctx 表示该 job 经历的 context switch 数目

* majf 和 minf 分别表示 major and minor page faults

> 因为上下文切换导致的主要和次要页面失败的用户/系统 CPU 使用百分比. 因为测试被配置的使用直接 IO, 因此有很少的页面失败: ;

```
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, >=64=0.0%
```

IO depth 的分布.

* 1 表示 1-2 的占比;
* 2 表示 2-4 的占比;
* 4 表示 4-8 的占比;
* 以此类推.

表示在任何时间有多少 IO 分发给系统. 这完全是**应用方面**的, 意味着它和**设备的 IO 队列**做不同的事情, iodepth 设置为 32, 因此 IO 深度在 100% 的时间里一直是 32;

```
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
```
IO submit 的分布, 即在一个 submit 调用里, 提交了多少 I/O.

* 4 表示 0-4 区间内的占比;
* 8 表示 4-8 区间内的占比;
* 以此类推.

```
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, >=64=0.0%
```

IO complete. 一次 complete 查询中(`io_getevents` 调用), 完成了多少 I/O.

```
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     issued rwts: total=524288,0,0,0 short=0,0,0,0 dropped=0,0,0,0     latency   : target=0, window=0, percentile=100.00%, depth=32
```

IO issued rwts.

* total. 总共发出了多少 (read, write, trim, x) 请求
* short. (read, write, send, recv) 由多少返回大小 小于 请求大小
* 有多少被 dropped.

这一行需要和后面的 `Disk stats (read/write)` 里的 `nvme0n1: ios=2060661/0` 对照来看: 在本例中, 4 个 job 的读都是 524288; 4 个 job 都没有其他操作, 所以加在一起是 `2097152`, 接近 `nvme0n1: ios=2060661/0` 里面的 `2060661`.

注意: 1. 写操作加起来(g0-j0,g0-j1,g1-j0,g1-j1,g1-j2)并不相等, 因为 g1 写的是 1m 大小, 可能分成多个 I/O 进行的; 2. 另外, 在文件系统中测试时, 这个关系也不一样, 可能有元数据操作

```
     latency   : target=0, window=0, percentile=100.00%, depth=32
```

IO latency. 和 latency_target 相关, 忽略

```
Run status group 0 (all jobs):
   READ: bw=1644MiB/s (1724MB/s), 411MiB/s-411MiB/s (431MB/s-431MB/s), io=8192MiB (8590MB), run=4982-4982msec
```

group 统计. group 0 read 操作:

* `bw=1644MiB/s (1724MB/s)`: 这组 job 的总带宽.
* `411MiB/s-411MiB/s (431MB/s-431MB/s)`: 所有 job 实例中的最小带宽和最大带宽(分别以 `1K=1024` 和 `1K=1000` 计算); 从前面输出可以看到, 每个 job 的带宽都是 411MiB/s.
* io. 这组 job 的总 io 数据量大小; 结合上面每个 job 的 (2048MiB/4982msec), 可以看到 8192 = 2048 x 4.
* run. 线程的最小和最大运行时间; 结合上面每个 job 的 (2048MiB/4982msec).

```
Disk stats (read/write):
  nvme0n1: ios=2060661/0, merge=0/0, ticks=620092/0, in_queue=620091, util=98.12%
```

磁盘统计

* ios. iostat 的 `r/s` 和 `w/s` 在运行时间上的累积, 即所有 group 总共执行的 read/write 的 IO 请求次数, 和前面的 `IO issued rwts` 一致.
* merge. iostat 的 `rrqm/s` 和 `wrqm/s` 在运行时间上的累积, 即总共发生的 IO 合并数.
* ticks. disk busy 的 ticks 数.
* in_queue. 所有 I/O 在 disk queue 中花费的 ticks 总数, 即花费在队列上的总共时间
* Util: iostat 的 util, 即磁盘利用率.

